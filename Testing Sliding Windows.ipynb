{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16524ae0",
   "metadata": {},
   "source": [
    "# METHODOLOGY AND EXPERIMENTATION CPI FORECASTING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1831438",
   "metadata": {},
   "source": [
    "Methodology:\n",
    "In this study, we compare the performance of several models for CPI forecasting, \n",
    "including VAR, ARIMA, Lasso Regressor, SVR, Random Forest Regressor, LSTM, CNN, . \n",
    "Additionally, we propose a novel approach using an RNN encoder-decoder with multi-head attention. \n",
    "The models are trained using historical CPI data and relevant economic indicators. \n",
    "The forecasting accuracy of each model is evaluated by comparing the predicted CPI values with the actual data.\n",
    "\n",
    "Experimentation:\n",
    "To conduct the experiments, we divide the CPI dataset into training and testing sets, \n",
    "with the last 6 months reserved for testing. The models are trained on the training set and evaluated on the testing set \n",
    "using performance metrics such as mean absolute error, root mean squared error, and R-squared. \n",
    "The experiments are designed to assess the forecasting capabilities of each model and determine the effectiveness \n",
    "of the proposed RNN encoder-decoder with multi-head attention approach compared to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5034e",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d18906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a90ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699860e2",
   "metadata": {},
   "source": [
    "#### Read File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9fd553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All-items</th>\n",
       "      <th>Food</th>\n",
       "      <th>Shelter</th>\n",
       "      <th>Household operations</th>\n",
       "      <th>Clothing and footwear</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Gasoline</th>\n",
       "      <th>Health and personal care</th>\n",
       "      <th>Recreation &amp; education</th>\n",
       "      <th>Alcohol, tobacco &amp; cannabis</th>\n",
       "      <th>All-items excluding food and energy</th>\n",
       "      <th>All-items excluding energy</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Goods</th>\n",
       "      <th>Services</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>102.0</td>\n",
       "      <td>101.6</td>\n",
       "      <td>102.1</td>\n",
       "      <td>100.1</td>\n",
       "      <td>96.6</td>\n",
       "      <td>105.5</td>\n",
       "      <td>108.4</td>\n",
       "      <td>100.5</td>\n",
       "      <td>99.3</td>\n",
       "      <td>106.8</td>\n",
       "      <td>101.5</td>\n",
       "      <td>101.5</td>\n",
       "      <td>108.3</td>\n",
       "      <td>101.9</td>\n",
       "      <td>102.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-02-01</th>\n",
       "      <td>102.8</td>\n",
       "      <td>101.5</td>\n",
       "      <td>102.5</td>\n",
       "      <td>100.6</td>\n",
       "      <td>98.7</td>\n",
       "      <td>107.1</td>\n",
       "      <td>116.1</td>\n",
       "      <td>100.8</td>\n",
       "      <td>100.6</td>\n",
       "      <td>108.1</td>\n",
       "      <td>102.1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>102.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>103.1</td>\n",
       "      <td>101.7</td>\n",
       "      <td>103.2</td>\n",
       "      <td>100.6</td>\n",
       "      <td>100.3</td>\n",
       "      <td>107.6</td>\n",
       "      <td>117.2</td>\n",
       "      <td>100.5</td>\n",
       "      <td>100.3</td>\n",
       "      <td>108.3</td>\n",
       "      <td>102.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>115.3</td>\n",
       "      <td>103.6</td>\n",
       "      <td>102.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>102.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>102.3</td>\n",
       "      <td>100.7</td>\n",
       "      <td>98.7</td>\n",
       "      <td>105.4</td>\n",
       "      <td>106.7</td>\n",
       "      <td>101.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.9</td>\n",
       "      <td>102.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>106.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>102.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-01</th>\n",
       "      <td>102.5</td>\n",
       "      <td>102.1</td>\n",
       "      <td>102.9</td>\n",
       "      <td>100.6</td>\n",
       "      <td>98.3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>99.3</td>\n",
       "      <td>101.4</td>\n",
       "      <td>100.7</td>\n",
       "      <td>110.2</td>\n",
       "      <td>102.5</td>\n",
       "      <td>102.4</td>\n",
       "      <td>103.7</td>\n",
       "      <td>101.8</td>\n",
       "      <td>103.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            All-items  Food   Shelter  Household operations  \\\n",
       "Date                                                          \n",
       "2003-01-01      102.0  101.6    102.1                 100.1   \n",
       "2003-02-01      102.8  101.5    102.5                 100.6   \n",
       "2003-03-01      103.1  101.7    103.2                 100.6   \n",
       "2003-04-01      102.4  101.8    102.3                 100.7   \n",
       "2003-05-01      102.5  102.1    102.9                 100.6   \n",
       "\n",
       "            Clothing and footwear  Transportation  Gasoline  \\\n",
       "Date                                                          \n",
       "2003-01-01                   96.6           105.5     108.4   \n",
       "2003-02-01                   98.7           107.1     116.1   \n",
       "2003-03-01                  100.3           107.6     117.2   \n",
       "2003-04-01                   98.7           105.4     106.7   \n",
       "2003-05-01                   98.3           104.0      99.3   \n",
       "\n",
       "            Health and personal care  Recreation & education   \\\n",
       "Date                                                            \n",
       "2003-01-01                     100.5                     99.3   \n",
       "2003-02-01                     100.8                    100.6   \n",
       "2003-03-01                     100.5                    100.3   \n",
       "2003-04-01                     101.2                    100.0   \n",
       "2003-05-01                     101.4                    100.7   \n",
       "\n",
       "            Alcohol, tobacco & cannabis  All-items excluding food and energy   \\\n",
       "Date                                                                            \n",
       "2003-01-01                        106.8                                 101.5   \n",
       "2003-02-01                        108.1                                 102.1   \n",
       "2003-03-01                        108.3                                 102.3   \n",
       "2003-04-01                        108.9                                 102.3   \n",
       "2003-05-01                        110.2                                 102.5   \n",
       "\n",
       "            All-items excluding energy   Energy  Goods  Services   \n",
       "Date                                                               \n",
       "2003-01-01                        101.5   108.3  101.9      102.1  \n",
       "2003-02-01                        102.0   113.0  103.0      102.6  \n",
       "2003-03-01                        102.2   115.3  103.6      102.7  \n",
       "2003-04-01                        102.2   106.0  101.9      102.9  \n",
       "2003-05-01                        102.4   103.7  101.8      103.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Owner\\Downloads\\MRP\\CPI\\CPI_Monthly_2003_2023_updated.csv\", parse_dates=[0],index_col=[0]\n",
    "                  )\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18761c",
   "metadata": {},
   "source": [
    "#### Get Basic summary stastistics and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a64a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 244 entries, 2003-01-01 to 2023-04-01\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   All-items                             244 non-null    float64\n",
      " 1   Food                                  244 non-null    float64\n",
      " 2   Shelter                               244 non-null    float64\n",
      " 3   Household operations                  244 non-null    float64\n",
      " 4   Clothing and footwear                 244 non-null    float64\n",
      " 5   Transportation                        244 non-null    float64\n",
      " 6   Gasoline                              244 non-null    float64\n",
      " 7   Health and personal care              244 non-null    float64\n",
      " 8   Recreation & education                244 non-null    float64\n",
      " 9   Alcohol, tobacco & cannabis           244 non-null    float64\n",
      " 10  All-items excluding food and energy   244 non-null    float64\n",
      " 11  All-items excluding energy            244 non-null    float64\n",
      " 12  Energy                                244 non-null    float64\n",
      " 13  Goods                                 244 non-null    float64\n",
      " 14  Services                              244 non-null    float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08615d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All-items</th>\n",
       "      <td>244.0</td>\n",
       "      <td>123.229508</td>\n",
       "      <td>13.362860</td>\n",
       "      <td>102.0</td>\n",
       "      <td>112.175</td>\n",
       "      <td>122.70</td>\n",
       "      <td>133.000</td>\n",
       "      <td>156.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>244.0</td>\n",
       "      <td>132.002459</td>\n",
       "      <td>20.085299</td>\n",
       "      <td>100.7</td>\n",
       "      <td>112.600</td>\n",
       "      <td>131.80</td>\n",
       "      <td>144.700</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shelter</th>\n",
       "      <td>244.0</td>\n",
       "      <td>129.881148</td>\n",
       "      <td>16.165007</td>\n",
       "      <td>102.1</td>\n",
       "      <td>119.500</td>\n",
       "      <td>127.95</td>\n",
       "      <td>140.075</td>\n",
       "      <td>169.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household operations</th>\n",
       "      <td>244.0</td>\n",
       "      <td>114.036885</td>\n",
       "      <td>9.665732</td>\n",
       "      <td>100.1</td>\n",
       "      <td>104.000</td>\n",
       "      <td>114.05</td>\n",
       "      <td>122.725</td>\n",
       "      <td>133.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothing and footwear</th>\n",
       "      <td>244.0</td>\n",
       "      <td>94.535246</td>\n",
       "      <td>2.662912</td>\n",
       "      <td>87.9</td>\n",
       "      <td>92.775</td>\n",
       "      <td>94.65</td>\n",
       "      <td>96.225</td>\n",
       "      <td>100.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transportation</th>\n",
       "      <td>244.0</td>\n",
       "      <td>128.072541</td>\n",
       "      <td>15.869033</td>\n",
       "      <td>103.7</td>\n",
       "      <td>116.700</td>\n",
       "      <td>127.35</td>\n",
       "      <td>137.125</td>\n",
       "      <td>176.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gasoline</th>\n",
       "      <td>244.0</td>\n",
       "      <td>161.768852</td>\n",
       "      <td>33.503064</td>\n",
       "      <td>99.3</td>\n",
       "      <td>142.525</td>\n",
       "      <td>157.40</td>\n",
       "      <td>183.350</td>\n",
       "      <td>299.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health and personal care</th>\n",
       "      <td>244.0</td>\n",
       "      <td>117.973361</td>\n",
       "      <td>10.583401</td>\n",
       "      <td>100.5</td>\n",
       "      <td>107.900</td>\n",
       "      <td>118.40</td>\n",
       "      <td>125.600</td>\n",
       "      <td>145.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recreation &amp; education</th>\n",
       "      <td>244.0</td>\n",
       "      <td>108.413115</td>\n",
       "      <td>7.160660</td>\n",
       "      <td>99.1</td>\n",
       "      <td>102.075</td>\n",
       "      <td>106.40</td>\n",
       "      <td>114.500</td>\n",
       "      <td>127.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol, tobacco &amp; cannabis</th>\n",
       "      <td>244.0</td>\n",
       "      <td>144.764754</td>\n",
       "      <td>21.909026</td>\n",
       "      <td>106.8</td>\n",
       "      <td>126.600</td>\n",
       "      <td>139.60</td>\n",
       "      <td>166.475</td>\n",
       "      <td>189.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All-items excluding food and energy</th>\n",
       "      <td>244.0</td>\n",
       "      <td>118.772131</td>\n",
       "      <td>11.355626</td>\n",
       "      <td>101.5</td>\n",
       "      <td>109.600</td>\n",
       "      <td>117.00</td>\n",
       "      <td>127.525</td>\n",
       "      <td>146.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All-items excluding energy</th>\n",
       "      <td>244.0</td>\n",
       "      <td>121.115574</td>\n",
       "      <td>12.842375</td>\n",
       "      <td>101.5</td>\n",
       "      <td>109.975</td>\n",
       "      <td>119.80</td>\n",
       "      <td>130.600</td>\n",
       "      <td>152.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>244.0</td>\n",
       "      <td>149.719262</td>\n",
       "      <td>24.265764</td>\n",
       "      <td>103.7</td>\n",
       "      <td>134.500</td>\n",
       "      <td>149.80</td>\n",
       "      <td>159.950</td>\n",
       "      <td>242.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goods</th>\n",
       "      <td>244.0</td>\n",
       "      <td>115.347951</td>\n",
       "      <td>9.581440</td>\n",
       "      <td>100.9</td>\n",
       "      <td>107.875</td>\n",
       "      <td>114.45</td>\n",
       "      <td>120.200</td>\n",
       "      <td>143.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Services</th>\n",
       "      <td>244.0</td>\n",
       "      <td>131.046721</td>\n",
       "      <td>17.354589</td>\n",
       "      <td>102.1</td>\n",
       "      <td>116.800</td>\n",
       "      <td>130.20</td>\n",
       "      <td>144.675</td>\n",
       "      <td>168.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      count        mean        std    min  \\\n",
       "All-items                             244.0  123.229508  13.362860  102.0   \n",
       "Food                                  244.0  132.002459  20.085299  100.7   \n",
       "Shelter                               244.0  129.881148  16.165007  102.1   \n",
       "Household operations                  244.0  114.036885   9.665732  100.1   \n",
       "Clothing and footwear                 244.0   94.535246   2.662912   87.9   \n",
       "Transportation                        244.0  128.072541  15.869033  103.7   \n",
       "Gasoline                              244.0  161.768852  33.503064   99.3   \n",
       "Health and personal care              244.0  117.973361  10.583401  100.5   \n",
       "Recreation & education                244.0  108.413115   7.160660   99.1   \n",
       "Alcohol, tobacco & cannabis           244.0  144.764754  21.909026  106.8   \n",
       "All-items excluding food and energy   244.0  118.772131  11.355626  101.5   \n",
       "All-items excluding energy            244.0  121.115574  12.842375  101.5   \n",
       "Energy                                244.0  149.719262  24.265764  103.7   \n",
       "Goods                                 244.0  115.347951   9.581440  100.9   \n",
       "Services                              244.0  131.046721  17.354589  102.1   \n",
       "\n",
       "                                          25%     50%      75%    max  \n",
       "All-items                             112.175  122.70  133.000  156.4  \n",
       "Food                                  112.600  131.80  144.700  183.1  \n",
       "Shelter                               119.500  127.95  140.075  169.9  \n",
       "Household operations                  104.000  114.05  122.725  133.7  \n",
       "Clothing and footwear                  92.775   94.65   96.225  100.8  \n",
       "Transportation                        116.700  127.35  137.125  176.2  \n",
       "Gasoline                              142.525  157.40  183.350  299.4  \n",
       "Health and personal care              107.900  118.40  125.600  145.7  \n",
       "Recreation & education                102.075  106.40  114.500  127.1  \n",
       "Alcohol, tobacco & cannabis           126.600  139.60  166.475  189.4  \n",
       "All-items excluding food and energy   109.600  117.00  127.525  146.6  \n",
       "All-items excluding energy            109.975  119.80  130.600  152.7  \n",
       "Energy                                134.500  149.80  159.950  242.5  \n",
       "Goods                                 107.875  114.45  120.200  143.9  \n",
       "Services                              116.800  130.20  144.675  168.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf305eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All-items                               0\n",
       "Food                                    0\n",
       "Shelter                                 0\n",
       "Household operations                    0\n",
       "Clothing and footwear                   0\n",
       "Transportation                          0\n",
       "Gasoline                                0\n",
       "Health and personal care                0\n",
       "Recreation & education                  0\n",
       "Alcohol, tobacco & cannabis             0\n",
       "All-items excluding food and energy     0\n",
       "All-items excluding energy              0\n",
       "Energy                                  0\n",
       "Goods                                   0\n",
       "Services                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df982a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers\n",
    "def remove_outliers_iqr(data, column_name):\n",
    "    Q1 = data[column_name].quantile(0.25)\n",
    "    Q3 = data[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    data_no_outliers = data[(data[column_name] >= lower_bound) & (data[column_name] <= upper_bound)]\n",
    "    return data_no_outliers\n",
    "\n",
    "# Remove outliers from the 'Gasoline' column\n",
    "data = remove_outliers_iqr(data, 'Gasoline')\n",
    "\n",
    "# Remove outliers from the 'Energy' column\n",
    "data = remove_outliers_iqr(data, 'Energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c7d2b",
   "metadata": {},
   "source": [
    "# PROPOSED MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe393d",
   "metadata": {},
   "source": [
    "### RNN Encoder Decoder Single Head Attention Model with Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2382f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "39/39 [==============================] - 4s 27ms/step - loss: 15193.3613 - val_loss: 11572.3330\n",
      "Epoch 2/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 10723.6787 - val_loss: 8149.5757\n",
      "Epoch 3/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 7782.9639 - val_loss: 5686.3276\n",
      "Epoch 4/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 5473.3188 - val_loss: 3876.5564\n",
      "Epoch 5/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 3856.8721 - val_loss: 2659.3240\n",
      "Epoch 6/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2741.3459 - val_loss: 1825.5607\n",
      "Epoch 7/500\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1976.4415 - val_loss: 1284.4763\n",
      "Epoch 8/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1464.4257 - val_loss: 939.0129\n",
      "Epoch 9/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1125.4308 - val_loss: 720.7023\n",
      "Epoch 10/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 906.4979 - val_loss: 588.4620\n",
      "Epoch 11/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 768.5054 - val_loss: 513.8511\n",
      "Epoch 12/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 683.2164 - val_loss: 474.8844\n",
      "Epoch 13/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 620.0018 - val_loss: 420.2778\n",
      "Epoch 14/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 549.8049 - val_loss: 374.6472\n",
      "Epoch 15/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 491.0891 - val_loss: 331.8062\n",
      "Epoch 16/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 423.9643 - val_loss: 246.9467\n",
      "Epoch 17/500\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 349.7816 - val_loss: 215.8425\n",
      "Epoch 18/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 310.3854 - val_loss: 192.0291\n",
      "Epoch 19/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 278.3545 - val_loss: 173.8883\n",
      "Epoch 20/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 252.8660 - val_loss: 154.9050\n",
      "Epoch 21/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 226.0493 - val_loss: 140.5099\n",
      "Epoch 22/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 205.0203 - val_loss: 123.2192\n",
      "Epoch 23/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 186.4777 - val_loss: 113.9307\n",
      "Epoch 24/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 170.9014 - val_loss: 103.8111\n",
      "Epoch 25/500\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 157.1324 - val_loss: 92.5947\n",
      "Epoch 26/500\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 144.5497 - val_loss: 85.4905\n",
      "Epoch 27/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 134.0461 - val_loss: 78.2541\n",
      "Epoch 28/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 125.0020 - val_loss: 73.3654\n",
      "Epoch 29/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 116.5354 - val_loss: 67.9135\n",
      "Epoch 30/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 109.1992 - val_loss: 63.7411\n",
      "Epoch 31/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 102.4272 - val_loss: 61.0367\n",
      "Epoch 32/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 96.3467 - val_loss: 55.0636\n",
      "Epoch 33/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 90.0571 - val_loss: 51.8582\n",
      "Epoch 34/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 85.0836 - val_loss: 49.3733\n",
      "Epoch 35/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 80.5760 - val_loss: 46.1164\n",
      "Epoch 36/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 75.7920 - val_loss: 43.4370\n",
      "Epoch 37/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 71.9516 - val_loss: 41.5777\n",
      "Epoch 38/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 67.8225 - val_loss: 38.9373\n",
      "Epoch 39/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 64.3100 - val_loss: 37.3053\n",
      "Epoch 40/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 61.4914 - val_loss: 36.0053\n",
      "Epoch 41/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 58.6518 - val_loss: 34.4683\n",
      "Epoch 42/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 56.0407 - val_loss: 32.9507\n",
      "Epoch 43/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 53.6498 - val_loss: 31.7528\n",
      "Epoch 44/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 51.9891 - val_loss: 31.1117\n",
      "Epoch 45/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 49.5984 - val_loss: 29.1037\n",
      "Epoch 46/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 47.4467 - val_loss: 28.1168\n",
      "Epoch 47/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 45.6677 - val_loss: 26.9735\n",
      "Epoch 48/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 43.8829 - val_loss: 26.1755\n",
      "Epoch 49/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 42.3199 - val_loss: 25.6290\n",
      "Epoch 50/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 40.7731 - val_loss: 24.7660\n",
      "Epoch 51/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 39.1914 - val_loss: 23.6153\n",
      "Epoch 52/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 37.6149 - val_loss: 22.8571\n",
      "Epoch 53/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 36.3725 - val_loss: 22.3803\n",
      "Epoch 54/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 35.3250 - val_loss: 22.2008\n",
      "Epoch 55/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 34.3503 - val_loss: 21.3470\n",
      "Epoch 56/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 33.4945 - val_loss: 21.7621\n",
      "Epoch 57/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 32.7660 - val_loss: 20.3990\n",
      "Epoch 58/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 31.4067 - val_loss: 20.0753\n",
      "Epoch 59/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 30.5204 - val_loss: 19.2793\n",
      "Epoch 60/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 29.4390 - val_loss: 18.7231\n",
      "Epoch 61/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 28.3718 - val_loss: 18.1069\n",
      "Epoch 62/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 27.6574 - val_loss: 18.1755\n",
      "Epoch 63/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 27.4338 - val_loss: 17.8563\n",
      "Epoch 64/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 26.2960 - val_loss: 18.0376\n",
      "Epoch 65/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 26.1630 - val_loss: 16.8627\n",
      "Epoch 66/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 24.8458 - val_loss: 16.3567\n",
      "Epoch 67/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 24.2865 - val_loss: 16.0232\n",
      "Epoch 68/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 23.5657 - val_loss: 15.7814\n",
      "Epoch 69/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 22.9168 - val_loss: 15.3727\n",
      "Epoch 70/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 22.3346 - val_loss: 15.0087\n",
      "Epoch 71/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 21.7967 - val_loss: 14.8926\n",
      "Epoch 72/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 21.3604 - val_loss: 14.6241\n",
      "Epoch 73/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 21.0349 - val_loss: 14.6599\n",
      "Epoch 74/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 20.5594 - val_loss: 14.0307\n",
      "Epoch 75/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 20.0659 - val_loss: 13.9338\n",
      "Epoch 76/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 19.4084 - val_loss: 13.4686\n",
      "Epoch 77/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 18.8522 - val_loss: 13.2076\n",
      "Epoch 78/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 18.4043 - val_loss: 13.0160\n",
      "Epoch 79/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 18.1308 - val_loss: 12.8149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 17.5754 - val_loss: 12.4764\n",
      "Epoch 81/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 17.1977 - val_loss: 12.5894\n",
      "Epoch 82/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 17.2179 - val_loss: 12.2934\n",
      "Epoch 83/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 16.5926 - val_loss: 11.9479\n",
      "Epoch 84/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 16.0970 - val_loss: 11.6004\n",
      "Epoch 85/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 15.8175 - val_loss: 11.6654\n",
      "Epoch 86/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 15.5050 - val_loss: 11.6544\n",
      "Epoch 87/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 15.0695 - val_loss: 10.9041\n",
      "Epoch 88/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 14.7878 - val_loss: 10.9399\n",
      "Epoch 89/500\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 14.3278 - val_loss: 10.5389\n",
      "Epoch 90/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 13.9771 - val_loss: 10.3611\n",
      "Epoch 91/500\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 13.6641 - val_loss: 10.1149\n",
      "Epoch 92/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 13.3982 - val_loss: 9.9302\n",
      "Epoch 93/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 13.0860 - val_loss: 9.7131\n",
      "Epoch 94/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 12.7642 - val_loss: 9.5899\n",
      "Epoch 95/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 12.9653 - val_loss: 10.6876\n",
      "Epoch 96/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 12.7901 - val_loss: 9.3359\n",
      "Epoch 97/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 12.7805 - val_loss: 9.3443\n",
      "Epoch 98/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 12.4138 - val_loss: 9.2202\n",
      "Epoch 99/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 11.6701 - val_loss: 9.1192\n",
      "Epoch 100/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 11.5307 - val_loss: 8.5840\n",
      "Epoch 101/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 11.0089 - val_loss: 8.6218\n",
      "Epoch 102/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 10.7901 - val_loss: 8.1332\n",
      "Epoch 103/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 10.4602 - val_loss: 8.1330\n",
      "Epoch 104/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 10.1944 - val_loss: 7.8188\n",
      "Epoch 105/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 10.0137 - val_loss: 7.6456\n",
      "Epoch 106/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 9.8250 - val_loss: 7.6238\n",
      "Epoch 107/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 10.0463 - val_loss: 7.7603\n",
      "Epoch 108/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 9.6219 - val_loss: 7.4537\n",
      "Epoch 109/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 9.2693 - val_loss: 7.0410\n",
      "Epoch 110/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 8.9996 - val_loss: 7.2183\n",
      "Epoch 111/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 8.7456 - val_loss: 6.8735\n",
      "Epoch 112/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 8.5349 - val_loss: 6.8471\n",
      "Epoch 113/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 8.3999 - val_loss: 6.4511\n",
      "Epoch 114/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 8.2519 - val_loss: 6.4087\n",
      "Epoch 115/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 8.2615 - val_loss: 6.3877\n",
      "Epoch 116/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 7.8978 - val_loss: 6.0138\n",
      "Epoch 117/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.7508 - val_loss: 6.0351\n",
      "Epoch 118/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.5583 - val_loss: 5.9339\n",
      "Epoch 119/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.8820 - val_loss: 6.1779\n",
      "Epoch 120/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.4516 - val_loss: 5.6935\n",
      "Epoch 121/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 7.0665 - val_loss: 5.3597\n",
      "Epoch 122/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 6.8093 - val_loss: 5.2611\n",
      "Epoch 123/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.6814 - val_loss: 5.1925\n",
      "Epoch 124/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.6088 - val_loss: 5.1107\n",
      "Epoch 125/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.5163 - val_loss: 5.4691\n",
      "Epoch 126/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.3968 - val_loss: 4.8358\n",
      "Epoch 127/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.0620 - val_loss: 4.6724\n",
      "Epoch 128/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.9576 - val_loss: 4.9314\n",
      "Epoch 129/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.0596 - val_loss: 4.6877\n",
      "Epoch 130/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 6.0309 - val_loss: 5.0103\n",
      "Epoch 131/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.7527 - val_loss: 4.6930\n",
      "Epoch 132/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.6983 - val_loss: 4.2446\n",
      "Epoch 133/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.4379 - val_loss: 4.4706\n",
      "Epoch 134/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.3024 - val_loss: 4.0716\n",
      "Epoch 135/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.2581 - val_loss: 4.0468\n",
      "Epoch 136/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.3361 - val_loss: 4.6714\n",
      "Epoch 137/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.6458 - val_loss: 4.5097\n",
      "Epoch 138/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.3264 - val_loss: 3.9694\n",
      "Epoch 139/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.8063 - val_loss: 3.6879\n",
      "Epoch 140/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.6439 - val_loss: 3.9102\n",
      "Epoch 141/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.0011 - val_loss: 3.6533\n",
      "Epoch 142/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.9610 - val_loss: 4.1120\n",
      "Epoch 143/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 5.7081 - val_loss: 3.9180\n",
      "Epoch 144/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 4.5323 - val_loss: 3.1893\n",
      "Epoch 145/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 4.1917 - val_loss: 3.2593\n",
      "Epoch 146/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 4.3433 - val_loss: 3.3645\n",
      "Epoch 147/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 4.0110 - val_loss: 2.9498\n",
      "Epoch 148/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.8342 - val_loss: 2.9356\n",
      "Epoch 149/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.9561 - val_loss: 2.9645\n",
      "Epoch 150/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.7323 - val_loss: 2.8304\n",
      "Epoch 151/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.5894 - val_loss: 2.6282\n",
      "Epoch 152/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.5321 - val_loss: 2.8568\n",
      "Epoch 153/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.5115 - val_loss: 2.5475\n",
      "Epoch 154/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 3.3508 - val_loss: 2.5259\n",
      "Epoch 155/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.2532 - val_loss: 2.4344\n",
      "Epoch 156/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.1989 - val_loss: 2.7126\n",
      "Epoch 157/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.1873 - val_loss: 2.2184\n",
      "Epoch 158/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.9677 - val_loss: 2.2418\n",
      "Epoch 159/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.9415 - val_loss: 2.1228\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 13ms/step - loss: 2.8063 - val_loss: 2.0633\n",
      "Epoch 161/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.8239 - val_loss: 2.0749\n",
      "Epoch 162/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.1493 - val_loss: 2.1771\n",
      "Epoch 163/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.8433 - val_loss: 2.3807\n",
      "Epoch 164/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.7555 - val_loss: 1.9264\n",
      "Epoch 165/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.6458 - val_loss: 1.8198\n",
      "Epoch 166/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.5471 - val_loss: 1.9005\n",
      "Epoch 167/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.5922 - val_loss: 1.8065\n",
      "Epoch 168/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.5752 - val_loss: 1.8298\n",
      "Epoch 169/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.4342 - val_loss: 1.6812\n",
      "Epoch 170/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.3611 - val_loss: 2.4955\n",
      "Epoch 171/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.4927 - val_loss: 1.6039\n",
      "Epoch 172/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.3851 - val_loss: 1.9416\n",
      "Epoch 173/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.6563 - val_loss: 1.7069\n",
      "Epoch 174/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.6370 - val_loss: 1.6463\n",
      "Epoch 175/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 2.5575 - val_loss: 1.6955\n",
      "Epoch 176/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 2.6527 - val_loss: 1.7365\n",
      "Epoch 177/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.0433 - val_loss: 2.1728\n",
      "Epoch 178/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.5544 - val_loss: 1.3842\n",
      "Epoch 179/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.1109 - val_loss: 1.3624\n",
      "Epoch 180/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.9817 - val_loss: 1.2146\n",
      "Epoch 181/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8221 - val_loss: 1.0996\n",
      "Epoch 182/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.9121 - val_loss: 1.2863\n",
      "Epoch 183/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.9400 - val_loss: 1.0241\n",
      "Epoch 184/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8464 - val_loss: 1.1447\n",
      "Epoch 185/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8371 - val_loss: 1.0912\n",
      "Epoch 186/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8982 - val_loss: 1.2910\n",
      "Epoch 187/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.9385 - val_loss: 1.0752\n",
      "Epoch 188/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.6238 - val_loss: 0.8505\n",
      "Epoch 189/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.0432 - val_loss: 1.2385\n",
      "Epoch 190/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.9336 - val_loss: 0.8235\n",
      "Epoch 191/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.4950 - val_loss: 0.7955\n",
      "Epoch 192/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.7787 - val_loss: 1.4958\n",
      "Epoch 193/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.1019 - val_loss: 1.2071\n",
      "Epoch 194/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.9198 - val_loss: 1.1312\n",
      "Epoch 195/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.9859 - val_loss: 1.0287\n",
      "Epoch 196/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.7536 - val_loss: 1.0409\n",
      "Epoch 197/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.2172 - val_loss: 1.2025\n",
      "Epoch 198/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.5685 - val_loss: 0.8390\n",
      "Epoch 199/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.5298 - val_loss: 0.8727\n",
      "Epoch 200/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.5110 - val_loss: 0.7582\n",
      "Epoch 201/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.3182 - val_loss: 0.6023\n",
      "Epoch 202/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.2883 - val_loss: 0.7329\n",
      "Epoch 203/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.3068 - val_loss: 0.6680\n",
      "Epoch 204/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.3833 - val_loss: 0.5431\n",
      "Epoch 205/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.2085 - val_loss: 0.5337\n",
      "Epoch 206/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.1257 - val_loss: 0.4852\n",
      "Epoch 207/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.1539 - val_loss: 0.5650\n",
      "Epoch 208/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.5429 - val_loss: 0.6295\n",
      "Epoch 209/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.2105 - val_loss: 0.4486\n",
      "Epoch 210/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0377 - val_loss: 0.3972\n",
      "Epoch 211/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0313 - val_loss: 0.5115\n",
      "Epoch 212/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0110 - val_loss: 0.3722\n",
      "Epoch 213/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.9538 - val_loss: 0.3761\n",
      "Epoch 214/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0447 - val_loss: 0.3976\n",
      "Epoch 215/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.9869 - val_loss: 0.3809\n",
      "Epoch 216/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.9329 - val_loss: 0.3522\n",
      "Epoch 217/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.4096 - val_loss: 0.6643\n",
      "Epoch 218/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.1621 - val_loss: 2.8057\n",
      "Epoch 219/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 3.8980 - val_loss: 4.5396\n",
      "Epoch 220/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 5.2558 - val_loss: 3.0701\n",
      "Epoch 221/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 4.3874 - val_loss: 2.5049\n",
      "Epoch 222/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.2756 - val_loss: 1.0201\n",
      "Epoch 223/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.4237 - val_loss: 0.4317\n",
      "Epoch 224/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.9195 - val_loss: 0.3533\n",
      "Epoch 225/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8283 - val_loss: 0.2286\n",
      "Epoch 226/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7663 - val_loss: 0.2135\n",
      "Epoch 227/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6490 - val_loss: 0.1396\n",
      "Epoch 228/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6478 - val_loss: 0.1303\n",
      "Epoch 229/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6021 - val_loss: 0.1226\n",
      "Epoch 230/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6471 - val_loss: 0.1789\n",
      "Epoch 231/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6064 - val_loss: 0.1278\n",
      "Epoch 232/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.5787 - val_loss: 0.1025\n",
      "Epoch 233/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5422 - val_loss: 0.0802\n",
      "Epoch 234/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5254 - val_loss: 0.1370\n",
      "Epoch 235/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.4454 - val_loss: 0.1063\n",
      "Epoch 236/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5203 - val_loss: 0.1075\n",
      "Epoch 237/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5063 - val_loss: 0.1257\n",
      "Epoch 238/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4193 - val_loss: 0.0931\n",
      "Epoch 239/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5671 - val_loss: 0.7251\n",
      "Epoch 240/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.7760 - val_loss: 0.5788\n",
      "Epoch 241/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6300 - val_loss: 0.1739\n",
      "Epoch 242/500\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5761 - val_loss: 0.3952\n",
      "Epoch 243/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8365 - val_loss: 0.6495\n",
      "Epoch 244/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.7068 - val_loss: 0.2008\n",
      "Epoch 245/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6144 - val_loss: 0.4093\n",
      "Epoch 246/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4457 - val_loss: 0.1125\n",
      "Epoch 247/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3247 - val_loss: 0.0861\n",
      "Epoch 248/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2969 - val_loss: 0.0736\n",
      "Epoch 249/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2657 - val_loss: 0.0938\n",
      "Epoch 250/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3874 - val_loss: 0.4349\n",
      "Epoch 251/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6272 - val_loss: 0.3119\n",
      "Epoch 252/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8404 - val_loss: 1.6022\n",
      "Epoch 253/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.3788 - val_loss: 0.2592\n",
      "Epoch 254/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4701 - val_loss: 0.1180\n",
      "Epoch 255/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4897 - val_loss: 0.3491\n",
      "Epoch 256/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.5285 - val_loss: 0.2156\n",
      "Epoch 257/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4168 - val_loss: 0.1605\n",
      "Epoch 258/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2656 - val_loss: 0.1026\n",
      "Epoch 259/500\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.2434 - val_loss: 0.1488\n",
      "Epoch 260/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2739 - val_loss: 0.2231\n",
      "Epoch 261/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2232 - val_loss: 0.1381\n",
      "Epoch 262/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2282 - val_loss: 0.1501\n",
      "Epoch 263/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6599 - val_loss: 0.3213\n",
      "Epoch 264/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.3649 - val_loss: 0.2139\n",
      "Epoch 265/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1818 - val_loss: 0.1798\n",
      "Epoch 266/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2288 - val_loss: 0.2014\n",
      "Epoch 267/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3286 - val_loss: 0.3684\n",
      "Epoch 268/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3369 - val_loss: 0.1904\n",
      "Epoch 269/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1638 - val_loss: 0.1290\n",
      "Epoch 270/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1495 - val_loss: 0.1606\n",
      "Epoch 271/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1264 - val_loss: 0.1845\n",
      "Epoch 272/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1269 - val_loss: 0.2004\n",
      "Epoch 273/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1387 - val_loss: 0.2823\n",
      "Epoch 274/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1912 - val_loss: 0.2620\n",
      "Epoch 275/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2386 - val_loss: 0.3185\n",
      "Epoch 276/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1912 - val_loss: 0.2680\n",
      "Epoch 277/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5246 - val_loss: 0.2512\n",
      "Epoch 278/500\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.4553 - val_loss: 0.4836\n",
      "Epoch 279/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2484 - val_loss: 0.0597\n",
      "Epoch 280/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2010 - val_loss: 0.2420\n",
      "Epoch 281/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2115 - val_loss: 0.2000\n",
      "Epoch 282/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2103 - val_loss: 0.1896\n",
      "Epoch 283/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1338 - val_loss: 0.1649\n",
      "Epoch 284/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2000 - val_loss: 0.4916\n",
      "Epoch 285/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6010 - val_loss: 0.3535\n",
      "Epoch 286/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4840 - val_loss: 0.2866\n",
      "Epoch 287/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2746 - val_loss: 0.2248\n",
      "Epoch 288/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1610 - val_loss: 0.2774\n",
      "Epoch 289/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1218 - val_loss: 0.1187\n",
      "Epoch 290/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0954 - val_loss: 0.1864\n",
      "Epoch 291/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1020 - val_loss: 0.0918\n",
      "Epoch 292/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0972 - val_loss: 0.0858\n",
      "Epoch 293/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0866 - val_loss: 0.0977\n",
      "Epoch 294/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0999 - val_loss: 0.1311\n",
      "Epoch 295/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1791 - val_loss: 0.1643\n",
      "Epoch 296/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2995 - val_loss: 0.2262\n",
      "Epoch 297/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2218 - val_loss: 0.1096\n",
      "Epoch 298/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2366 - val_loss: 0.1951\n",
      "Epoch 299/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3970 - val_loss: 0.3139\n",
      "Epoch 300/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3319 - val_loss: 0.6592\n",
      "Epoch 301/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6892 - val_loss: 1.5344\n",
      "Epoch 302/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.0877 - val_loss: 0.4067\n",
      "Epoch 303/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2822 - val_loss: 0.0736\n",
      "Epoch 304/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1074 - val_loss: 0.0387\n",
      "Epoch 305/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1025 - val_loss: 0.0949\n",
      "Epoch 306/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0999 - val_loss: 0.1216\n",
      "Epoch 307/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1966 - val_loss: 0.5826\n",
      "Epoch 308/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.0598 - val_loss: 0.7100\n",
      "Epoch 309/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.3285 - val_loss: 1.2924\n",
      "Epoch 310/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 2.2044 - val_loss: 1.2868\n",
      "Epoch 311/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.4272 - val_loss: 0.5746\n",
      "Epoch 312/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5797 - val_loss: 0.1691\n",
      "Epoch 313/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2950 - val_loss: 0.1970\n",
      "Epoch 314/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1657 - val_loss: 0.2186\n",
      "Epoch 315/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1375 - val_loss: 0.1034\n",
      "Epoch 316/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0916 - val_loss: 0.0384\n",
      "Epoch 317/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0809 - val_loss: 0.0810\n",
      "Epoch 318/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0816 - val_loss: 0.0557\n",
      "Epoch 319/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2753 - val_loss: 0.4120\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3966 - val_loss: 0.6066\n",
      "Epoch 321/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3561 - val_loss: 0.1591\n",
      "Epoch 322/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2047 - val_loss: 0.5274\n",
      "Epoch 323/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1833 - val_loss: 0.2636\n",
      "Epoch 324/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1962 - val_loss: 0.2810\n",
      "Epoch 325/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1892 - val_loss: 0.3185\n",
      "Epoch 326/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2617 - val_loss: 0.6770\n",
      "Epoch 327/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.8881 - val_loss: 1.5475\n",
      "Epoch 328/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 2.9179 - val_loss: 0.8439\n",
      "Epoch 329/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.4817 - val_loss: 0.8303\n",
      "Epoch 330/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.1884 - val_loss: 1.7265\n",
      "Epoch 331/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.8539 - val_loss: 0.6924\n",
      "Epoch 332/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3411 - val_loss: 0.1926\n",
      "Epoch 333/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1432 - val_loss: 0.0534\n",
      "Epoch 334/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0704 - val_loss: 0.2511\n",
      "Epoch 335/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0985 - val_loss: 0.0560\n",
      "Epoch 336/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1360 - val_loss: 0.3183\n",
      "Epoch 337/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1218 - val_loss: 0.5751\n",
      "Epoch 338/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3313 - val_loss: 0.4833\n",
      "Epoch 339/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1072 - val_loss: 0.0595\n",
      "Epoch 340/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0868 - val_loss: 0.2243\n",
      "Epoch 341/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0662 - val_loss: 0.2986\n",
      "Epoch 342/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1232 - val_loss: 0.0370\n",
      "Epoch 343/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0869 - val_loss: 0.2034\n",
      "Epoch 344/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1133 - val_loss: 0.0962\n",
      "Epoch 345/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0649 - val_loss: 0.0325\n",
      "Epoch 346/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0715 - val_loss: 0.2462\n",
      "Epoch 347/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.0878 - val_loss: 1.7711\n",
      "Epoch 348/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 3.7576 - val_loss: 0.8997\n",
      "Epoch 349/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.1768 - val_loss: 0.5404\n",
      "Epoch 350/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8151 - val_loss: 0.1909\n",
      "Epoch 351/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8831 - val_loss: 0.8806\n",
      "Epoch 352/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6628 - val_loss: 0.1898\n",
      "Epoch 353/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.3994 - val_loss: 0.1044\n",
      "Epoch 354/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.2880 - val_loss: 0.1041\n",
      "Epoch 355/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2189 - val_loss: 0.1380\n",
      "Epoch 356/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2167 - val_loss: 0.1777\n",
      "Epoch 357/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3645 - val_loss: 0.2779\n",
      "Epoch 358/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4210 - val_loss: 0.0872\n",
      "Epoch 359/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2386 - val_loss: 0.2018\n",
      "Epoch 360/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1041 - val_loss: 0.0750\n",
      "Epoch 361/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0997 - val_loss: 0.0621\n",
      "Epoch 362/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1415 - val_loss: 0.1255\n",
      "Epoch 363/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1002 - val_loss: 0.1104\n",
      "Epoch 364/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0828 - val_loss: 0.1092\n",
      "Epoch 365/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0686 - val_loss: 0.0396\n",
      "Epoch 366/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0711 - val_loss: 0.0522\n",
      "Epoch 367/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0936 - val_loss: 0.1395\n",
      "Epoch 368/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1359 - val_loss: 0.1205\n",
      "Epoch 369/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1810 - val_loss: 0.0800\n",
      "Epoch 370/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0810 - val_loss: 0.0796\n",
      "Epoch 371/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0633 - val_loss: 0.0942\n",
      "Epoch 372/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1030 - val_loss: 0.1158\n",
      "Epoch 373/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0924 - val_loss: 0.0919\n",
      "Epoch 374/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0636 - val_loss: 0.0740\n",
      "Epoch 375/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0730 - val_loss: 0.0355\n",
      "Epoch 376/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1348 - val_loss: 0.1187\n",
      "Epoch 377/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1201 - val_loss: 0.1647\n",
      "Epoch 378/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0970 - val_loss: 0.0524\n",
      "Epoch 379/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0630 - val_loss: 0.0356\n",
      "Epoch 380/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0754 - val_loss: 0.0468\n",
      "Epoch 381/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1324 - val_loss: 0.2395\n",
      "Epoch 382/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.2023 - val_loss: 1.6190\n",
      "Epoch 383/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.7010 - val_loss: 0.1877\n",
      "Epoch 384/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5596 - val_loss: 0.1081\n",
      "Epoch 385/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1405 - val_loss: 0.1858\n",
      "Epoch 386/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2792 - val_loss: 0.1180\n",
      "Epoch 387/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0802 - val_loss: 0.1060\n",
      "Epoch 388/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1035 - val_loss: 0.1096\n",
      "Epoch 389/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1231 - val_loss: 0.0657\n",
      "Epoch 390/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0776 - val_loss: 0.0572\n",
      "Epoch 391/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0515 - val_loss: 0.0507\n",
      "Epoch 392/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0400 - val_loss: 0.0245\n",
      "Epoch 393/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0430 - val_loss: 0.0763\n",
      "Epoch 394/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0478 - val_loss: 0.0610\n",
      "Epoch 395/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0572 - val_loss: 0.0765\n",
      "Epoch 396/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0540 - val_loss: 0.0555\n",
      "Epoch 397/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0492 - val_loss: 0.1716\n",
      "Epoch 398/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1605 - val_loss: 0.2552\n",
      "Epoch 399/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1278 - val_loss: 0.1547\n",
      "Epoch 400/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0835 - val_loss: 0.0581\n",
      "Epoch 401/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1137 - val_loss: 0.0591\n",
      "Epoch 402/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0509 - val_loss: 0.0412\n",
      "Epoch 403/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1134 - val_loss: 0.0874\n",
      "Epoch 404/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1074 - val_loss: 0.0774\n",
      "Epoch 405/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0685 - val_loss: 0.0691\n",
      "Epoch 406/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0409 - val_loss: 0.0308\n",
      "Epoch 407/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0737 - val_loss: 0.0249\n",
      "Epoch 408/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2036 - val_loss: 0.1786\n",
      "Epoch 409/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.6029 - val_loss: 0.1828\n",
      "Epoch 410/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8452 - val_loss: 1.2583\n",
      "Epoch 411/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3445 - val_loss: 0.2314\n",
      "Epoch 412/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.2481 - val_loss: 0.1793\n",
      "Epoch 413/500\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.2220 - val_loss: 0.2986\n",
      "Epoch 414/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2248 - val_loss: 0.1209\n",
      "Epoch 415/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0779 - val_loss: 0.0673\n",
      "Epoch 416/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0905 - val_loss: 0.1119\n",
      "Epoch 417/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1004 - val_loss: 0.0667\n",
      "Epoch 418/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1188 - val_loss: 0.2407\n",
      "Epoch 419/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2481 - val_loss: 0.3380\n",
      "Epoch 420/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1737 - val_loss: 0.1288\n",
      "Epoch 421/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0639 - val_loss: 0.0310\n",
      "Epoch 422/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0344 - val_loss: 0.2168\n",
      "Epoch 423/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1329 - val_loss: 0.4298\n",
      "Epoch 424/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3286 - val_loss: 0.4603\n",
      "Epoch 425/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.4697 - val_loss: 0.2796\n",
      "Epoch 426/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.3175 - val_loss: 0.3520\n",
      "Epoch 427/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2627 - val_loss: 0.2697\n",
      "Epoch 428/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1953 - val_loss: 0.1822\n",
      "Epoch 429/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1940 - val_loss: 0.1574\n",
      "Epoch 430/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5957 - val_loss: 0.6451\n",
      "Epoch 431/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2573 - val_loss: 0.1904\n",
      "Epoch 432/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1133 - val_loss: 0.0837\n",
      "Epoch 433/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0941 - val_loss: 0.0732\n",
      "Epoch 434/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1021 - val_loss: 0.0651\n",
      "Epoch 435/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0571 - val_loss: 0.0537\n",
      "Epoch 436/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0862 - val_loss: 0.0313\n",
      "Epoch 437/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0680 - val_loss: 0.0826\n",
      "Epoch 438/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1336 - val_loss: 0.1977\n",
      "Epoch 439/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1178 - val_loss: 0.2332\n",
      "Epoch 440/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0812 - val_loss: 0.0688\n",
      "Epoch 441/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.2584 - val_loss: 0.1471\n",
      "Epoch 442/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.2189 - val_loss: 0.0566\n",
      "Epoch 443/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2582 - val_loss: 0.4021\n",
      "Epoch 444/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2568 - val_loss: 0.0801\n",
      "Epoch 445/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0561 - val_loss: 0.0700\n",
      "Epoch 446/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0968 - val_loss: 0.1304\n",
      "Epoch 447/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2072 - val_loss: 0.1968\n",
      "Epoch 448/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1894 - val_loss: 0.1440\n",
      "Epoch 449/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1714 - val_loss: 0.1515\n",
      "Epoch 450/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3879 - val_loss: 0.0765\n",
      "Epoch 451/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.5144 - val_loss: 0.2993\n",
      "Epoch 452/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2788 - val_loss: 0.2994\n",
      "Epoch 453/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2053 - val_loss: 0.2802\n",
      "Epoch 454/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0887 - val_loss: 0.1652\n",
      "Epoch 455/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1024 - val_loss: 0.0907\n",
      "Epoch 456/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1158 - val_loss: 0.0998\n",
      "Epoch 457/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1556 - val_loss: 0.0702\n",
      "Epoch 458/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0585 - val_loss: 0.0361\n",
      "Epoch 459/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0747 - val_loss: 0.1673\n",
      "Epoch 460/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2463 - val_loss: 0.1485\n",
      "Epoch 461/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1853 - val_loss: 0.1200\n",
      "Epoch 462/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0804 - val_loss: 0.2144\n",
      "Epoch 463/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4126 - val_loss: 0.2429\n",
      "Epoch 464/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3797 - val_loss: 0.3010\n",
      "Epoch 465/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1503 - val_loss: 0.1584\n",
      "Epoch 466/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0986 - val_loss: 0.0654\n",
      "Epoch 467/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0553 - val_loss: 0.0750\n",
      "Epoch 468/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2794 - val_loss: 0.2152\n",
      "Epoch 469/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6704 - val_loss: 0.8783\n",
      "Epoch 470/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6419 - val_loss: 0.6475\n",
      "Epoch 471/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.7983 - val_loss: 1.4723\n",
      "Epoch 472/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.8107 - val_loss: 0.6080\n",
      "Epoch 473/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.0543 - val_loss: 0.4582\n",
      "Epoch 474/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2141 - val_loss: 0.1674\n",
      "Epoch 475/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1310 - val_loss: 0.2044\n",
      "Epoch 476/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0600 - val_loss: 0.1025\n",
      "Epoch 477/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0679 - val_loss: 0.0326\n",
      "Epoch 478/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0530 - val_loss: 0.0359\n",
      "Epoch 479/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0434 - val_loss: 0.1280\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0685 - val_loss: 0.0382\n",
      "Epoch 481/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1330 - val_loss: 0.1364\n",
      "Epoch 482/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1680 - val_loss: 0.3017\n",
      "Epoch 483/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3841 - val_loss: 0.6498\n",
      "Epoch 484/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2497 - val_loss: 0.0738\n",
      "Epoch 485/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0573 - val_loss: 0.0639\n",
      "Epoch 486/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0570 - val_loss: 0.1212\n",
      "Epoch 487/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0501 - val_loss: 0.0747\n",
      "Epoch 488/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0692 - val_loss: 0.0920\n",
      "Epoch 489/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1738 - val_loss: 0.1104\n",
      "Epoch 490/500\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0628 - val_loss: 0.0582\n",
      "Epoch 491/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0481 - val_loss: 0.1248\n",
      "Epoch 492/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0774 - val_loss: 0.0338\n",
      "Epoch 493/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2116 - val_loss: 0.1165\n",
      "Epoch 494/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1363 - val_loss: 0.1144\n",
      "Epoch 495/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0680 - val_loss: 0.0413\n",
      "Epoch 496/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0636 - val_loss: 0.0732\n",
      "Epoch 497/500\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2771 - val_loss: 0.2846\n",
      "Epoch 498/500\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2493 - val_loss: 0.1154\n",
      "Epoch 499/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1070 - val_loss: 0.0610\n",
      "Epoch 500/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0572 - val_loss: 0.0663\n",
      "MAE: 0.09680505540635849\n",
      "SMAPE: 0.07619993198594709\n",
      "RMSE: 0.1585471685632907\n",
      "R2 Score: 0.9996702364498141\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Defining the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Defining the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Defining the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Defining the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data for teacher forcing\n",
    "encoder_input_train = train_data.values[:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[1:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing  decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[1:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[1:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "encoder_input_test = test_data.values[:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[1:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[1:, :, np.newaxis]\n",
    "\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8ed1f",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa637036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 4s 123ms/step - loss: 14537.5674 - val_loss: 15664.4531\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 13805.7783 - val_loss: 14981.5488\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 13031.9961 - val_loss: 14007.0361\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 11990.5732 - val_loss: 12841.9805\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 10903.9463 - val_loss: 11705.5371\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 9898.7148 - val_loss: 10778.2666\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 9166.9111 - val_loss: 10072.5693\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 8497.1631 - val_loss: 9342.4102\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 7823.1128 - val_loss: 8643.1543\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 7151.3506 - val_loss: 7857.2534\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 6432.1392 - val_loss: 7165.4941\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 5843.4932 - val_loss: 6557.8799\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 5315.2671 - val_loss: 6025.9795\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 4860.7432 - val_loss: 5554.5679\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 4427.1367 - val_loss: 5102.2744\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 4035.3276 - val_loss: 4694.7754\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 3680.5361 - val_loss: 4313.2168\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 3351.0620 - val_loss: 3965.3711\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 3051.8542 - val_loss: 3651.7607\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 2784.5459 - val_loss: 3367.6460\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2542.8945 - val_loss: 3105.1951\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 2321.9531 - val_loss: 2870.8640\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 2126.4077 - val_loss: 2652.7080\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1945.2452 - val_loss: 2458.7146\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1781.2343 - val_loss: 2276.7747\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1629.8236 - val_loss: 2108.0122\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1494.1207 - val_loss: 1955.0544\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1369.5693 - val_loss: 1819.5363\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 1263.0096 - val_loss: 1694.4829\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1164.0382 - val_loss: 1581.5947\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1075.9331 - val_loss: 1478.6494\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 997.4761 - val_loss: 1384.1161\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 923.0267 - val_loss: 1299.2745\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 859.3010 - val_loss: 1222.7681\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 802.5376 - val_loss: 1152.3362\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 751.2424 - val_loss: 1087.5402\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 703.4299 - val_loss: 1031.1323\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 664.4651 - val_loss: 977.7528\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 626.9239 - val_loss: 930.9212\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 594.5208 - val_loss: 888.7106\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 565.2141 - val_loss: 851.6745\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 542.9172 - val_loss: 814.8186\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 518.4252 - val_loss: 784.3044\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 499.0251 - val_loss: 756.7200\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 482.3188 - val_loss: 731.3798\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 467.5887 - val_loss: 708.2229\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 454.2511 - val_loss: 687.7507\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 443.2470 - val_loss: 668.5356\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 432.5946 - val_loss: 652.2343\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 423.5319 - val_loss: 637.7468\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 416.3716 - val_loss: 624.1667\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 409.8292 - val_loss: 611.7385\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 403.8620 - val_loss: 600.5685\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 398.0282 - val_loss: 590.9636\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 393.9977 - val_loss: 581.9630\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 390.0345 - val_loss: 573.6707\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 386.6760 - val_loss: 566.1251\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 383.7189 - val_loss: 559.5521\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 380.9108 - val_loss: 553.8350\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 379.0490 - val_loss: 548.0972\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 376.9225 - val_loss: 543.0728\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 375.0374 - val_loss: 539.4382\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 373.5941 - val_loss: 535.1912\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 372.3977 - val_loss: 531.1747\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 371.0152 - val_loss: 527.9745\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 370.1050 - val_loss: 524.3116\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 369.0252 - val_loss: 522.2545\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 368.2697 - val_loss: 518.9749\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 367.4645 - val_loss: 516.5444\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 366.9807 - val_loss: 513.5085\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 365.9781 - val_loss: 512.2905\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 365.5962 - val_loss: 510.2914\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 364.8361 - val_loss: 508.6075\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 364.2884 - val_loss: 507.5819\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 363.7986 - val_loss: 506.0136\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 363.3891 - val_loss: 504.1450\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 362.8816 - val_loss: 502.7450\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 362.4308 - val_loss: 501.7783\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 362.1544 - val_loss: 499.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 361.4783 - val_loss: 499.2924\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 361.0911 - val_loss: 498.5841\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 360.6901 - val_loss: 497.8804\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 360.3570 - val_loss: 496.5608\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 359.9185 - val_loss: 495.6477\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 359.5571 - val_loss: 494.8942\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 359.2963 - val_loss: 493.6799\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 358.8142 - val_loss: 492.9626\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 358.4133 - val_loss: 492.5100\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 358.1062 - val_loss: 491.9922\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 357.7655 - val_loss: 491.9622\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 357.5504 - val_loss: 492.0783\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 357.0703 - val_loss: 491.3818\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 356.6953 - val_loss: 490.7317\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 356.3037 - val_loss: 489.7738\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 356.0135 - val_loss: 489.3832\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 355.6803 - val_loss: 488.3288\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 355.3335 - val_loss: 487.7723\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 355.1382 - val_loss: 486.6067\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 354.6508 - val_loss: 486.6612\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 354.4577 - val_loss: 485.7891\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 354.0492 - val_loss: 485.2778\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 353.7847 - val_loss: 485.8045\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 353.3572 - val_loss: 485.5679\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 353.1494 - val_loss: 484.3829\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 352.6734 - val_loss: 484.1953\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 352.3436 - val_loss: 483.8502\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 352.0811 - val_loss: 484.0138\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 351.9063 - val_loss: 482.8015\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 351.5096 - val_loss: 483.1630\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 351.0942 - val_loss: 482.7771\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 350.9274 - val_loss: 481.5408\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 350.5619 - val_loss: 481.9633\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 350.2227 - val_loss: 481.1283\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 349.8715 - val_loss: 480.9612\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 349.6716 - val_loss: 480.0590\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 349.2946 - val_loss: 480.5426\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 349.0585 - val_loss: 480.4103\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 348.7507 - val_loss: 479.3381\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 348.4037 - val_loss: 478.8695\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 348.0805 - val_loss: 478.3767\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 347.8657 - val_loss: 478.8084\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 347.4516 - val_loss: 478.2828\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 347.2118 - val_loss: 478.1790\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 346.8880 - val_loss: 477.4063\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 346.6250 - val_loss: 476.5028\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 346.2885 - val_loss: 476.0750\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 346.0020 - val_loss: 475.7840\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 345.7979 - val_loss: 474.9478\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 345.3695 - val_loss: 475.1993\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 345.3223 - val_loss: 474.4304\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 344.9718 - val_loss: 475.3781\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 344.7070 - val_loss: 474.4266\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 344.6265 - val_loss: 475.5894\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 344.0494 - val_loss: 474.0060\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 343.9561 - val_loss: 472.5806\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 343.4383 - val_loss: 473.1495\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 343.2191 - val_loss: 473.4226\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 342.9103 - val_loss: 473.5407\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 342.5420 - val_loss: 472.8492\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 342.3204 - val_loss: 472.0779\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 342.0067 - val_loss: 471.6674\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 341.7538 - val_loss: 471.6496\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 341.5077 - val_loss: 471.3280\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 341.2972 - val_loss: 470.1642\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 341.2120 - val_loss: 471.1344\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 340.7307 - val_loss: 470.7736\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 340.9150 - val_loss: 468.3849\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 340.4723 - val_loss: 469.4637\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 339.8408 - val_loss: 468.9790\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 339.6490 - val_loss: 468.3066\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 339.2430 - val_loss: 467.9420\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 339.1183 - val_loss: 467.6035\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 338.7882 - val_loss: 467.2501\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 339.0243 - val_loss: 465.7241\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 338.3850 - val_loss: 467.1208\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 338.3901 - val_loss: 468.3059\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 337.8110 - val_loss: 467.1848\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 337.4237 - val_loss: 466.2791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 337.1681 - val_loss: 465.9205\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 337.0658 - val_loss: 464.7621\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 336.6034 - val_loss: 464.8698\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 336.5102 - val_loss: 464.8062\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 336.3687 - val_loss: 463.8401\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 335.8602 - val_loss: 464.2954\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 335.7286 - val_loss: 463.2987\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 335.4373 - val_loss: 464.2143\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 335.0998 - val_loss: 463.4153\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 334.9868 - val_loss: 462.6095\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 334.6470 - val_loss: 461.9214\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 334.3341 - val_loss: 462.9081\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 334.1133 - val_loss: 463.4747\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 333.8146 - val_loss: 462.4673\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 333.5509 - val_loss: 461.7129\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 333.4027 - val_loss: 460.8059\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 333.1228 - val_loss: 461.6956\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 332.7720 - val_loss: 461.3424\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 332.7380 - val_loss: 460.0596\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 332.2354 - val_loss: 460.0687\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 332.0170 - val_loss: 459.6070\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 331.7821 - val_loss: 460.1233\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 331.4982 - val_loss: 459.4601\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 331.4734 - val_loss: 460.3929\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 331.1353 - val_loss: 460.1658\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 330.7454 - val_loss: 459.0949\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 330.4825 - val_loss: 458.4499\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 330.2670 - val_loss: 457.9233\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 330.0214 - val_loss: 457.4212\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 329.7817 - val_loss: 456.5133\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 329.4814 - val_loss: 456.4712\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 329.2365 - val_loss: 456.3495\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 329.0106 - val_loss: 455.8788\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 328.8522 - val_loss: 455.4643\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 328.5867 - val_loss: 454.6545\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 328.2284 - val_loss: 455.3206\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 327.9109 - val_loss: 455.0424\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 328.5574 - val_loss: 459.4380\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 326.4510 - val_loss: 454.1276\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 324.6977 - val_loss: 452.8759\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 323.7927 - val_loss: 450.4260\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 322.5333 - val_loss: 449.6822\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 321.7252 - val_loss: 449.6997\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 320.2560 - val_loss: 445.9851\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 319.7342 - val_loss: 447.4488\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 317.4507 - val_loss: 443.2305\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 314.8090 - val_loss: 441.6923\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 312.1818 - val_loss: 436.5168\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 309.4274 - val_loss: 445.8769\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 307.0157 - val_loss: 430.6986\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 307.0960 - val_loss: 426.8546\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 303.6528 - val_loss: 425.4749\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 301.2047 - val_loss: 421.9539\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 298.0716 - val_loss: 418.8563\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 293.7366 - val_loss: 412.2120\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 284.2902 - val_loss: 403.6814\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 264.9307 - val_loss: 373.4310\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 253.5707 - val_loss: 396.1052\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 246.9555 - val_loss: 339.8078\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 228.4992 - val_loss: 323.5084\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 214.8654 - val_loss: 304.9617\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 203.0073 - val_loss: 288.8807\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 193.6744 - val_loss: 273.0081\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 187.5510 - val_loss: 266.5160\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 180.8372 - val_loss: 253.3820\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 176.9078 - val_loss: 252.3368\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 182.5274 - val_loss: 245.6999\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 173.2761 - val_loss: 241.9979\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 166.9977 - val_loss: 232.7791\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 166.4194 - val_loss: 220.6806\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 160.4617 - val_loss: 211.8323\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 155.9995 - val_loss: 209.5832\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 152.5962 - val_loss: 203.8771\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 148.3002 - val_loss: 204.9048\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 144.2166 - val_loss: 196.7117\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 140.1625 - val_loss: 191.2029\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 137.0148 - val_loss: 192.7775\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 148.8550 - val_loss: 198.9030\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 140.3510 - val_loss: 182.6976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 138.6001 - val_loss: 186.7475\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 137.3401 - val_loss: 173.8170\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 134.3318 - val_loss: 183.4373\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 120.9037 - val_loss: 173.8679\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 118.5167 - val_loss: 167.4644\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 113.3227 - val_loss: 162.3547\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 110.3264 - val_loss: 157.8403\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 108.0782 - val_loss: 156.6033\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 107.0516 - val_loss: 152.8843\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 104.3431 - val_loss: 165.8058\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 105.3791 - val_loss: 148.3995\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 101.6310 - val_loss: 145.5563\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 98.6824 - val_loss: 143.1579\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 98.6300 - val_loss: 143.5897\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 100.9349 - val_loss: 145.5999\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 99.3748 - val_loss: 143.0483\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 96.0646 - val_loss: 138.4476\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 95.3612 - val_loss: 135.9466\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 95.8777 - val_loss: 133.9710\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 93.4717 - val_loss: 133.0014\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 92.1060 - val_loss: 132.3452\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 89.3769 - val_loss: 127.8130\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 86.8982 - val_loss: 124.8595\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 86.0586 - val_loss: 122.9500\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 85.6787 - val_loss: 121.4569\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 85.6198 - val_loss: 126.8859\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 106.6217 - val_loss: 129.4565\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 90.7493 - val_loss: 118.6884\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 86.0759 - val_loss: 114.9566\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 82.3744 - val_loss: 114.3404\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 80.0621 - val_loss: 112.9164\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 78.9328 - val_loss: 110.8371\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 76.8665 - val_loss: 109.7912\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 74.9992 - val_loss: 106.4077\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 73.9936 - val_loss: 105.7995\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 74.0954 - val_loss: 104.7392\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 72.3623 - val_loss: 102.1443\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 70.8462 - val_loss: 101.1265\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 70.4295 - val_loss: 98.8610\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 68.9418 - val_loss: 97.6900\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 69.0879 - val_loss: 101.4507\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 72.0268 - val_loss: 94.7002\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 68.4165 - val_loss: 94.3657\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 65.4179 - val_loss: 91.8774\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 64.3163 - val_loss: 94.1527\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 64.6737 - val_loss: 90.5459\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 66.6940 - val_loss: 88.6622\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 65.4971 - val_loss: 89.8093\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 64.0023 - val_loss: 86.3609\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 62.7262 - val_loss: 86.2135\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 61.0311 - val_loss: 83.7034\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 60.3557 - val_loss: 83.6621\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 59.1341 - val_loss: 80.4532\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 58.4968 - val_loss: 79.2653\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 57.0882 - val_loss: 80.6075\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 56.1386 - val_loss: 79.8498\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 57.3483 - val_loss: 78.4191\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 54.9551 - val_loss: 76.2666\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 54.0562 - val_loss: 73.9530\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 53.4483 - val_loss: 74.5695\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 55.6277 - val_loss: 74.9128\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 60.1086 - val_loss: 75.0917\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 53.5958 - val_loss: 71.6172\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 62.0475 - val_loss: 89.8425\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 60.1155 - val_loss: 72.0426\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 56.9405 - val_loss: 69.1675\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 55.5106 - val_loss: 74.9967\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 54.7462 - val_loss: 68.5676\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 52.7739 - val_loss: 67.7422\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 51.2655 - val_loss: 66.8366\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 50.6210 - val_loss: 66.4208\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 49.7907 - val_loss: 67.2709\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 49.4121 - val_loss: 66.0214\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 48.8961 - val_loss: 67.4592\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 49.0284 - val_loss: 63.4837\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 47.4107 - val_loss: 67.3493\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 46.8634 - val_loss: 61.7956\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 45.6761 - val_loss: 62.2476\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 44.8254 - val_loss: 59.8053\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 44.1594 - val_loss: 59.0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 43.3078 - val_loss: 59.1630\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 43.0632 - val_loss: 58.3888\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 43.7200 - val_loss: 56.9488\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 42.5547 - val_loss: 56.9519\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 42.5649 - val_loss: 57.2430\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 44.3412 - val_loss: 56.5157\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 46.1100 - val_loss: 53.9785\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 45.1477 - val_loss: 53.9582\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 43.8439 - val_loss: 56.2714\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 44.3363 - val_loss: 53.9670\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 44.1826 - val_loss: 52.7027\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 42.0607 - val_loss: 52.9198\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 41.1002 - val_loss: 51.0600\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 40.2039 - val_loss: 49.9161\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 39.5922 - val_loss: 49.5793\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 42.1563 - val_loss: 54.8098\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 43.4257 - val_loss: 52.6230\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 43.6955 - val_loss: 48.8475\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 39.7903 - val_loss: 48.7367\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 38.1067 - val_loss: 47.0456\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 38.1681 - val_loss: 47.6799\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 37.4398 - val_loss: 46.8843\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 37.1329 - val_loss: 46.6587\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 35.9953 - val_loss: 45.8511\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 35.6506 - val_loss: 45.1708\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 34.8828 - val_loss: 44.8548\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 34.4313 - val_loss: 43.7934\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 34.0032 - val_loss: 43.4385\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 33.4126 - val_loss: 43.2220\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 33.5218 - val_loss: 42.8111\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 35.1644 - val_loss: 42.2488\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 36.6520 - val_loss: 42.9443\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 37.1288 - val_loss: 43.1879\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 37.8476 - val_loss: 40.5520\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 36.7690 - val_loss: 43.2471\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 36.3415 - val_loss: 43.2373\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 35.6159 - val_loss: 40.2629\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 33.2227 - val_loss: 40.3677\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 32.6912 - val_loss: 40.8663\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 32.2905 - val_loss: 39.7368\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 32.3618 - val_loss: 38.3394\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 32.2756 - val_loss: 41.7596\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 32.0093 - val_loss: 38.4639\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 31.1604 - val_loss: 36.4452\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 31.1209 - val_loss: 36.8220\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 30.4782 - val_loss: 36.5870\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 30.6256 - val_loss: 35.6930\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 30.4430 - val_loss: 39.2002\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 32.5367 - val_loss: 36.9627\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 31.3570 - val_loss: 35.7728\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 35.4633 - val_loss: 37.6621\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 35.9131 - val_loss: 34.5978\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 35.8332 - val_loss: 38.0441\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 34.7223 - val_loss: 35.8834\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 33.6409 - val_loss: 37.0625\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 32.6802 - val_loss: 33.6979\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 31.6612 - val_loss: 34.3449\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 31.0492 - val_loss: 33.1809\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 29.9506 - val_loss: 33.3653\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 29.4591 - val_loss: 33.3785\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 29.1867 - val_loss: 33.0033\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 28.7637 - val_loss: 32.0449\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 28.6092 - val_loss: 32.0468\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 28.4131 - val_loss: 32.3562\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 27.9720 - val_loss: 31.8371\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 27.3869 - val_loss: 31.1203\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 26.7726 - val_loss: 31.3807\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 26.6396 - val_loss: 30.2361\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 26.3046 - val_loss: 30.0286\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 26.6990 - val_loss: 29.0146\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 28.5652 - val_loss: 32.1224\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 28.5070 - val_loss: 28.6499\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 26.8798 - val_loss: 28.5894\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 25.2311 - val_loss: 28.2436\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 24.6202 - val_loss: 27.7436\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 24.3369 - val_loss: 27.4716\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 24.2486 - val_loss: 26.9350\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 23.9867 - val_loss: 27.0584\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 23.8476 - val_loss: 27.2096\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 25.4608 - val_loss: 27.2894\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 24ms/step - loss: 25.7138 - val_loss: 26.4841\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 24.3592 - val_loss: 25.4521\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 23.5760 - val_loss: 25.7413\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 24.0308 - val_loss: 26.2062\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 27.0431 - val_loss: 25.2832\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 26.2895 - val_loss: 25.4272\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 23.2737 - val_loss: 25.3869\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 24.8366 - val_loss: 25.3989\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 22.8150 - val_loss: 24.5504\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 25.5637 - val_loss: 25.6203\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 23.1081 - val_loss: 25.1010\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 24.6916 - val_loss: 24.2628\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 21.8616 - val_loss: 23.3854\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 26.4167 - val_loss: 23.7905\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 25.7782 - val_loss: 25.2898\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 22.5534 - val_loss: 22.9905\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 21.8465 - val_loss: 23.8874\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 21.6650 - val_loss: 24.0111\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 21.6151 - val_loss: 23.2456\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 20.7985 - val_loss: 22.6058\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 20.4663 - val_loss: 21.8228\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 19.9819 - val_loss: 21.5402\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 20.1498 - val_loss: 23.7003\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 20.1908 - val_loss: 21.3555\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 19.7795 - val_loss: 20.8720\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 19.8230 - val_loss: 20.7470\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 20.2483 - val_loss: 21.1045\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 19.7284 - val_loss: 21.0881\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 19.6336 - val_loss: 20.1958\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 25.7801 - val_loss: 23.5473\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 27.7487 - val_loss: 32.3049\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 26.3901 - val_loss: 20.4956\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 22.3280 - val_loss: 20.4674\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 21.3489 - val_loss: 19.8688\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 19.6508 - val_loss: 20.1392\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 19.1540 - val_loss: 20.1002\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 18.8242 - val_loss: 19.8487\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 18.5913 - val_loss: 19.8439\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 18.4847 - val_loss: 19.4676\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 18.3828 - val_loss: 19.3555\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 18.0034 - val_loss: 19.3296\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 18.1338 - val_loss: 19.6442\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 18.2314 - val_loss: 19.5276\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 18.3532 - val_loss: 18.8040\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 18.7009 - val_loss: 19.0471\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 18.3375 - val_loss: 19.8459\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 17.6844 - val_loss: 18.8477\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 17.7767 - val_loss: 17.6460\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 17.8521 - val_loss: 22.0671\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 18.9586 - val_loss: 18.0146\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 18.0087 - val_loss: 23.1635\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 18.2657 - val_loss: 19.9146\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 17.8794 - val_loss: 17.2383\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 17.7989 - val_loss: 17.9683\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 18.7139 - val_loss: 18.6794\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 19.6999 - val_loss: 18.3398\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 16.4257 - val_loss: 16.5726\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 15.7492 - val_loss: 16.0247\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 15.3607 - val_loss: 15.4590\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 14.8528 - val_loss: 14.7053\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 14.6713 - val_loss: 13.8610\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 14.0295 - val_loss: 14.6227\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 14.2774 - val_loss: 14.9451\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 13.6482 - val_loss: 12.9802\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 13.2951 - val_loss: 13.4158\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 13.1314 - val_loss: 14.3654\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 13.0855 - val_loss: 11.9992\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 12.6472 - val_loss: 12.2559\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 12.4990 - val_loss: 11.9773\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 12.7841 - val_loss: 14.4597\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 12.6274 - val_loss: 13.1051\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 13.0968 - val_loss: 11.2268\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 12.2322 - val_loss: 10.7175\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 11.7957 - val_loss: 11.6332\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 12.4178 - val_loss: 10.7835\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 12.1204 - val_loss: 10.8867\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 11.7982 - val_loss: 10.7340\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 11.6632 - val_loss: 10.9909\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 11.4741 - val_loss: 10.6423\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 11.5698 - val_loss: 10.6801\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 23ms/step - loss: 12.0959 - val_loss: 10.5082\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 10.8151 - val_loss: 9.4179\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 14.9020 - val_loss: 16.4785\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 14.6089 - val_loss: 10.2770\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 14.8196 - val_loss: 9.5598\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 12.3183 - val_loss: 9.6030\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 15.7922 - val_loss: 32.1884\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 21.4696 - val_loss: 43.6788\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 18.3678 - val_loss: 12.8005\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 16.3821 - val_loss: 15.6368\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 12.5961 - val_loss: 10.1914\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 11.8724 - val_loss: 9.4049\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 11.2610 - val_loss: 9.8835\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 11.3011 - val_loss: 10.8788\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 11.2583 - val_loss: 8.9459\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 10.4581 - val_loss: 8.8786\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 10.0737 - val_loss: 9.4569\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 10.0889 - val_loss: 8.6263\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 9.5182 - val_loss: 9.2314\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 10.2024 - val_loss: 8.8125\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 9.9977 - val_loss: 8.2676\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 9.4173 - val_loss: 8.0086\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 8.9613 - val_loss: 8.1667\n",
      "MAE: 1.1992427684642648\n",
      "SMAPE: 0.9246361198616796\n",
      "RMSE: 2.3193596560247154\n",
      "R2 Score: 0.9489921351194927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 36 data points for the rolling window\n",
    "window_size = 36\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e17728",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc90a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 4s 173ms/step - loss: 15885.2158 - val_loss: 15389.9814\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 15415.0938 - val_loss: 14946.1299\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 14961.0869 - val_loss: 14473.5029\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 14472.9424 - val_loss: 13998.4766\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13970.3115 - val_loss: 13436.9482\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 13341.3232 - val_loss: 12739.0039\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 12612.4912 - val_loss: 12040.2139\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 11937.7217 - val_loss: 11386.4854\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 11284.5938 - val_loss: 10765.8535\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 10701.7080 - val_loss: 10252.0254\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 10205.7822 - val_loss: 9776.3545\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9722.5518 - val_loss: 9277.6377\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9222.4814 - val_loss: 8791.7637\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8733.8018 - val_loss: 8309.2871\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8257.2041 - val_loss: 7845.7026\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7783.6372 - val_loss: 7386.5708\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7333.1431 - val_loss: 6945.4907\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6900.3530 - val_loss: 6543.5591\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6517.9429 - val_loss: 6179.8945\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6166.9585 - val_loss: 5860.7578\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5843.0293 - val_loss: 5543.2114\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5525.9902 - val_loss: 5245.5977\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5237.9331 - val_loss: 4972.3398\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4968.4277 - val_loss: 4713.7124\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4714.3330 - val_loss: 4470.7275\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4469.0039 - val_loss: 4226.4678\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4226.6675 - val_loss: 4002.5095\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4005.7131 - val_loss: 3794.4670\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3795.1462 - val_loss: 3587.8250\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3590.5710 - val_loss: 3390.1252\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3397.5957 - val_loss: 3212.7869\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3222.3945 - val_loss: 3045.8662\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3053.6863 - val_loss: 2887.9470\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2895.2100 - val_loss: 2734.7000\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2743.5654 - val_loss: 2587.1111\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2597.5916 - val_loss: 2452.0159\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2459.5891 - val_loss: 2323.4971\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2334.4343 - val_loss: 2202.9856\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2215.3884 - val_loss: 2083.9155\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2095.5515 - val_loss: 1970.8612\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1981.9694 - val_loss: 1872.2617\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1884.2584 - val_loss: 1778.4323\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1790.4943 - val_loss: 1690.2692\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1702.0038 - val_loss: 1607.1783\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1620.0665 - val_loss: 1527.9269\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1539.7101 - val_loss: 1453.6283\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1465.8490 - val_loss: 1382.5094\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1393.3107 - val_loss: 1316.7957\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1327.2554 - val_loss: 1255.5411\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1266.0886 - val_loss: 1197.9510\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1207.5554 - val_loss: 1144.4227\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1153.0424 - val_loss: 1094.4911\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1103.3214 - val_loss: 1047.2659\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1055.9590 - val_loss: 1003.0349\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1011.2485 - val_loss: 961.8591\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 971.2933 - val_loss: 922.6523\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 929.5014 - val_loss: 887.5519\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 893.5424 - val_loss: 854.6504\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 860.4982 - val_loss: 823.5303\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 828.4585 - val_loss: 794.7473\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 800.4019 - val_loss: 767.2385\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 771.0840 - val_loss: 742.5663\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 745.1941 - val_loss: 719.5173\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 721.7281 - val_loss: 695.7696\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 698.4055 - val_loss: 674.4356\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 676.9767 - val_loss: 655.0831\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 655.5659 - val_loss: 638.1375\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 637.6841 - val_loss: 622.3969\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 621.5270 - val_loss: 607.6047\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 606.7847 - val_loss: 593.6635\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 592.6870 - val_loss: 580.8220\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 578.6591 - val_loss: 569.4512\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 567.3607 - val_loss: 558.6465\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 555.9961 - val_loss: 548.8827\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 545.4504 - val_loss: 540.0801\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 535.1011 - val_loss: 532.4954\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 527.5999 - val_loss: 524.9554\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 519.6852 - val_loss: 518.0564\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 19ms/step - loss: 512.1503 - val_loss: 511.8359\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 504.8594 - val_loss: 506.4396\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 499.0117 - val_loss: 501.3316\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 493.6909 - val_loss: 496.4959\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 488.7753 - val_loss: 491.9887\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 483.5593 - val_loss: 488.0793\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 479.7832 - val_loss: 484.3220\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 475.2044 - val_loss: 481.1628\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 471.5077 - val_loss: 478.3473\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 468.2712 - val_loss: 475.7661\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 465.4491 - val_loss: 473.3617\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 462.6301 - val_loss: 471.2064\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 459.8776 - val_loss: 469.4547\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 458.0188 - val_loss: 467.6249\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 455.6709 - val_loss: 466.0684\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 453.7860 - val_loss: 464.6741\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 452.0597 - val_loss: 463.4155\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 450.3857 - val_loss: 462.2253\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 448.7146 - val_loss: 460.9500\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 447.3744 - val_loss: 459.9522\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 445.8023 - val_loss: 459.2209\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 444.9066 - val_loss: 458.5039\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 443.9857 - val_loss: 457.8593\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 442.9286 - val_loss: 457.3412\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 442.3347 - val_loss: 456.8379\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 441.4419 - val_loss: 456.4615\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 440.8315 - val_loss: 456.1106\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 440.6339 - val_loss: 455.7284\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 439.6859 - val_loss: 455.4604\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 439.5299 - val_loss: 455.1768\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 438.8892 - val_loss: 454.9612\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 438.4586 - val_loss: 454.7777\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 438.4000 - val_loss: 454.5961\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 437.8920 - val_loss: 454.4441\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 437.5112 - val_loss: 454.3132\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 437.3971 - val_loss: 454.1922\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 437.0434 - val_loss: 454.0913\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 436.8750 - val_loss: 453.9966\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 436.6394 - val_loss: 453.9078\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 436.4347 - val_loss: 453.8160\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 436.2305 - val_loss: 453.7386\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 436.0872 - val_loss: 453.6726\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 435.8855 - val_loss: 453.5817\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 435.8856 - val_loss: 453.5319\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 435.5894 - val_loss: 453.4460\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 435.4666 - val_loss: 453.3773\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 435.3175 - val_loss: 453.3187\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 435.1803 - val_loss: 453.2556\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 435.0632 - val_loss: 453.1754\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 434.9663 - val_loss: 453.0907\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 434.9791 - val_loss: 453.0748\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 434.7985 - val_loss: 452.9625\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 434.6637 - val_loss: 452.9289\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 434.6057 - val_loss: 452.8868\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 434.3894 - val_loss: 452.7745\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 434.2659 - val_loss: 452.6925\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 434.2831 - val_loss: 452.6753\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 434.0504 - val_loss: 452.5617\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 434.0272 - val_loss: 452.4500\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 433.9149 - val_loss: 452.4090\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 433.7594 - val_loss: 452.3175\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 433.7850 - val_loss: 452.1765\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 433.5835 - val_loss: 452.1394\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 433.5038 - val_loss: 452.0168\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 433.3816 - val_loss: 451.9431\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 433.2901 - val_loss: 451.8403\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 433.1789 - val_loss: 451.7771\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 433.0684 - val_loss: 451.6740\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 432.9482 - val_loss: 451.5892\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 432.8737 - val_loss: 451.4898\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 432.7955 - val_loss: 451.4044\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 432.6655 - val_loss: 451.3069\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 432.7344 - val_loss: 451.1556\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 432.5655 - val_loss: 451.1579\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 432.3904 - val_loss: 451.0840\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 432.4597 - val_loss: 450.8926\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 432.1670 - val_loss: 450.8114\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 432.0956 - val_loss: 450.7943\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 432.0056 - val_loss: 450.6243\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 30ms/step - loss: 431.9107 - val_loss: 450.5612\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 431.7451 - val_loss: 450.4558\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 431.7443 - val_loss: 450.4191\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 431.7317 - val_loss: 450.2010\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 431.4500 - val_loss: 450.1223\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 431.3938 - val_loss: 449.9988\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 431.2638 - val_loss: 449.8728\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 431.1354 - val_loss: 449.7787\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 431.1002 - val_loss: 449.7180\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 431.0315 - val_loss: 449.5869\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 430.8458 - val_loss: 449.5010\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 430.7253 - val_loss: 449.4056\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 430.7242 - val_loss: 449.3358\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 430.5608 - val_loss: 449.1737\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 430.4369 - val_loss: 449.0830\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 430.3987 - val_loss: 448.9629\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 430.3003 - val_loss: 448.8878\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 430.1455 - val_loss: 448.7892\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 430.0355 - val_loss: 448.6612\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 429.9289 - val_loss: 448.5304\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 429.8938 - val_loss: 448.4679\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 429.7382 - val_loss: 448.3484\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 429.6925 - val_loss: 448.1988\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 429.6056 - val_loss: 448.1222\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 429.5098 - val_loss: 448.0107\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 429.4204 - val_loss: 447.9336\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 429.2128 - val_loss: 447.7904\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 429.2309 - val_loss: 447.6113\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 429.0560 - val_loss: 447.5282\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 428.9369 - val_loss: 447.3889\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 428.9442 - val_loss: 447.2326\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 428.7104 - val_loss: 447.1459\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 428.6254 - val_loss: 447.0292\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 428.5054 - val_loss: 446.9484\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 428.4052 - val_loss: 446.8548\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 428.3385 - val_loss: 446.7938\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 428.2088 - val_loss: 446.6852\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 428.1230 - val_loss: 446.6033\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 428.0858 - val_loss: 446.4499\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 427.9652 - val_loss: 446.3185\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 427.8565 - val_loss: 446.2556\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 427.7199 - val_loss: 446.1182\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 427.6176 - val_loss: 446.0356\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 427.5837 - val_loss: 445.9572\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 427.4110 - val_loss: 445.8661\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 427.3398 - val_loss: 445.7526\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 427.1952 - val_loss: 445.6382\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 427.2019 - val_loss: 445.4845\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 427.0830 - val_loss: 445.3480\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 426.9554 - val_loss: 445.2215\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 426.9719 - val_loss: 445.1593\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 426.6905 - val_loss: 445.0508\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 426.6292 - val_loss: 444.9251\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 426.5260 - val_loss: 444.7917\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 426.4418 - val_loss: 444.6810\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 426.3575 - val_loss: 444.6232\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 426.5518 - val_loss: 444.4240\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 426.1359 - val_loss: 444.3099\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 425.9867 - val_loss: 444.2227\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 425.9225 - val_loss: 444.1120\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 425.8233 - val_loss: 444.0284\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 425.6985 - val_loss: 443.9740\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 425.5936 - val_loss: 443.8947\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 425.4977 - val_loss: 443.8087\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 425.4144 - val_loss: 443.7260\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 425.3137 - val_loss: 443.6406\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 425.2007 - val_loss: 443.4982\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 425.4256 - val_loss: 443.2422\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 425.0492 - val_loss: 443.1034\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 425.0454 - val_loss: 443.1266\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 424.8376 - val_loss: 442.9606\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 424.7228 - val_loss: 442.8481\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 424.5879 - val_loss: 442.7434\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 424.5089 - val_loss: 442.6778\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 424.3914 - val_loss: 442.5995\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 424.3520 - val_loss: 442.4357\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 424.3373 - val_loss: 442.3964\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 423.9704 - val_loss: 441.4059\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 423.3829 - val_loss: 440.3944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 422.4508 - val_loss: 439.8685\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 421.8055 - val_loss: 438.9493\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 421.0394 - val_loss: 438.4114\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 420.4164 - val_loss: 437.5924\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 419.3920 - val_loss: 435.9545\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 418.6826 - val_loss: 435.1060\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 417.6183 - val_loss: 434.2570\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 416.6212 - val_loss: 432.6689\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 415.4106 - val_loss: 431.4109\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 414.2441 - val_loss: 430.4168\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 413.1242 - val_loss: 427.4431\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 411.1903 - val_loss: 425.1100\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 408.6938 - val_loss: 422.4283\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 405.0319 - val_loss: 417.9705\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 404.5203 - val_loss: 413.1624\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 399.6287 - val_loss: 411.7213\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 396.6774 - val_loss: 406.1015\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 392.9994 - val_loss: 403.5177\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 389.7021 - val_loss: 400.4621\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 387.5844 - val_loss: 398.2563\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 385.6941 - val_loss: 398.2186\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 383.3262 - val_loss: 393.5830\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 380.5912 - val_loss: 391.5375\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 379.5833 - val_loss: 389.6752\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 376.5391 - val_loss: 385.5092\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 374.0235 - val_loss: 383.2791\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 371.6357 - val_loss: 380.4502\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 369.1589 - val_loss: 379.0763\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 368.3958 - val_loss: 376.5010\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 363.7482 - val_loss: 372.9008\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 361.7213 - val_loss: 369.7058\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 359.1752 - val_loss: 367.7327\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 356.4780 - val_loss: 364.5895\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 353.5765 - val_loss: 360.7178\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 350.2247 - val_loss: 355.7362\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 347.7961 - val_loss: 352.6901\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 343.4408 - val_loss: 347.9888\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 340.3840 - val_loss: 345.8064\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 338.8689 - val_loss: 341.8435\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 334.7222 - val_loss: 340.4816\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 330.9021 - val_loss: 335.8710\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 331.0321 - val_loss: 332.3412\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 325.1159 - val_loss: 330.8669\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 324.4444 - val_loss: 325.6980\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 318.8400 - val_loss: 323.5629\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 317.6318 - val_loss: 320.9469\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 313.6301 - val_loss: 317.8626\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 312.3229 - val_loss: 315.8068\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 309.1551 - val_loss: 313.7144\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 307.3048 - val_loss: 311.1059\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 313.5571 - val_loss: 310.3276\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 307.6017 - val_loss: 309.4297\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 301.9511 - val_loss: 305.1004\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 299.3583 - val_loss: 302.7861\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 297.2443 - val_loss: 300.6427\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 294.7100 - val_loss: 299.0430\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 294.9640 - val_loss: 298.2597\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 291.6658 - val_loss: 294.8103\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 290.4989 - val_loss: 292.0796\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 287.3465 - val_loss: 289.4427\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 285.8399 - val_loss: 286.7184\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 280.4741 - val_loss: 274.8322\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 277.6855 - val_loss: 271.8272\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 271.5509 - val_loss: 261.8923\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 264.8153 - val_loss: 250.2251\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 252.7316 - val_loss: 228.3106\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 236.5867 - val_loss: 208.0662\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 224.8932 - val_loss: 198.9965\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 212.6154 - val_loss: 189.4985\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 208.7688 - val_loss: 195.1837\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 209.7215 - val_loss: 193.2346\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 198.7624 - val_loss: 177.7280\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 193.4350 - val_loss: 174.8374\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 188.4884 - val_loss: 171.5392\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 182.8301 - val_loss: 168.2867\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 177.7503 - val_loss: 175.8856\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 176.4352 - val_loss: 158.0552\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 167.3537 - val_loss: 157.0346\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 160.7055 - val_loss: 146.9425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 156.8207 - val_loss: 142.9020\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 151.8590 - val_loss: 138.9809\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 148.1257 - val_loss: 134.6390\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 144.0826 - val_loss: 133.1092\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 140.5637 - val_loss: 126.7041\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 138.6269 - val_loss: 128.6180\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 138.9446 - val_loss: 125.2393\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 133.9482 - val_loss: 123.8968\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 134.2770 - val_loss: 118.3674\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 129.1096 - val_loss: 114.7559\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 126.2044 - val_loss: 115.3274\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 125.6543 - val_loss: 111.3653\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 121.4826 - val_loss: 114.6027\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 124.6568 - val_loss: 107.2484\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 125.8508 - val_loss: 114.3217\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 124.2802 - val_loss: 116.7933\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 121.9394 - val_loss: 103.8438\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 116.1846 - val_loss: 104.7257\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 116.0727 - val_loss: 100.8151\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 115.4866 - val_loss: 101.3696\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 112.9570 - val_loss: 100.2034\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 113.8027 - val_loss: 96.4364\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 110.1038 - val_loss: 96.6309\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 108.6382 - val_loss: 92.7781\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 106.0093 - val_loss: 92.7495\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 104.8163 - val_loss: 89.7604\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 102.8532 - val_loss: 89.1590\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 101.4271 - val_loss: 88.8952\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 100.9794 - val_loss: 86.3813\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 99.5014 - val_loss: 86.4372\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 100.0356 - val_loss: 86.0656\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 97.7816 - val_loss: 83.6994\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 96.0013 - val_loss: 80.7729\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 95.4114 - val_loss: 80.3190\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 95.6901 - val_loss: 78.4727\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 93.6037 - val_loss: 79.6715\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 92.7705 - val_loss: 77.6545\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 91.4370 - val_loss: 77.4904\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 90.8644 - val_loss: 78.9998\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 91.4109 - val_loss: 75.2187\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 88.8290 - val_loss: 73.0832\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 87.2340 - val_loss: 72.5552\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 87.0052 - val_loss: 74.2113\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 87.3447 - val_loss: 71.1498\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 85.1349 - val_loss: 70.1109\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 87.1705 - val_loss: 70.7970\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 88.5262 - val_loss: 73.3790\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 85.3401 - val_loss: 70.1432\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 82.9288 - val_loss: 65.8194\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 81.4213 - val_loss: 65.7136\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 80.2999 - val_loss: 66.6822\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 80.0338 - val_loss: 64.2313\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 78.1187 - val_loss: 62.7323\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 77.7762 - val_loss: 62.4825\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 76.9367 - val_loss: 62.4163\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 75.8390 - val_loss: 59.7021\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 74.7672 - val_loss: 62.2028\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 76.1640 - val_loss: 58.3169\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 74.5121 - val_loss: 58.2219\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 74.0030 - val_loss: 57.3689\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 73.4091 - val_loss: 56.8322\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 73.6283 - val_loss: 59.1774\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 74.8720 - val_loss: 60.5153\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 74.9902 - val_loss: 56.7726\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 73.1841 - val_loss: 57.0066\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 71.9294 - val_loss: 55.5501\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 70.2480 - val_loss: 54.5105\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 69.0104 - val_loss: 52.6212\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 68.7091 - val_loss: 51.8280\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 67.0791 - val_loss: 52.6320\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 67.7554 - val_loss: 52.1795\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 67.5563 - val_loss: 52.7665\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 67.6817 - val_loss: 50.5608\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 65.7400 - val_loss: 50.4921\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 66.3861 - val_loss: 52.7267\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 65.7379 - val_loss: 48.4705\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 64.0820 - val_loss: 48.1471\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 63.4194 - val_loss: 48.3600\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 63.0793 - val_loss: 45.7720\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 62.0751 - val_loss: 45.4822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 61.8285 - val_loss: 45.1986\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 63.1696 - val_loss: 45.0008\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 61.8007 - val_loss: 44.4014\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 60.4924 - val_loss: 43.0073\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 59.8107 - val_loss: 42.1283\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 58.3695 - val_loss: 42.0441\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 59.3217 - val_loss: 44.0818\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 59.4191 - val_loss: 42.0951\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 57.6877 - val_loss: 44.4020\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 56.9235 - val_loss: 42.5731\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 57.3006 - val_loss: 39.8219\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 56.9845 - val_loss: 41.1657\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 57.4729 - val_loss: 38.4756\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 55.9317 - val_loss: 41.1073\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 56.8802 - val_loss: 38.5425\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 57.8588 - val_loss: 38.1497\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 55.0119 - val_loss: 37.5285\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 56.1822 - val_loss: 37.0637\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 55.2063 - val_loss: 37.8190\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 55.7020 - val_loss: 39.4679\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 58.9183 - val_loss: 40.1426\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 54.2828 - val_loss: 35.7376\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 51.6096 - val_loss: 34.9493\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 51.4052 - val_loss: 35.5956\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 50.5843 - val_loss: 33.3076\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 49.3965 - val_loss: 33.4233\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 48.8575 - val_loss: 32.7618\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 47.9463 - val_loss: 32.7262\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 48.1507 - val_loss: 31.8046\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 47.6095 - val_loss: 31.3113\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 47.9829 - val_loss: 31.1259\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 47.4649 - val_loss: 31.4570\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 47.1924 - val_loss: 30.4139\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 48.1961 - val_loss: 30.8259\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 46.6809 - val_loss: 29.9271\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 46.9508 - val_loss: 30.3257\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 46.0798 - val_loss: 29.4817\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 45.7594 - val_loss: 29.4197\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 45.4670 - val_loss: 29.0502\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 44.0942 - val_loss: 28.9885\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 45.2886 - val_loss: 27.8792\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 44.1017 - val_loss: 28.6197\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 44.4389 - val_loss: 28.8218\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 44.8471 - val_loss: 28.1109\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 42.9608 - val_loss: 27.4791\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 41.7463 - val_loss: 26.6495\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 41.3637 - val_loss: 26.4149\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 41.3582 - val_loss: 26.0520\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 41.8716 - val_loss: 28.1477\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 41.0579 - val_loss: 25.4837\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 40.7511 - val_loss: 28.2474\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 41.1462 - val_loss: 26.3469\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 41.0249 - val_loss: 25.3573\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 39.5031 - val_loss: 24.0872\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 39.4101 - val_loss: 23.9548\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 38.7956 - val_loss: 24.0772\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 38.5798 - val_loss: 23.6764\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 39.3603 - val_loss: 23.4540\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 41.2105 - val_loss: 23.6290\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 39.3909 - val_loss: 23.7794\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 39.9682 - val_loss: 23.9762\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 38.5527 - val_loss: 22.6147\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 39.2457 - val_loss: 23.5061\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 39.4805 - val_loss: 24.0727\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 43.0242 - val_loss: 22.6534\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 41.1536 - val_loss: 21.6044\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 39.5741 - val_loss: 21.2325\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 37.2827 - val_loss: 21.0148\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 38.3733 - val_loss: 23.7136\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 38.6637 - val_loss: 21.1407\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 37.4142 - val_loss: 22.2651\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 39.3717 - val_loss: 22.2869\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 40.3647 - val_loss: 21.1173\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 39.5036 - val_loss: 21.4116\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 38.1111 - val_loss: 21.3812\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 37.4075 - val_loss: 21.4705\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 37.0656 - val_loss: 19.8511\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 35.3391 - val_loss: 19.2275\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 34.6222 - val_loss: 19.2890\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 33.9450 - val_loss: 18.5380\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 25ms/step - loss: 33.2262 - val_loss: 18.8314\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 32.8641 - val_loss: 19.0881\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 34.5907 - val_loss: 17.9584\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 37.9159 - val_loss: 21.4960\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 36.6536 - val_loss: 19.2035\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 33.6376 - val_loss: 20.3215\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 33.7835 - val_loss: 19.4961\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 32.6375 - val_loss: 19.0085\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 31.3572 - val_loss: 17.7186\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 31.8677 - val_loss: 17.4411\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 33.7411 - val_loss: 18.9463\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 34.3805 - val_loss: 17.7895\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 30.6009 - val_loss: 17.2332\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 30.1056 - val_loss: 16.7025\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 30.1324 - val_loss: 16.1752\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 30.3768 - val_loss: 17.6980\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 29.8206 - val_loss: 15.9710\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 31.0887 - val_loss: 15.9835\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 34.1433 - val_loss: 16.7707\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 36.4062 - val_loss: 17.9174\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 37.2070 - val_loss: 16.7877\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 35.5681 - val_loss: 17.1565\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 34.6223 - val_loss: 16.7856\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 33.8340 - val_loss: 16.2560\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 32.4057 - val_loss: 15.7161\n",
      "MAE: 1.932233649359809\n",
      "SMAPE: 1.450359851548784\n",
      "RMSE: 3.9312298998318993\n",
      "R2 Score: 0.8732463441138788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 24 data points for the rolling window\n",
    "window_size = 24\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8eaad",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c259a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 3s 409ms/step - loss: 15978.7354 - val_loss: 14941.4307\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15654.6436 - val_loss: 14639.1143\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 15363.1602 - val_loss: 14347.6758\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 15070.8643 - val_loss: 14084.4619\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 14798.4639 - val_loss: 13823.5547\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 14527.1260 - val_loss: 13551.1992\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 14231.2764 - val_loss: 13258.3955\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 13934.9531 - val_loss: 12995.7607\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 13658.5732 - val_loss: 12715.5781\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 13359.7734 - val_loss: 12404.1631\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 13030.7178 - val_loss: 12063.0820\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 12680.5498 - val_loss: 11699.0166\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 12283.7295 - val_loss: 11310.0537\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 11895.8916 - val_loss: 10950.0391\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 11533.6689 - val_loss: 10622.9287\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 11201.8604 - val_loss: 10310.3984\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 10882.0674 - val_loss: 10014.2188\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 10588.7783 - val_loss: 9752.7979\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 10336.7939 - val_loss: 9499.6982\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 10072.3125 - val_loss: 9237.2510\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9803.9932 - val_loss: 8981.7178\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 9543.4189 - val_loss: 8742.0381\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9296.4258 - val_loss: 8505.1201\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9054.0576 - val_loss: 8249.6553\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8797.7969 - val_loss: 7989.4585\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8520.0674 - val_loss: 7739.8735\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8269.0742 - val_loss: 7480.7852\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7987.0464 - val_loss: 7198.8423\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 7705.5981 - val_loss: 6919.8828\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 7427.1934 - val_loss: 6681.9370\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7188.0449 - val_loss: 6455.5210\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6957.9790 - val_loss: 6251.2212\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6752.3179 - val_loss: 6051.2612\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6547.1938 - val_loss: 5844.2583\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6330.7212 - val_loss: 5632.6870\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6112.9663 - val_loss: 5427.1450\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5902.2480 - val_loss: 5246.4844\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5722.7378 - val_loss: 5083.3022\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 5555.8984 - val_loss: 4925.0879\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5396.7930 - val_loss: 4768.8472\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5234.2954 - val_loss: 4615.0239\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5075.7280 - val_loss: 4469.3833\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4925.3247 - val_loss: 4324.9438\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4776.8765 - val_loss: 4179.4287\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4623.9551 - val_loss: 4039.9778\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4475.7900 - val_loss: 3909.2754\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4345.6021 - val_loss: 3781.2415\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4209.3232 - val_loss: 3653.9968\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4079.7803 - val_loss: 3534.7937\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3957.8125 - val_loss: 3423.6160\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3843.3484 - val_loss: 3317.0813\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3729.3196 - val_loss: 3212.6892\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3619.5969 - val_loss: 3110.9775\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3511.9885 - val_loss: 3013.8184\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3415.0039 - val_loss: 2919.8596\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3315.4551 - val_loss: 2828.9268\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3222.1296 - val_loss: 2738.3210\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3126.2188 - val_loss: 2650.5120\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3036.1975 - val_loss: 2561.4314\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2939.5457 - val_loss: 2475.1765\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2849.2969 - val_loss: 2392.5635\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2767.8936 - val_loss: 2314.6458\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2683.2988 - val_loss: 2241.4973\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2605.9089 - val_loss: 2168.8826\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2529.9746 - val_loss: 2099.9297\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2455.6790 - val_loss: 2033.8175\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2387.8955 - val_loss: 1970.0433\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2317.1697 - val_loss: 1909.5570\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2257.7856 - val_loss: 1849.3107\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2191.7930 - val_loss: 1791.8881\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2128.7424 - val_loss: 1737.3043\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2073.8142 - val_loss: 1683.7422\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2014.3431 - val_loss: 1632.6906\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1962.4760 - val_loss: 1582.6304\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1907.7939 - val_loss: 1534.6588\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1856.0869 - val_loss: 1488.3702\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1806.2906 - val_loss: 1443.6747\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1757.1338 - val_loss: 1400.7618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1711.9332 - val_loss: 1358.9508\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1664.8051 - val_loss: 1319.0958\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1623.5907 - val_loss: 1280.0010\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1583.4185 - val_loss: 1241.7832\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1542.5062 - val_loss: 1204.9398\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1500.3583 - val_loss: 1170.0547\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1463.7694 - val_loss: 1136.0084\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1423.9862 - val_loss: 1103.8883\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1389.3995 - val_loss: 1072.6237\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1356.0742 - val_loss: 1042.1705\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1322.2550 - val_loss: 1012.9056\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1290.8187 - val_loss: 984.4222\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1259.0551 - val_loss: 956.8802\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1230.2196 - val_loss: 929.9903\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1200.7123 - val_loss: 904.2935\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1171.4681 - val_loss: 879.8305\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1146.3358 - val_loss: 855.7945\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1117.0350 - val_loss: 833.3923\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1093.7532 - val_loss: 811.3278\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1069.3597 - val_loss: 790.0778\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1044.5917 - val_loss: 769.9066\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1023.7309 - val_loss: 750.0605\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 998.5903 - val_loss: 731.7327\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 978.4209 - val_loss: 713.8444\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 960.1614 - val_loss: 696.1297\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 940.1638 - val_loss: 679.1620\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 920.0593 - val_loss: 663.0596\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 901.4871 - val_loss: 647.5410\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 885.0947 - val_loss: 632.3500\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 865.6197 - val_loss: 618.1808\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 848.0505 - val_loss: 604.7365\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 834.9385 - val_loss: 591.1214\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 817.0713 - val_loss: 578.6771\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 803.7438 - val_loss: 566.3433\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 787.5054 - val_loss: 554.9525\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 774.4432 - val_loss: 543.8859\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 763.0710 - val_loss: 532.8667\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 749.5637 - val_loss: 522.4678\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 737.2724 - val_loss: 512.5548\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 724.6348 - val_loss: 503.3236\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 714.6272 - val_loss: 494.1720\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 703.8992 - val_loss: 485.4344\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 692.8796 - val_loss: 477.2028\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 682.3441 - val_loss: 469.5032\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 674.5090 - val_loss: 461.7974\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 663.4607 - val_loss: 454.8425\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 655.1509 - val_loss: 448.1024\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 647.3278 - val_loss: 441.5713\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 638.5955 - val_loss: 435.4816\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 631.6933 - val_loss: 429.5275\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 623.1932 - val_loss: 424.0706\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 615.3769 - val_loss: 419.0440\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 608.5008 - val_loss: 414.3482\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 604.6658 - val_loss: 409.4142\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 596.8605 - val_loss: 404.8134\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 591.4300 - val_loss: 400.5189\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 585.0266 - val_loss: 396.3689\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 580.1257 - val_loss: 392.4421\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 574.5414 - val_loss: 388.8478\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 569.1345 - val_loss: 385.4086\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 565.0715 - val_loss: 382.0923\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 560.5793 - val_loss: 378.9559\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 555.7538 - val_loss: 375.9763\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 550.7000 - val_loss: 373.2958\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 546.0828 - val_loss: 370.8220\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 542.8339 - val_loss: 368.3223\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 538.9736 - val_loss: 365.9980\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 534.1971 - val_loss: 364.2742\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 526.5047 - val_loss: 396.4662\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 537.3106 - val_loss: 359.9602\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 525.4565 - val_loss: 360.4604\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 524.5470 - val_loss: 355.4015\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 516.5136 - val_loss: 352.5058\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 515.8157 - val_loss: 350.4592\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 512.7332 - val_loss: 348.8987\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 510.8067 - val_loss: 347.5063\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 507.1975 - val_loss: 346.0850\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 505.4098 - val_loss: 344.7901\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 34ms/step - loss: 503.2665 - val_loss: 343.5350\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 500.5404 - val_loss: 342.4274\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 498.4851 - val_loss: 341.3600\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 496.4935 - val_loss: 340.3673\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 495.0198 - val_loss: 339.4011\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 493.0553 - val_loss: 338.5733\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 491.2458 - val_loss: 337.7695\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 489.9694 - val_loss: 336.9323\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 488.1815 - val_loss: 336.1444\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 486.8152 - val_loss: 335.4993\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 485.4418 - val_loss: 334.8965\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 483.5254 - val_loss: 334.3931\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 482.3982 - val_loss: 333.9736\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 481.3734 - val_loss: 333.5255\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 480.2701 - val_loss: 333.0846\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 479.0139 - val_loss: 332.6424\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 477.6408 - val_loss: 332.2940\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 476.9315 - val_loss: 332.0117\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 475.9106 - val_loss: 331.7280\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 474.9815 - val_loss: 331.4864\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 473.7566 - val_loss: 331.2613\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 472.9406 - val_loss: 331.0779\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 472.1089 - val_loss: 330.9131\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 471.6969 - val_loss: 330.7201\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 470.5935 - val_loss: 330.5609\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 470.2434 - val_loss: 330.4911\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 469.1239 - val_loss: 330.3359\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 468.2821 - val_loss: 330.2481\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 467.6768 - val_loss: 330.1838\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 466.9557 - val_loss: 330.1346\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 465.9492 - val_loss: 330.1033\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 465.3467 - val_loss: 330.0887\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 464.6620 - val_loss: 330.0175\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 463.8469 - val_loss: 330.0594\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 463.0660 - val_loss: 330.1128\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 461.7480 - val_loss: 330.1264\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 462.4956 - val_loss: 329.9633\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 459.3511 - val_loss: 330.0832\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 458.4072 - val_loss: 329.5748\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 457.3304 - val_loss: 324.0398\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 453.1671 - val_loss: 326.8494\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 454.6272 - val_loss: 328.4671\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 448.1040 - val_loss: 326.9681\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 455.6944 - val_loss: 325.5111\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 447.0345 - val_loss: 321.1541\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 441.0230 - val_loss: 321.5458\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 439.6832 - val_loss: 322.6341\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 434.1982 - val_loss: 321.3100\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 434.3898 - val_loss: 320.7954\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 438.5591 - val_loss: 320.7575\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 431.8353 - val_loss: 322.2539\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 429.2367 - val_loss: 320.0721\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 428.0300 - val_loss: 318.1379\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 425.0457 - val_loss: 315.2178\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 422.3323 - val_loss: 312.6113\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 415.9757 - val_loss: 310.9043\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 420.1592 - val_loss: 308.8616\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 415.9200 - val_loss: 305.7736\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 410.0569 - val_loss: 300.8208\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 404.3418 - val_loss: 296.7977\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 401.1609 - val_loss: 291.9344\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 395.5547 - val_loss: 291.9611\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 391.3416 - val_loss: 288.6954\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 387.2216 - val_loss: 284.0990\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 382.7497 - val_loss: 279.8685\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 381.0189 - val_loss: 276.0874\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 374.8388 - val_loss: 274.7592\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 371.1577 - val_loss: 272.5970\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 368.1620 - val_loss: 267.1076\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 366.3136 - val_loss: 265.5708\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 359.9281 - val_loss: 264.5264\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 358.5128 - val_loss: 262.7949\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 355.6036 - val_loss: 260.1581\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 351.0802 - val_loss: 254.9885\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 347.9701 - val_loss: 252.6225\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 343.9731 - val_loss: 251.2078\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 340.5291 - val_loss: 249.7855\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 337.8114 - val_loss: 247.2384\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 335.0192 - val_loss: 245.9165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 333.0171 - val_loss: 245.2167\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 330.6128 - val_loss: 243.0941\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 328.1690 - val_loss: 240.8527\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 325.4153 - val_loss: 237.6535\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 323.9552 - val_loss: 239.6111\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 320.6991 - val_loss: 235.4468\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 319.1351 - val_loss: 235.8762\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 317.5212 - val_loss: 234.2952\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 315.8540 - val_loss: 233.6730\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 312.0443 - val_loss: 230.7779\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 310.4355 - val_loss: 229.9478\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 309.3699 - val_loss: 230.2971\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 307.1197 - val_loss: 227.6733\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 305.4497 - val_loss: 225.1068\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 301.8528 - val_loss: 223.9871\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 301.3838 - val_loss: 221.8593\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 297.4896 - val_loss: 220.0325\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 300.1491 - val_loss: 218.4563\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 296.7124 - val_loss: 216.3778\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 294.1064 - val_loss: 220.1502\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 292.6407 - val_loss: 216.5419\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 287.2183 - val_loss: 215.2798\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 287.4749 - val_loss: 213.1857\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 286.1758 - val_loss: 210.1365\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 281.0761 - val_loss: 208.5509\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 281.3854 - val_loss: 210.2157\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 279.7159 - val_loss: 206.7092\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 275.7341 - val_loss: 203.9266\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 273.0732 - val_loss: 202.2618\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 271.0769 - val_loss: 199.2137\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 268.5484 - val_loss: 198.4572\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 266.8601 - val_loss: 197.4205\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 264.2362 - val_loss: 194.6608\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 262.1563 - val_loss: 192.5673\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 260.2949 - val_loss: 191.5514\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 257.8792 - val_loss: 190.3361\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 256.4625 - val_loss: 189.3592\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 251.8067 - val_loss: 189.2096\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 258.5046 - val_loss: 185.6166\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 253.9094 - val_loss: 177.3464\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 245.6852 - val_loss: 180.9660\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 244.0677 - val_loss: 176.2414\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 239.5866 - val_loss: 170.3218\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 236.0259 - val_loss: 165.7973\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 232.2594 - val_loss: 161.3637\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 227.6333 - val_loss: 154.3944\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 221.2419 - val_loss: 146.2562\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 216.0883 - val_loss: 138.8566\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 210.7142 - val_loss: 133.9527\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 206.5656 - val_loss: 132.3089\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 204.6883 - val_loss: 128.9935\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 200.6757 - val_loss: 126.3639\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 197.4844 - val_loss: 125.5835\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 194.4925 - val_loss: 123.9419\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 192.3288 - val_loss: 123.8623\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 191.6411 - val_loss: 121.3126\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 187.3676 - val_loss: 119.8217\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 185.9377 - val_loss: 118.6360\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 183.5211 - val_loss: 116.1398\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 181.3167 - val_loss: 114.8631\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 178.8331 - val_loss: 114.7220\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 176.8704 - val_loss: 112.7228\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 175.8545 - val_loss: 111.8854\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 174.5612 - val_loss: 110.3156\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 172.2293 - val_loss: 109.3750\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 171.3055 - val_loss: 108.3764\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 169.9079 - val_loss: 107.7500\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 168.0971 - val_loss: 107.2840\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 166.3410 - val_loss: 106.6593\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 164.2045 - val_loss: 105.6956\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 162.1481 - val_loss: 105.2857\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 160.8710 - val_loss: 104.1867\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 159.8834 - val_loss: 102.6657\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 158.6928 - val_loss: 102.0178\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 157.6758 - val_loss: 101.7038\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 155.2488 - val_loss: 100.0307\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 153.8430 - val_loss: 98.6636\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 151.9268 - val_loss: 97.6454\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 150.6160 - val_loss: 96.8319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 148.5787 - val_loss: 95.7719\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 147.4341 - val_loss: 95.1034\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 145.9058 - val_loss: 93.6000\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 145.2407 - val_loss: 92.9608\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 143.1478 - val_loss: 91.8323\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 141.7258 - val_loss: 92.0138\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 140.7435 - val_loss: 90.9276\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 139.5564 - val_loss: 90.4601\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 138.2802 - val_loss: 90.3747\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 137.1297 - val_loss: 88.2431\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 135.5403 - val_loss: 88.0998\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 134.3583 - val_loss: 88.0471\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 132.9151 - val_loss: 87.0026\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 132.2306 - val_loss: 86.2692\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 131.6214 - val_loss: 84.5917\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 129.0853 - val_loss: 84.3106\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 128.4598 - val_loss: 83.9447\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 127.0302 - val_loss: 82.9808\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 125.8966 - val_loss: 82.7548\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 125.1859 - val_loss: 81.9568\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 123.6858 - val_loss: 80.8242\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 122.6637 - val_loss: 80.9079\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 121.7200 - val_loss: 80.4629\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 121.3785 - val_loss: 79.8144\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 121.1681 - val_loss: 81.0742\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 121.6420 - val_loss: 79.9692\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 120.1366 - val_loss: 82.9746\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 121.1421 - val_loss: 89.5163\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 121.0121 - val_loss: 87.8451\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 119.9881 - val_loss: 85.6873\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 118.6248 - val_loss: 81.2337\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 117.6119 - val_loss: 77.7243\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 114.6881 - val_loss: 77.9548\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 113.2340 - val_loss: 76.5738\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 112.4195 - val_loss: 76.6456\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 111.6806 - val_loss: 74.3394\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 110.0811 - val_loss: 73.6341\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 109.2289 - val_loss: 74.2815\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 108.2327 - val_loss: 73.3723\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 107.2410 - val_loss: 72.8705\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 106.3537 - val_loss: 71.6360\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 105.2954 - val_loss: 71.3491\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 104.7635 - val_loss: 70.8743\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 104.7185 - val_loss: 70.3179\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 103.4491 - val_loss: 69.4998\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 102.3570 - val_loss: 68.5567\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 101.5992 - val_loss: 68.4658\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 101.4386 - val_loss: 69.7560\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 100.6334 - val_loss: 68.6896\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 99.3402 - val_loss: 67.2324\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 98.7824 - val_loss: 66.8904\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 97.7969 - val_loss: 67.1123\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 97.3734 - val_loss: 66.7872\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 96.1703 - val_loss: 65.5229\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 95.6249 - val_loss: 65.1732\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 94.7952 - val_loss: 65.7052\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 94.0969 - val_loss: 65.1254\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 93.6235 - val_loss: 64.6496\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 92.9159 - val_loss: 64.6783\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 92.3217 - val_loss: 64.1461\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 91.5749 - val_loss: 63.6051\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 91.2634 - val_loss: 63.9751\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 90.9988 - val_loss: 63.8249\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 90.7412 - val_loss: 64.1188\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 90.3406 - val_loss: 63.2314\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 89.5971 - val_loss: 62.1216\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 88.2437 - val_loss: 61.8319\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 87.8145 - val_loss: 61.5883\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 86.8460 - val_loss: 61.6012\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 86.5198 - val_loss: 62.3664\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 86.0782 - val_loss: 60.0935\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 86.4074 - val_loss: 59.2038\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 85.0272 - val_loss: 59.5931\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 84.7795 - val_loss: 60.2732\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 84.6196 - val_loss: 58.6859\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 84.1570 - val_loss: 59.1365\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 83.5808 - val_loss: 58.6374\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 82.6805 - val_loss: 58.4051\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 82.0147 - val_loss: 58.8383\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 81.6341 - val_loss: 58.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 81.1012 - val_loss: 56.4550\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 80.6976 - val_loss: 56.0890\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 80.3870 - val_loss: 57.4736\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 79.4395 - val_loss: 57.1583\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 79.0415 - val_loss: 55.8520\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 78.8272 - val_loss: 55.6569\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 78.3752 - val_loss: 57.8663\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 78.8377 - val_loss: 57.6369\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 77.1695 - val_loss: 54.3515\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 76.6399 - val_loss: 55.1357\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 78.4662 - val_loss: 54.3785\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 76.6584 - val_loss: 54.9955\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 77.4834 - val_loss: 57.4184\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 77.7347 - val_loss: 57.0440\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 78.5363 - val_loss: 55.7675\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 77.5596 - val_loss: 61.9548\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 77.4000 - val_loss: 55.1166\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 75.5411 - val_loss: 52.4412\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 73.0747 - val_loss: 52.7386\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 72.1943 - val_loss: 50.6322\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 72.0070 - val_loss: 50.2791\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 70.7085 - val_loss: 51.7154\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 70.4119 - val_loss: 49.9169\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 69.6778 - val_loss: 50.1445\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 68.8754 - val_loss: 49.7504\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 68.6040 - val_loss: 49.2609\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 68.0120 - val_loss: 50.3811\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 67.7972 - val_loss: 49.0286\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 67.4904 - val_loss: 48.2743\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 66.9730 - val_loss: 47.4028\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 66.7358 - val_loss: 46.6409\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 65.7327 - val_loss: 47.3621\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 66.7001 - val_loss: 47.8978\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 70.7842 - val_loss: 47.4620\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 73.4048 - val_loss: 47.6416\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 73.6204 - val_loss: 47.9706\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 72.3129 - val_loss: 45.5695\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 70.5702 - val_loss: 42.7920\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 69.1688 - val_loss: 41.9746\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 67.1530 - val_loss: 42.6166\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 67.4772 - val_loss: 43.5218\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 68.0568 - val_loss: 42.2972\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 66.1258 - val_loss: 39.8661\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 65.9629 - val_loss: 42.3414\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 63.7812 - val_loss: 42.2078\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 65.4281 - val_loss: 39.3517\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 63.8085 - val_loss: 39.7182\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 61.9246 - val_loss: 39.2305\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 60.9981 - val_loss: 39.7077\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 61.1675 - val_loss: 40.0645\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 60.4543 - val_loss: 38.1969\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 59.8572 - val_loss: 38.6328\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 60.1497 - val_loss: 37.4698\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 59.3224 - val_loss: 37.3548\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 59.1745 - val_loss: 38.3205\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 59.4180 - val_loss: 36.5750\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 57.8720 - val_loss: 37.8338\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 57.6991 - val_loss: 37.1938\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 57.4208 - val_loss: 37.9952\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 57.7209 - val_loss: 37.5160\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 56.8868 - val_loss: 36.3095\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 56.7283 - val_loss: 36.6771\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 56.3847 - val_loss: 35.3134\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 56.0900 - val_loss: 36.0621\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 55.7519 - val_loss: 36.6666\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 55.0140 - val_loss: 35.4756\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 54.5219 - val_loss: 35.9551\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 54.6170 - val_loss: 34.0107\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 53.6918 - val_loss: 34.3813\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 53.5056 - val_loss: 34.5326\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 53.4814 - val_loss: 33.9728\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 52.8339 - val_loss: 35.2345\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 52.8189 - val_loss: 33.3872\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 52.4370 - val_loss: 33.1698\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 53.0851 - val_loss: 34.9202\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 52.1264 - val_loss: 34.4126\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 52.4628 - val_loss: 35.0697\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 52.4970 - val_loss: 34.0435\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 52.3414 - val_loss: 33.2940\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 52.2613 - val_loss: 34.8054\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 41ms/step - loss: 51.6996 - val_loss: 32.1073\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 50.8030 - val_loss: 34.2164\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 50.9128 - val_loss: 32.7506\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 50.6976 - val_loss: 35.1445\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 50.8403 - val_loss: 34.6796\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 50.9659 - val_loss: 32.4744\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 49.9163 - val_loss: 34.0496\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 49.8516 - val_loss: 34.3285\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 49.7548 - val_loss: 32.2514\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 49.2653 - val_loss: 30.8692\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 48.9820 - val_loss: 30.6111\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 48.1026 - val_loss: 30.1935\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 47.5199 - val_loss: 32.0582\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 47.7015 - val_loss: 28.3891\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 47.0152 - val_loss: 28.1638\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 46.9059 - val_loss: 29.6278\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 46.1427 - val_loss: 27.9037\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 46.3670 - val_loss: 28.5055\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 46.3551 - val_loss: 27.5970\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 45.4998 - val_loss: 28.6636\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 44.9861 - val_loss: 28.4659\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 44.6841 - val_loss: 27.2714\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 44.5468 - val_loss: 27.0976\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 44.6001 - val_loss: 27.5569\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 43.8587 - val_loss: 26.6813\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 43.5663 - val_loss: 27.6590\n",
      "MAE: 2.2710645802815757\n",
      "SMAPE: 1.7411513802087835\n",
      "RMSE: 5.151145706616349\n",
      "R2 Score: 0.832249239782936\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 12 data points for the rolling window\n",
    "window_size = 12\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af292403",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15699f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 4s 776ms/step - loss: 13359.4414 - val_loss: 13991.7764\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 13176.0508 - val_loss: 13810.8311\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 12990.9600 - val_loss: 13630.8623\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12807.4482 - val_loss: 13457.3818\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12630.9170 - val_loss: 13287.1016\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 12448.3350 - val_loss: 13116.4502\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 12270.2803 - val_loss: 12943.5000\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 12088.2764 - val_loss: 12765.1729\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11899.7100 - val_loss: 12576.4561\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 11709.4717 - val_loss: 12392.0938\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11517.9385 - val_loss: 12190.5439\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 11318.3828 - val_loss: 11975.7188\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 11104.3896 - val_loss: 11775.2998\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10898.7061 - val_loss: 11559.3643\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10678.3555 - val_loss: 11314.6689\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10432.3516 - val_loss: 11046.6729\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10182.5576 - val_loss: 10781.8877\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9922.0713 - val_loss: 10518.4561\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 9679.6328 - val_loss: 10252.7178\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 9420.5889 - val_loss: 9981.4502\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9161.3389 - val_loss: 9717.8242\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8926.2041 - val_loss: 9477.7705\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8700.0469 - val_loss: 9262.2607\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 8503.5078 - val_loss: 9061.8994\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 8316.7354 - val_loss: 8870.1719\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 8135.5288 - val_loss: 8683.3438\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7964.1274 - val_loss: 8497.4297\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 7790.4531 - val_loss: 8314.9180\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 7619.0820 - val_loss: 8139.8022\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7460.6968 - val_loss: 7970.0762\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 7306.2207 - val_loss: 7806.9829\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 7149.9414 - val_loss: 7648.8359\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 7000.0781 - val_loss: 7492.9937\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6851.5610 - val_loss: 7337.0063\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6699.5078 - val_loss: 7179.5288\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6556.2329 - val_loss: 7021.3423\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6409.0425 - val_loss: 6869.5078\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6267.2871 - val_loss: 6730.8008\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 6135.0601 - val_loss: 6599.1211\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6008.7690 - val_loss: 6467.0820\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5881.1406 - val_loss: 6331.3384\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5749.4062 - val_loss: 6193.7847\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5620.8882 - val_loss: 6058.1562\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 5494.7417 - val_loss: 5927.0176\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5364.5073 - val_loss: 5800.5796\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5248.9102 - val_loss: 5675.8530\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5127.6001 - val_loss: 5554.2788\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 5016.3701 - val_loss: 5437.9253\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4905.3115 - val_loss: 5325.5977\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4798.2075 - val_loss: 5214.7671\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4691.9849 - val_loss: 5103.7422\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4586.3296 - val_loss: 4991.8540\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4480.4780 - val_loss: 4889.9414\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4377.7583 - val_loss: 4775.8657\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4276.9551 - val_loss: 4672.6621\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4181.7305 - val_loss: 4571.0757\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4082.2588 - val_loss: 4470.4380\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3987.2527 - val_loss: 4373.3511\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3896.3406 - val_loss: 4279.5249\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3808.7947 - val_loss: 4185.2964\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3718.9795 - val_loss: 4092.2625\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3629.9290 - val_loss: 3999.0105\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3546.4170 - val_loss: 3907.3347\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3456.1448 - val_loss: 3820.8164\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3377.0618 - val_loss: 3738.1536\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3301.9639 - val_loss: 3660.0645\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3230.5977 - val_loss: 3585.7090\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3158.0232 - val_loss: 3513.1387\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3087.1816 - val_loss: 3440.5312\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3020.8074 - val_loss: 3367.3977\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2950.9441 - val_loss: 3295.3328\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2882.9382 - val_loss: 3224.8252\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2816.8792 - val_loss: 3155.7961\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2751.7744 - val_loss: 3087.4729\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2688.5854 - val_loss: 3017.3030\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2618.9036 - val_loss: 2946.1218\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2555.6946 - val_loss: 2875.6121\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2491.2034 - val_loss: 2809.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2427.7605 - val_loss: 2747.3928\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2372.2803 - val_loss: 2688.0671\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2319.8206 - val_loss: 2630.2031\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 2267.2356 - val_loss: 2574.2571\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2213.4602 - val_loss: 2520.7910\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2164.3191 - val_loss: 2468.8538\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2115.9292 - val_loss: 2418.6003\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2067.4082 - val_loss: 2369.8271\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 2022.9772 - val_loss: 2321.8469\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1977.6929 - val_loss: 2274.7754\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1931.6162 - val_loss: 2228.4900\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1890.0485 - val_loss: 2181.9121\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1848.0797 - val_loss: 2134.7429\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1802.5148 - val_loss: 2088.2502\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1758.9818 - val_loss: 2045.2482\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1721.2231 - val_loss: 2004.0240\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1684.0494 - val_loss: 1964.0835\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1646.1226 - val_loss: 1925.4193\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1609.9482 - val_loss: 1887.7506\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1574.6461 - val_loss: 1850.8395\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1542.2682 - val_loss: 1814.5967\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1507.5834 - val_loss: 1779.5453\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1474.0449 - val_loss: 1745.1934\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1444.7725 - val_loss: 1711.2666\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1410.7264 - val_loss: 1678.3978\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1382.0345 - val_loss: 1645.6888\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1353.1409 - val_loss: 1613.5400\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1321.2781 - val_loss: 1581.7670\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1293.0620 - val_loss: 1549.3617\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1264.2275 - val_loss: 1517.4565\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1233.1256 - val_loss: 1486.7858\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1205.5448 - val_loss: 1456.7988\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1178.6542 - val_loss: 1427.6826\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1153.8003 - val_loss: 1399.4501\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1128.3153 - val_loss: 1372.2186\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1102.8994 - val_loss: 1345.7872\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1081.1885 - val_loss: 1319.9130\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1056.6034 - val_loss: 1295.1600\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1034.6569 - val_loss: 1271.0687\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1012.6011 - val_loss: 1247.6639\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 991.4404 - val_loss: 1224.6534\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 971.6418 - val_loss: 1201.8153\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 949.5191 - val_loss: 1179.5408\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 929.8162 - val_loss: 1158.2017\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 911.3303 - val_loss: 1137.7582\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 891.7733 - val_loss: 1117.9043\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 874.9985 - val_loss: 1098.2220\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 857.3577 - val_loss: 1079.0656\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 839.3854 - val_loss: 1060.3798\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 822.3431 - val_loss: 1041.8876\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 806.1453 - val_loss: 1023.5366\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 790.8610 - val_loss: 1005.4980\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 774.8729 - val_loss: 988.0703\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 759.3840 - val_loss: 971.1995\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 744.8591 - val_loss: 954.8237\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 728.9999 - val_loss: 938.9899\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 716.4737 - val_loss: 923.2663\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 701.5981 - val_loss: 908.1103\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 688.8742 - val_loss: 893.1685\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 675.7542 - val_loss: 878.6346\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 664.4774 - val_loss: 864.4968\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 651.9318 - val_loss: 851.1234\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 638.4825 - val_loss: 838.3167\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 628.2812 - val_loss: 825.4857\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 618.0473 - val_loss: 813.0068\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 606.2922 - val_loss: 801.0972\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 596.2598 - val_loss: 789.4087\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 586.1449 - val_loss: 778.0250\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 576.3416 - val_loss: 766.9188\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 566.9034 - val_loss: 756.0784\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 558.5529 - val_loss: 745.5438\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 548.8699 - val_loss: 735.5525\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 540.3638 - val_loss: 725.8299\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 531.7104 - val_loss: 716.3591\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 523.7901 - val_loss: 707.0109\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 515.0589 - val_loss: 697.8303\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 508.1530 - val_loss: 688.5822\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 500.4092 - val_loss: 679.6087\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 48ms/step - loss: 492.7901 - val_loss: 670.9039\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 484.9074 - val_loss: 662.4153\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 479.1511 - val_loss: 653.9788\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 471.6626 - val_loss: 646.0137\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 464.8938 - val_loss: 638.2812\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 459.1080 - val_loss: 630.5826\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 452.0908 - val_loss: 623.0438\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 446.5945 - val_loss: 615.6225\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 439.8385 - val_loss: 608.6822\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 434.1489 - val_loss: 601.9394\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 428.6582 - val_loss: 595.3423\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 423.2868 - val_loss: 588.8885\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 418.6468 - val_loss: 582.5961\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 412.8360 - val_loss: 576.6313\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 408.8945 - val_loss: 570.7442\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 403.4728 - val_loss: 565.2083\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 399.5596 - val_loss: 559.7656\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 394.8756 - val_loss: 554.5881\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 391.0916 - val_loss: 549.5432\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 385.9987 - val_loss: 544.7184\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 382.5770 - val_loss: 539.7059\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 378.9476 - val_loss: 534.7481\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 374.7421 - val_loss: 529.9626\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 370.7039 - val_loss: 525.2269\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 367.6111 - val_loss: 520.4705\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 363.6426 - val_loss: 515.9207\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 360.7797 - val_loss: 511.4783\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 356.2864 - val_loss: 507.3270\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 354.1572 - val_loss: 503.0810\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 350.4117 - val_loss: 499.1318\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 346.8857 - val_loss: 495.2647\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 345.1322 - val_loss: 491.3185\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 341.5721 - val_loss: 487.7089\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 338.4796 - val_loss: 484.1905\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 336.6784 - val_loss: 480.6412\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 333.1018 - val_loss: 477.3459\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 331.6028 - val_loss: 473.9563\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 328.6558 - val_loss: 470.8302\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 326.8166 - val_loss: 467.7877\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 324.3281 - val_loss: 464.9697\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 322.3011 - val_loss: 462.2520\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 320.1042 - val_loss: 459.6267\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 318.0081 - val_loss: 456.9930\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 316.4131 - val_loss: 454.2943\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 314.5412 - val_loss: 451.6770\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 312.6565 - val_loss: 449.1525\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 310.5869 - val_loss: 446.6942\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 309.1808 - val_loss: 444.1966\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 307.4294 - val_loss: 441.8026\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 305.7937 - val_loss: 439.4950\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 303.8970 - val_loss: 437.2663\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 302.5733 - val_loss: 434.9964\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 301.5361 - val_loss: 432.7982\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 299.4172 - val_loss: 430.8191\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 298.2534 - val_loss: 428.7969\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 296.9895 - val_loss: 426.8230\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 295.8282 - val_loss: 424.9308\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 294.4659 - val_loss: 423.1747\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 293.2484 - val_loss: 421.5317\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 292.1239 - val_loss: 420.5934\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 291.1310 - val_loss: 431.0059\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 298.8754 - val_loss: 431.5997\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 297.6802 - val_loss: 424.7285\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 288.1421 - val_loss: 414.0488\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 287.1827 - val_loss: 412.3557\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 286.3340 - val_loss: 410.8963\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 285.5157 - val_loss: 409.5169\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 284.8020 - val_loss: 408.2129\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 283.8741 - val_loss: 407.0221\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 283.4655 - val_loss: 405.8619\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 282.5017 - val_loss: 404.8582\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 281.8106 - val_loss: 403.9043\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 281.4840 - val_loss: 402.9230\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 280.6267 - val_loss: 402.0914\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 280.3743 - val_loss: 401.2667\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 279.4327 - val_loss: 400.6147\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 278.9228 - val_loss: 399.6677\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 278.2939 - val_loss: 398.6109\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 277.9478 - val_loss: 397.4130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 277.7043 - val_loss: 396.3391\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 276.8195 - val_loss: 395.5530\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 276.4000 - val_loss: 394.8390\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 276.1345 - val_loss: 394.2739\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 275.4991 - val_loss: 393.9583\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 275.1370 - val_loss: 393.7559\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 274.7949 - val_loss: 393.5365\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 274.4803 - val_loss: 392.7431\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 274.0540 - val_loss: 391.7751\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 273.8944 - val_loss: 390.9259\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 273.5824 - val_loss: 390.6078\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 273.1166 - val_loss: 392.8194\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 273.3254 - val_loss: 389.3026\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 272.4756 - val_loss: 388.9369\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 272.2065 - val_loss: 388.3105\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 271.9027 - val_loss: 387.6160\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 271.7073 - val_loss: 386.8946\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 271.2464 - val_loss: 386.2761\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 271.3848 - val_loss: 385.6123\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 270.8405 - val_loss: 385.3017\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 270.5511 - val_loss: 384.8915\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 270.3669 - val_loss: 384.5612\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 270.0763 - val_loss: 384.4518\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 269.8918 - val_loss: 384.3818\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 269.6859 - val_loss: 384.1936\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 269.3872 - val_loss: 383.4910\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 269.1901 - val_loss: 382.8770\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 269.0223 - val_loss: 382.1818\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 268.8253 - val_loss: 381.8081\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 268.5386 - val_loss: 381.5233\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 268.4283 - val_loss: 381.3320\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 268.2074 - val_loss: 381.1033\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 268.3407 - val_loss: 380.4372\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 267.8298 - val_loss: 380.2770\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 267.6916 - val_loss: 380.0522\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 267.4190 - val_loss: 379.3759\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 267.3134 - val_loss: 378.5057\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 267.1360 - val_loss: 378.0370\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 266.8058 - val_loss: 377.8955\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 266.7729 - val_loss: 377.4442\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 266.4398 - val_loss: 377.3331\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 266.2469 - val_loss: 376.9936\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 265.9773 - val_loss: 376.6593\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 265.8631 - val_loss: 376.0778\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 265.7147 - val_loss: 375.9379\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 265.5700 - val_loss: 376.0209\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 265.3636 - val_loss: 375.7061\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 265.1191 - val_loss: 375.4980\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 265.0585 - val_loss: 375.1428\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 264.8668 - val_loss: 374.6930\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 265.0190 - val_loss: 374.5932\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 264.8610 - val_loss: 375.1312\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 264.5372 - val_loss: 375.0186\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 264.3760 - val_loss: 374.8899\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 264.2671 - val_loss: 374.7328\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 264.1958 - val_loss: 374.5797\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 264.2678 - val_loss: 374.5198\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 264.0155 - val_loss: 375.0317\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 263.8265 - val_loss: 375.8900\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 263.9137 - val_loss: 376.8767\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 263.9169 - val_loss: 377.4426\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 263.7338 - val_loss: 377.4583\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 263.7562 - val_loss: 377.3965\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 263.8573 - val_loss: 377.5739\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 263.3133 - val_loss: 376.3853\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 263.2632 - val_loss: 375.3480\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 262.8780 - val_loss: 375.2663\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 262.7955 - val_loss: 375.1720\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 262.5802 - val_loss: 376.1089\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 262.2772 - val_loss: 377.5802\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 263.0481 - val_loss: 378.8097\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 262.3046 - val_loss: 378.0180\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 262.3291 - val_loss: 377.7212\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 261.9505 - val_loss: 378.6373\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 261.6677 - val_loss: 380.9322\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 262.4768 - val_loss: 381.4229\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 261.6775 - val_loss: 379.2448\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 260.8616 - val_loss: 375.9300\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 260.9744 - val_loss: 373.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 261.7049 - val_loss: 371.4809\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 262.9341 - val_loss: 370.9186\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 262.3671 - val_loss: 372.3909\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 261.6978 - val_loss: 374.3589\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 260.8101 - val_loss: 375.5389\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 260.5002 - val_loss: 376.4287\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 260.0381 - val_loss: 377.9738\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 259.7726 - val_loss: 379.5163\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 259.5808 - val_loss: 381.0111\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 259.8240 - val_loss: 381.3274\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 260.0598 - val_loss: 380.6671\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 259.6468 - val_loss: 378.9640\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 259.7498 - val_loss: 378.0436\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 258.7309 - val_loss: 378.9264\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 258.5212 - val_loss: 379.6383\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 258.3134 - val_loss: 379.5893\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 258.3750 - val_loss: 379.3570\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 257.5338 - val_loss: 376.7695\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 257.3181 - val_loss: 373.7808\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 258.0110 - val_loss: 372.0956\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 258.3921 - val_loss: 372.2710\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 258.2832 - val_loss: 373.9744\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 257.7271 - val_loss: 375.7354\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 256.8305 - val_loss: 376.8392\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 256.9109 - val_loss: 379.3180\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 256.0414 - val_loss: 379.8956\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 255.7883 - val_loss: 380.0956\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 255.7883 - val_loss: 380.0992\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 255.5769 - val_loss: 378.4273\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 255.2356 - val_loss: 377.1479\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 255.0752 - val_loss: 375.3628\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 255.6013 - val_loss: 374.7032\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 255.1566 - val_loss: 376.8638\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 254.5402 - val_loss: 379.7870\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 254.6529 - val_loss: 381.3142\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 254.6688 - val_loss: 380.9579\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 253.9712 - val_loss: 382.0820\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 254.0749 - val_loss: 382.6531\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 253.5893 - val_loss: 380.7782\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 253.1920 - val_loss: 379.2702\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 252.9941 - val_loss: 379.7094\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 252.5374 - val_loss: 381.6313\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 252.2145 - val_loss: 386.1397\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 251.4259 - val_loss: 391.4197\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 253.6860 - val_loss: 391.9843\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 251.5767 - val_loss: 384.9680\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 252.1095 - val_loss: 380.0920\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 253.0803 - val_loss: 380.8886\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 251.5975 - val_loss: 380.4502\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 251.5161 - val_loss: 383.8689\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 250.7651 - val_loss: 388.5009\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 249.7894 - val_loss: 391.0643\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 251.2646 - val_loss: 391.9080\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 249.6215 - val_loss: 386.8525\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 249.3337 - val_loss: 382.6671\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 249.3512 - val_loss: 383.4413\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 248.8196 - val_loss: 386.9290\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 248.0256 - val_loss: 392.8432\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 248.9275 - val_loss: 394.4265\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 248.8828 - val_loss: 389.5720\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 248.4153 - val_loss: 381.8871\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 248.2539 - val_loss: 381.6193\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 248.1452 - val_loss: 383.9171\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 246.9251 - val_loss: 390.7845\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 247.9778 - val_loss: 393.1331\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 247.4763 - val_loss: 389.4310\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 246.0781 - val_loss: 380.1523\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 247.4948 - val_loss: 378.8133\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 247.4897 - val_loss: 386.2415\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 244.9919 - val_loss: 393.9921\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 244.8071 - val_loss: 400.1934\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 246.3697 - val_loss: 399.1319\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 243.8913 - val_loss: 385.8167\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 244.3698 - val_loss: 377.2577\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 246.9582 - val_loss: 378.1184\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 246.1248 - val_loss: 390.5311\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 243.1481 - val_loss: 402.2445\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 245.4399 - val_loss: 404.5834\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 245.0799 - val_loss: 394.3404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 242.8928 - val_loss: 389.3855\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 243.0513 - val_loss: 389.9371\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 242.3871 - val_loss: 389.1611\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 242.2126 - val_loss: 389.5205\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 241.9023 - val_loss: 393.9361\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 241.9055 - val_loss: 401.8156\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 241.4684 - val_loss: 402.0117\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 241.0802 - val_loss: 403.3374\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 241.5274 - val_loss: 402.3848\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 240.3562 - val_loss: 407.6297\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 240.2925 - val_loss: 416.0858\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 245.4486 - val_loss: 407.7387\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 239.8238 - val_loss: 386.0354\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 244.1603 - val_loss: 381.2837\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 242.3844 - val_loss: 392.1235\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 241.2582 - val_loss: 402.0479\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 240.7194 - val_loss: 408.0700\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 243.2311 - val_loss: 404.9597\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 240.8945 - val_loss: 401.0921\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 240.5143 - val_loss: 398.9237\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 240.1661 - val_loss: 392.6244\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 240.0087 - val_loss: 394.8687\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 238.5641 - val_loss: 408.8302\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 239.2615 - val_loss: 419.6493\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 240.6822 - val_loss: 422.6673\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 240.8244 - val_loss: 409.1978\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 238.1429 - val_loss: 401.1156\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 238.5484 - val_loss: 397.6872\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 237.9858 - val_loss: 402.3732\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 237.7743 - val_loss: 407.9999\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 237.3978 - val_loss: 409.2284\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 237.3934 - val_loss: 406.7434\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 237.2984 - val_loss: 405.6966\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 236.7145 - val_loss: 397.4121\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 237.0997 - val_loss: 397.2788\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 236.7976 - val_loss: 403.2816\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 236.0880 - val_loss: 406.7990\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 235.8961 - val_loss: 410.7493\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 233.9947 - val_loss: 416.1071\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 237.8637 - val_loss: 410.0199\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 235.9029 - val_loss: 405.3759\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 236.2975 - val_loss: 406.1857\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 234.6923 - val_loss: 420.7403\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 235.3937 - val_loss: 425.4300\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 236.4185 - val_loss: 410.5718\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 233.7413 - val_loss: 384.3854\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 237.5275 - val_loss: 387.0598\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 236.7244 - val_loss: 410.5475\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 233.8974 - val_loss: 421.3060\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 234.9476 - val_loss: 421.8476\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 234.8591 - val_loss: 415.7279\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 233.3567 - val_loss: 405.6389\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 232.8107 - val_loss: 400.3145\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 233.0149 - val_loss: 397.3747\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 232.7316 - val_loss: 395.2156\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 232.6929 - val_loss: 397.9298\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 232.6619 - val_loss: 406.6294\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 231.4277 - val_loss: 429.1699\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 232.4070 - val_loss: 433.9890\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 232.6680 - val_loss: 416.7729\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 231.9201 - val_loss: 400.5084\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 231.0939 - val_loss: 401.1300\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 231.7123 - val_loss: 411.8384\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 230.5169 - val_loss: 431.6349\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 233.0184 - val_loss: 421.0297\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 230.4719 - val_loss: 386.1656\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 232.6821 - val_loss: 382.2939\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 233.8701 - val_loss: 395.5488\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 231.1056 - val_loss: 429.6252\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 230.8062 - val_loss: 441.0472\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 233.4744 - val_loss: 428.9685\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 231.6408 - val_loss: 411.8910\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 230.7355 - val_loss: 405.4193\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 229.7986 - val_loss: 411.8573\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 229.6190 - val_loss: 418.5899\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 230.1121 - val_loss: 416.1109\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 229.2484 - val_loss: 402.2241\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 229.3431 - val_loss: 398.5627\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 229.7023 - val_loss: 402.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 229.4336 - val_loss: 407.8979\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 229.0516 - val_loss: 411.8314\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 228.9993 - val_loss: 419.1356\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 228.5110 - val_loss: 415.4926\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 228.7409 - val_loss: 412.8724\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 228.0468 - val_loss: 420.7188\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 227.9216 - val_loss: 426.6577\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 228.1456 - val_loss: 433.3272\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 229.3875 - val_loss: 420.0409\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 227.4045 - val_loss: 394.1849\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 228.5806 - val_loss: 405.3894\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 227.4277 - val_loss: 441.8644\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 230.0123 - val_loss: 395.5651\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 228.5409 - val_loss: 400.3603\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 226.5058 - val_loss: 432.8868\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 228.2880 - val_loss: 459.1876\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 229.7064 - val_loss: 440.2551\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 228.9938 - val_loss: 417.0858\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 226.8849 - val_loss: 409.0709\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 226.6614 - val_loss: 403.6759\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 226.9319 - val_loss: 405.5893\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 226.7933 - val_loss: 417.3302\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 226.2532 - val_loss: 427.1470\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 226.7597 - val_loss: 423.6250\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 226.3353 - val_loss: 408.8026\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 225.7812 - val_loss: 397.0815\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 227.0759 - val_loss: 405.5542\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 226.1369 - val_loss: 425.3042\n",
      "MAE: 18.273084377712674\n",
      "SMAPE: 14.784730794955914\n",
      "RMSE: 23.697661479993343\n",
      "R2 Score: -12.454744797465025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 6 data points for the rolling window\n",
    "window_size = 6\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb35c32",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ff3ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15934.9189 - val_loss: 14873.7979\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 15841.8291 - val_loss: 14780.8955\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15740.7812 - val_loss: 14694.2188\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15644.2168 - val_loss: 14614.3447\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15554.2227 - val_loss: 14536.2344\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 15464.4648 - val_loss: 14457.9131\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 15371.7793 - val_loss: 14377.6758\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 15274.3770 - val_loss: 14295.2539\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 15172.8604 - val_loss: 14209.9883\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15067.8447 - val_loss: 14118.3652\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 14958.3643 - val_loss: 14019.1035\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14845.3066 - val_loss: 13914.0908\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14728.0332 - val_loss: 13813.6074\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14611.2988 - val_loss: 13713.2646\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14497.0557 - val_loss: 13611.1729\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14381.3838 - val_loss: 13509.9746\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 14266.3877 - val_loss: 13411.3711\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 14153.5879 - val_loss: 13314.8115\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14042.5010 - val_loss: 13220.9854\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13934.0820 - val_loss: 13131.6895\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 13829.1504 - val_loss: 13042.5410\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13725.6836 - val_loss: 12951.0898\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13620.9316 - val_loss: 12856.0479\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 13514.0889 - val_loss: 12756.6357\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13404.5000 - val_loss: 12652.4893\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13291.9785 - val_loss: 12545.6143\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 13176.8975 - val_loss: 12436.4346\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 13061.3164 - val_loss: 12323.6348\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 12944.2783 - val_loss: 12207.1982\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 12824.9268 - val_loss: 12088.7354\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 12703.8418 - val_loss: 11966.8545\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 12580.8857 - val_loss: 11841.1055\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 12455.1631 - val_loss: 11713.6650\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 12328.1621 - val_loss: 11587.5947\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 12202.3311 - val_loss: 11463.0000\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12078.7832 - val_loss: 11337.8691\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11955.4092 - val_loss: 11211.8770\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 11830.9590 - val_loss: 11085.6963\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 11705.9893 - val_loss: 10959.0957\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11580.9268 - val_loss: 10831.3135\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11455.1104 - val_loss: 10702.2725\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11328.1738 - val_loss: 10572.6582\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11200.4668 - val_loss: 10444.1865\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11073.3232 - val_loss: 10317.8633\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10948.6338 - val_loss: 10192.7705\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 10826.2314 - val_loss: 10068.3184\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10705.0020 - val_loss: 9944.6777\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10584.6084 - val_loss: 9821.4707\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10464.7520 - val_loss: 9697.6963\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10345.1621 - val_loss: 9572.5303\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 10225.2520 - val_loss: 9446.6396\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10104.5518 - val_loss: 9320.7539\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9983.4092 - val_loss: 9195.7598\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9862.8311 - val_loss: 9073.1455\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9743.5732 - val_loss: 8951.6289\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9626.0527 - val_loss: 8830.6250\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9510.2852 - val_loss: 8710.3223\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9393.2363 - val_loss: 8590.5771\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9276.9824 - val_loss: 8472.2783\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9161.4209 - val_loss: 8357.0059\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9047.9736 - val_loss: 8246.3828\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8941.2979 - val_loss: 8138.8506\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8833.4824 - val_loss: 8034.5425\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8730.9785 - val_loss: 7930.8354\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8627.4688 - val_loss: 7827.1519\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8525.0869 - val_loss: 7722.6631\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8421.9336 - val_loss: 7620.4019\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8319.3867 - val_loss: 7524.4380\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8223.8818 - val_loss: 7432.8408\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8131.6074 - val_loss: 7342.5864\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8040.9370 - val_loss: 7252.7402\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7951.6938 - val_loss: 7162.6694\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7861.3838 - val_loss: 7074.0791\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7772.4707 - val_loss: 6987.1187\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7684.6592 - val_loss: 6905.2949\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7605.2612 - val_loss: 6822.4766\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7518.1001 - val_loss: 6744.2114\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 7437.1519 - val_loss: 6668.5679\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7359.2261 - val_loss: 6594.5317\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7282.7632 - val_loss: 6521.8877\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7208.0049 - val_loss: 6450.2656\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7135.1973 - val_loss: 6378.9771\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7063.0400 - val_loss: 6307.8110\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6990.8599 - val_loss: 6236.9844\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6918.9292 - val_loss: 6167.1167\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6847.6064 - val_loss: 6098.9487\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6777.6216 - val_loss: 6032.3179\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6708.8408 - val_loss: 5967.0229\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6640.9995 - val_loss: 5902.9238\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6574.1885 - val_loss: 5839.7490\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6508.3345 - val_loss: 5777.3252\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6443.2095 - val_loss: 5715.7349\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6378.7798 - val_loss: 5655.2979\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6315.3506 - val_loss: 5596.4980\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6253.4561 - val_loss: 5539.4941\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6193.0908 - val_loss: 5484.2524\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6134.1470 - val_loss: 5430.7744\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6076.9019 - val_loss: 5378.0015\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6020.6533 - val_loss: 5324.5981\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5964.0669 - val_loss: 5270.3647\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5906.9175 - val_loss: 5215.3486\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5849.2417 - val_loss: 5159.7314\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5791.1064 - val_loss: 5103.8569\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5732.7607 - val_loss: 5048.0342\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5674.4043 - val_loss: 4992.3672\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5616.0488 - val_loss: 4936.8394\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5557.6802 - val_loss: 4881.4429\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5499.3154 - val_loss: 4826.2793\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5440.9751 - val_loss: 4771.6924\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5382.9194 - val_loss: 4717.8862\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5325.7314 - val_loss: 4663.7080\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5269.0688 - val_loss: 4608.6685\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5212.1821 - val_loss: 4555.2251\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5156.6167 - val_loss: 4504.6230\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5103.4946 - val_loss: 4455.7212\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5052.0972 - val_loss: 4407.4131\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5001.4390 - val_loss: 4359.1587\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4950.8657 - val_loss: 4310.6772\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4900.0220 - val_loss: 4261.9634\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4848.8218 - val_loss: 4213.3140\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4797.4927 - val_loss: 4165.2480\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4746.5918 - val_loss: 4118.1172\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4696.6855 - val_loss: 4071.6050\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4647.7456 - val_loss: 4024.9788\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4599.1938 - val_loss: 3977.5874\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4550.3525 - val_loss: 3929.1011\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4500.6167 - val_loss: 3879.6892\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4449.6699 - val_loss: 3829.9653\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4397.7783 - val_loss: 3780.4607\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4345.6597 - val_loss: 3731.5151\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4293.6943 - val_loss: 3683.7542\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4242.4971 - val_loss: 3637.8616\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4192.9746 - val_loss: 3594.1489\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4145.7402 - val_loss: 3552.4304\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4100.7114 - val_loss: 3512.3367\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4057.5598 - val_loss: 3473.3489\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4015.8118 - val_loss: 3435.0698\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3974.9292 - val_loss: 3397.2734\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3934.6675 - val_loss: 3359.7874\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3894.8042 - val_loss: 3322.4849\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3855.1917 - val_loss: 3285.4421\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3815.8025 - val_loss: 3248.7244\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3776.6677 - val_loss: 3212.4150\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3737.9016 - val_loss: 3176.6138\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3699.6912 - val_loss: 3141.4048\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3661.8953 - val_loss: 3106.9067\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3624.7805 - val_loss: 3072.9021\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3588.3503 - val_loss: 3039.1394\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3552.2141 - val_loss: 3005.5850\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3516.3179 - val_loss: 2972.2644\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3480.7109 - val_loss: 2939.1787\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3445.3386 - val_loss: 2906.3369\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3410.1787 - val_loss: 2873.8796\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3375.2236 - val_loss: 2841.9365\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 3340.6094 - val_loss: 2809.6763\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3305.9932 - val_loss: 2777.4202\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3271.5815 - val_loss: 2745.4526\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3237.5828 - val_loss: 2713.7766\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3203.9558 - val_loss: 2682.2983\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3170.5271 - val_loss: 2651.0774\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3137.2302 - val_loss: 2620.2588\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3104.2454 - val_loss: 2589.8938\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3071.6750 - val_loss: 2560.0530\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3039.5283 - val_loss: 2530.8110\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3007.9026 - val_loss: 2502.1516\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2976.8459 - val_loss: 2473.9583\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2946.3005 - val_loss: 2446.0803\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2916.1526 - val_loss: 2418.4006\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2886.2532 - val_loss: 2390.8970\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2856.4973 - val_loss: 2363.5850\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2826.8889 - val_loss: 2336.6160\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2797.4792 - val_loss: 2310.2339\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2768.5847 - val_loss: 2284.4426\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2740.4495 - val_loss: 2259.0476\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2712.8345 - val_loss: 2233.9399\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2685.5303 - val_loss: 2209.0625\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2658.4666 - val_loss: 2184.3511\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2631.5813 - val_loss: 2159.7317\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2604.7959 - val_loss: 2135.1160\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2578.0156 - val_loss: 2110.4714\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2551.1807 - val_loss: 2086.0559\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2524.4580 - val_loss: 2062.7336\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2498.6077 - val_loss: 2040.8090\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2474.2180 - val_loss: 2018.2865\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2449.5381 - val_loss: 1995.1178\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2424.3462 - val_loss: 1971.9106\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2399.2437 - val_loss: 1949.2268\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2374.7524 - val_loss: 1927.2107\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2350.8928 - val_loss: 1905.5194\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2327.2673 - val_loss: 1883.8700\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2303.6182 - val_loss: 1862.2538\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2279.9822 - val_loss: 1840.8342\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2256.5278 - val_loss: 1819.7522\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2233.3682 - val_loss: 1799.0648\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2210.5859 - val_loss: 1778.7509\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2188.1958 - val_loss: 1758.7540\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2166.1362 - val_loss: 1739.0331\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2144.3438 - val_loss: 1719.5660\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2122.7959 - val_loss: 1700.3396\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2101.4932 - val_loss: 1681.3448\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2080.4417 - val_loss: 1662.5748\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2059.6443 - val_loss: 1644.0251\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2039.0972 - val_loss: 1625.6914\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2018.7916 - val_loss: 1607.5712\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1998.7206 - val_loss: 1589.6625\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1978.8771 - val_loss: 1571.9612\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1959.2550 - val_loss: 1554.4656\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1939.8505 - val_loss: 1537.1735\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1920.6602 - val_loss: 1520.0802\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1901.6788 - val_loss: 1503.1841\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1882.9042 - val_loss: 1486.4821\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1864.3328 - val_loss: 1469.9716\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1845.9612 - val_loss: 1453.6486\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1827.7854 - val_loss: 1437.5123\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1809.8049 - val_loss: 1421.5602\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1792.0171 - val_loss: 1405.7897\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1774.4191 - val_loss: 1390.1986\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1757.0095 - val_loss: 1374.7858\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1739.7867 - val_loss: 1359.5516\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1722.7511 - val_loss: 1344.4972\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1705.9042 - val_loss: 1329.6222\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1689.2452 - val_loss: 1314.9255\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1672.7738 - val_loss: 1300.4062\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1656.4880 - val_loss: 1286.0604\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1640.3848 - val_loss: 1271.8867\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1624.4623 - val_loss: 1257.8821\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1608.7177 - val_loss: 1244.0430\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1593.1479 - val_loss: 1230.3685\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1577.7516 - val_loss: 1216.8557\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1562.5255 - val_loss: 1203.5028\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1547.4680 - val_loss: 1190.3082\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 1532.5765 - val_loss: 1177.2695\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1517.8497 - val_loss: 1164.3849\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1503.2852 - val_loss: 1151.6530\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1488.8821 - val_loss: 1139.0717\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1474.6370 - val_loss: 1126.6409\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1460.5503 - val_loss: 1114.3578\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1446.6190 - val_loss: 1102.2214\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1432.8427 - val_loss: 1090.2294\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1419.2186 - val_loss: 1078.3815\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1405.7458 - val_loss: 1066.6749\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1392.4224 - val_loss: 1055.1090\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1379.2468 - val_loss: 1043.6816\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1366.2185 - val_loss: 1032.3920\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1353.3351 - val_loss: 1021.2392\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1340.5958 - val_loss: 1010.2200\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1327.9982 - val_loss: 999.3340\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1315.5416 - val_loss: 988.5802\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1303.2247 - val_loss: 977.9575\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1291.0461 - val_loss: 967.4625\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1279.0034 - val_loss: 957.0958\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1267.0966 - val_loss: 946.8561\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1255.3235 - val_loss: 936.7411\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1243.6833 - val_loss: 926.7499\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1232.1738 - val_loss: 916.8823\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1220.7952 - val_loss: 907.1354\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1209.5446 - val_loss: 897.5091\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1198.4219 - val_loss: 888.0020\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1187.4255 - val_loss: 878.6122\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1176.5536 - val_loss: 869.3393\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1165.8059 - val_loss: 860.1810\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1155.1802 - val_loss: 851.1365\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1144.6760 - val_loss: 842.2053\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1134.2916 - val_loss: 833.3860\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1124.0262 - val_loss: 824.6775\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1113.8789 - val_loss: 816.0782\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1103.8475 - val_loss: 807.5875\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1093.9319 - val_loss: 799.2040\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1084.1306 - val_loss: 790.9263\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1074.4418 - val_loss: 782.7538\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1064.8654 - val_loss: 774.6850\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1055.3997 - val_loss: 766.7191\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1046.0435 - val_loss: 758.8547\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1036.7963 - val_loss: 751.0905\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1027.6560 - val_loss: 743.4265\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1018.6225 - val_loss: 735.8610\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1009.6948 - val_loss: 728.3928\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1000.8711 - val_loss: 721.0214\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 992.1506 - val_loss: 713.7452\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 983.5322 - val_loss: 706.5635\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 975.0150 - val_loss: 699.4755\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 966.5981 - val_loss: 692.4801\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 958.2806 - val_loss: 685.5760\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 950.0610 - val_loss: 678.7625\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 941.9385 - val_loss: 672.0381\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 933.9125 - val_loss: 665.4025\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 925.9813 - val_loss: 658.8547\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 918.1447 - val_loss: 652.3932\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 910.4012 - val_loss: 646.0179\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 902.7501 - val_loss: 639.7276\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 895.1906 - val_loss: 633.5208\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 887.7211 - val_loss: 627.3976\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 880.3417 - val_loss: 621.3561\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 873.0502 - val_loss: 615.3958\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 865.8467 - val_loss: 609.5162\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 858.7302 - val_loss: 603.7156\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 851.6993 - val_loss: 597.9941\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 844.7538 - val_loss: 592.3502\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 837.8922 - val_loss: 586.7833\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 831.1140 - val_loss: 581.2924\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 824.4181 - val_loss: 575.8767\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 817.8036 - val_loss: 570.5357\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 811.2702 - val_loss: 565.2682\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 804.8163 - val_loss: 560.0735\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 798.4420 - val_loss: 554.9504\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 792.1451 - val_loss: 549.8986\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 785.9257 - val_loss: 544.9173\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 779.7833 - val_loss: 540.0058\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 773.7164 - val_loss: 535.1629\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 767.7245 - val_loss: 530.3880\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 761.8067 - val_loss: 525.6806\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 755.9625 - val_loss: 521.0395\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 750.1906 - val_loss: 516.4642\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 744.4907 - val_loss: 511.9542\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 738.8621 - val_loss: 507.5081\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 733.3036 - val_loss: 503.1258\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 727.8147 - val_loss: 498.8063\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 722.3947 - val_loss: 494.5488\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 717.0425 - val_loss: 490.3528\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 711.7578 - val_loss: 486.2176\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 706.5400 - val_loss: 482.1424\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 701.3879 - val_loss: 478.1263\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 696.3009 - val_loss: 474.1690\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 691.2785 - val_loss: 470.2698\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 686.3202 - val_loss: 466.4274\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 681.4244 - val_loss: 462.6420\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 676.5914 - val_loss: 458.9123\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 671.8201 - val_loss: 455.2383\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 667.1100 - val_loss: 451.6185\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 662.4599 - val_loss: 448.0530\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 657.8698 - val_loss: 444.5406\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 653.3387 - val_loss: 441.0809\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 648.8659 - val_loss: 437.6736\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 644.4511 - val_loss: 434.3173\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 640.0931 - val_loss: 431.0122\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 635.7920 - val_loss: 427.7573\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 631.5466 - val_loss: 424.5522\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 627.3565 - val_loss: 421.3960\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 623.2209 - val_loss: 418.2883\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 619.1394 - val_loss: 415.2284\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 615.1113 - val_loss: 412.2157\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 611.1360 - val_loss: 409.2499\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 607.2128 - val_loss: 406.3301\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 603.3414 - val_loss: 403.4560\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 599.5211 - val_loss: 400.6268\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 595.7510 - val_loss: 397.8419\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 592.0311 - val_loss: 395.1010\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 588.3601 - val_loss: 392.4037\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 584.7380 - val_loss: 389.7492\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 581.1643 - val_loss: 387.1368\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 577.6380 - val_loss: 384.5661\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 574.1588 - val_loss: 382.0367\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 570.7264 - val_loss: 379.5482\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 567.3395 - val_loss: 377.1000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 563.9986 - val_loss: 374.6913\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 560.7023 - val_loss: 372.3216\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 557.4503 - val_loss: 369.9903\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 554.2419 - val_loss: 367.6971\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 551.0768 - val_loss: 365.4419\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 547.9550 - val_loss: 363.2232\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 544.8742 - val_loss: 361.0415\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 541.8355 - val_loss: 358.8954\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 538.8375 - val_loss: 356.7842\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 535.8796 - val_loss: 354.7074\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 532.9606 - val_loss: 352.6639\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 530.0801 - val_loss: 350.6525\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 527.2366 - val_loss: 348.6719\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 524.4288 - val_loss: 346.7206\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 521.6562 - val_loss: 344.7980\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 518.9184 - val_loss: 342.8997\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 516.2111 - val_loss: 341.0265\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 513.5393 - val_loss: 339.1774\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 510.9055 - val_loss: 337.3611\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 508.3219 - val_loss: 335.5941\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 505.7995 - val_loss: 333.8701\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 503.3090 - val_loss: 332.1734\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 500.8323 - val_loss: 330.5076\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 498.3802 - val_loss: 328.8786\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 495.9647 - val_loss: 327.2858\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 493.5895 - val_loss: 325.7245\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 491.2535 - val_loss: 324.1893\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 488.9525 - val_loss: 322.6778\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 486.6855 - val_loss: 321.1860\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 484.4447 - val_loss: 319.7153\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 482.2345 - val_loss: 318.2639\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 480.0528 - val_loss: 316.8324\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 477.9005 - val_loss: 315.4224\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 475.7788 - val_loss: 314.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 473.6893 - val_loss: 312.6779\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 471.6320 - val_loss: 311.3488\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 469.6069 - val_loss: 310.0486\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 467.6086 - val_loss: 308.7776\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 465.6368 - val_loss: 307.5353\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 463.6918 - val_loss: 306.3204\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 461.7740 - val_loss: 305.1316\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 459.8845 - val_loss: 303.9662\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 458.0233 - val_loss: 302.8224\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 456.1906 - val_loss: 301.6973\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 454.3839 - val_loss: 300.5891\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 452.6028 - val_loss: 299.4974\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 450.8471 - val_loss: 298.4214\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 449.1159 - val_loss: 297.3624\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 447.4097 - val_loss: 296.3220\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 445.7285 - val_loss: 295.3021\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 444.0726 - val_loss: 294.3041\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 442.4410 - val_loss: 293.3287\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 440.8334 - val_loss: 292.3759\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 439.2487 - val_loss: 291.4453\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 437.6867 - val_loss: 290.5358\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 436.1469 - val_loss: 289.6468\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 434.6295 - val_loss: 288.7762\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 433.1341 - val_loss: 287.9225\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 431.6602 - val_loss: 287.0834\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 430.2072 - val_loss: 286.2571\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 428.7737 - val_loss: 285.4422\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 427.3592 - val_loss: 284.6374\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 425.9624 - val_loss: 283.8412\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 424.5811 - val_loss: 283.0510\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 423.2133 - val_loss: 282.2623\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 421.8558 - val_loss: 281.4675\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 420.5040 - val_loss: 280.6564\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 419.1554 - val_loss: 279.8185\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 417.8116 - val_loss: 278.9550\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 416.4899 - val_loss: 278.1006\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 415.2282 - val_loss: 277.3262\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 414.0586 - val_loss: 276.6476\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 412.9210 - val_loss: 276.0064\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 411.7423 - val_loss: 275.3905\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 410.5356 - val_loss: 274.8159\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 409.3408 - val_loss: 274.2863\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 408.1840 - val_loss: 273.7856\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 407.0685 - val_loss: 273.2915\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 405.9835 - val_loss: 272.7881\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 404.9168 - val_loss: 272.2687\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 403.8607 - val_loss: 271.7325\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 402.8119 - val_loss: 271.1810\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 401.7701 - val_loss: 270.6181\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 400.7379 - val_loss: 270.0500\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 399.7198 - val_loss: 269.4862\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 398.7204 - val_loss: 268.9377\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 397.7435 - val_loss: 268.4139\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 396.7889 - val_loss: 267.9194\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 395.8520 - val_loss: 267.4537\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 394.9269 - val_loss: 267.0145\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 394.0097 - val_loss: 266.5992\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 393.1012 - val_loss: 266.2063\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 392.2050 - val_loss: 265.8318\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 391.3240 - val_loss: 265.4704\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 390.4596 - val_loss: 265.1153\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 389.6111 - val_loss: 264.7601\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 388.7757 - val_loss: 264.4005\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 387.9518 - val_loss: 264.0343\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 387.1377 - val_loss: 263.6617\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 386.3327 - val_loss: 263.2846\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 385.5372 - val_loss: 262.9059\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 384.7516 - val_loss: 262.5287\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 383.9757 - val_loss: 262.1559\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 383.2090 - val_loss: 261.7881\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 382.4500 - val_loss: 261.4242\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 381.6966 - val_loss: 261.0607\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 380.9461 - val_loss: 260.6927\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 380.1969 - val_loss: 260.3136\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 379.4486 - val_loss: 259.9181\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 378.7032 - val_loss: 259.5048\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 377.9667 - val_loss: 259.0810\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 377.2496 - val_loss: 258.6649\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 376.5648 - val_loss: 258.2810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 375.9215 - val_loss: 257.9461\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 375.3168 - val_loss: 257.6595\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 374.7319 - val_loss: 257.4067\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 374.1426 - val_loss: 257.1749\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 373.5352 - val_loss: 256.9620\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 372.9120 - val_loss: 256.7737\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 372.2874 - val_loss: 256.6145\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 371.6770 - val_loss: 256.4811\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 371.0895 - val_loss: 256.3634\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 370.5253 - val_loss: 256.2485\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 369.9799 - val_loss: 256.1260\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 369.4469 - val_loss: 255.9898\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 368.9213 - val_loss: 255.8370\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 368.3997 - val_loss: 255.6676\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 367.8808 - val_loss: 255.4831\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 367.3651 - val_loss: 255.2868\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 366.8536 - val_loss: 255.0833\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 366.3490 - val_loss: 254.8782\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 365.8531 - val_loss: 254.6777\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 365.3683 - val_loss: 254.4875\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 364.8952 - val_loss: 254.3120\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 364.4336 - val_loss: 254.1530\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 363.9813 - val_loss: 254.0109\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 363.5362 - val_loss: 253.8850\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 363.0962 - val_loss: 253.7737\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 362.6607 - val_loss: 253.6758\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 362.2300 - val_loss: 253.5898\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 361.8055 - val_loss: 253.5136\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 361.3882 - val_loss: 253.4446\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 360.9792 - val_loss: 253.3798\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 360.5781 - val_loss: 253.3162\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 360.1850 - val_loss: 253.2512\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 359.7988 - val_loss: 253.1830\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019A7F6FAA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE: 15.832860565185545\n",
      "SMAPE: 12.27234557231933\n",
      "RMSE: 21.855071530581508\n",
      "R2 Score: -30.552946901232545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 4 data points for the rolling window\n",
    "window_size = 4\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d10e3",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b07654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15806.3291 - val_loss: 14562.9336\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15694.7939 - val_loss: 14447.2666\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15571.8252 - val_loss: 14341.2549\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15453.2764 - val_loss: 14253.6865\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15346.3096 - val_loss: 14166.6211\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 15237.4678 - val_loss: 14077.9951\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 15122.9717 - val_loss: 13989.4561\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15004.8779 - val_loss: 13901.9814\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14884.4180 - val_loss: 13815.4873\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14763.8760 - val_loss: 13730.2178\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14647.1289 - val_loss: 13644.8545\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14534.7861 - val_loss: 13559.6602\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 14425.3018 - val_loss: 13468.0498\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 14310.3477 - val_loss: 13379.7822\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14197.2822 - val_loss: 13291.7393\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14087.4102 - val_loss: 13201.5781\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13977.1143 - val_loss: 13108.0820\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13865.1572 - val_loss: 13011.6211\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13751.5029 - val_loss: 12912.0752\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 13636.7236 - val_loss: 12809.4873\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 13521.1807 - val_loss: 12702.8018\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13403.9014 - val_loss: 12591.6357\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 13284.6650 - val_loss: 12474.7939\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 13162.8232 - val_loss: 12362.0732\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13054.7666 - val_loss: 12232.0068\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12914.7686 - val_loss: 12114.9248\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12791.4268 - val_loss: 11999.1377\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12671.8359 - val_loss: 11881.9648\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12552.3252 - val_loss: 11763.3789\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12432.5898 - val_loss: 11642.6436\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 12312.2939 - val_loss: 11526.3740\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12191.6377 - val_loss: 11397.0117\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12069.5127 - val_loss: 11263.1064\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11943.9287 - val_loss: 11124.8799\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11814.5830 - val_loss: 10980.0986\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11681.2227 - val_loss: 10830.1289\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11542.5342 - val_loss: 10676.1016\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11397.2588 - val_loss: 10514.5283\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11244.8467 - val_loss: 10347.5205\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11086.8115 - val_loss: 10186.9961\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10927.8213 - val_loss: 10038.8359\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10774.5195 - val_loss: 9886.2256\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10629.6943 - val_loss: 9740.2324\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 10491.8770 - val_loss: 9602.9658\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10358.9795 - val_loss: 9466.7705\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10229.2461 - val_loss: 9333.0996\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10103.0518 - val_loss: 9208.0332\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9982.2256 - val_loss: 9091.6758\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9866.6934 - val_loss: 8981.3398\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9755.5400 - val_loss: 8873.1611\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9646.8691 - val_loss: 8763.8398\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9538.9316 - val_loss: 8658.9268\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9433.3125 - val_loss: 8557.7129\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9330.7295 - val_loss: 8457.2412\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9230.0703 - val_loss: 8361.1982\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9132.4131 - val_loss: 8266.1338\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9037.5898 - val_loss: 8170.9819\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8944.9229 - val_loss: 8079.1812\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8854.2246 - val_loss: 7992.0356\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8764.6816 - val_loss: 7909.8965\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8677.3281 - val_loss: 7829.1313\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8591.6582 - val_loss: 7746.3794\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8507.6650 - val_loss: 7660.3101\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8424.9248 - val_loss: 7576.4512\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8343.2168 - val_loss: 7495.5718\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8262.5674 - val_loss: 7415.0649\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8182.6484 - val_loss: 7333.3530\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8102.6562 - val_loss: 7253.0454\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8023.0874 - val_loss: 7176.4258\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7945.2749 - val_loss: 7102.0376\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7870.1313 - val_loss: 7028.5000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7796.4712 - val_loss: 6956.1821\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7723.6919 - val_loss: 6885.2617\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7651.6313 - val_loss: 6815.8105\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7580.4429 - val_loss: 6747.7319\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7510.2676 - val_loss: 6680.9062\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7441.4741 - val_loss: 6615.0449\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 7373.4673 - val_loss: 6549.9160\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 7305.6655 - val_loss: 6485.5215\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7238.7134 - val_loss: 6421.8882\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7172.3110 - val_loss: 6359.7603\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7107.0723 - val_loss: 6299.3267\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7043.6274 - val_loss: 6239.2642\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6981.1704 - val_loss: 6179.3833\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6919.3530 - val_loss: 6119.7856\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6857.8301 - val_loss: 6060.4624\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6796.2759 - val_loss: 6001.5024\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6734.8950 - val_loss: 5942.4351\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6673.7671 - val_loss: 5883.6812\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6613.0962 - val_loss: 5825.7515\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6553.2446 - val_loss: 5768.6460\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6494.2280 - val_loss: 5711.0044\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6435.5728 - val_loss: 5653.4785\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6377.0659 - val_loss: 5595.6934\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6318.3882 - val_loss: 5537.3735\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6259.3457 - val_loss: 5477.5449\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6199.7339 - val_loss: 5417.4810\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6139.8892 - val_loss: 5357.8052\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6080.1626 - val_loss: 5298.6025\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6020.4922 - val_loss: 5239.7305\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5960.8008 - val_loss: 5180.8101\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5901.1079 - val_loss: 5121.9512\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5841.4038 - val_loss: 5063.2012\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5781.5249 - val_loss: 5004.8022\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5721.6812 - val_loss: 4946.7778\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5662.1875 - val_loss: 4889.2129\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5603.0288 - val_loss: 4832.4995\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5544.1655 - val_loss: 4777.0547\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5485.9282 - val_loss: 4723.1689\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5428.8096 - val_loss: 4670.8169\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5373.2031 - val_loss: 4619.9307\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5319.3350 - val_loss: 4570.2827\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5266.9399 - val_loss: 4521.6245\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5215.4702 - val_loss: 4473.8569\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5164.7358 - val_loss: 4427.0278\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5114.9009 - val_loss: 4380.9966\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5065.9722 - val_loss: 4335.6714\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5017.7974 - val_loss: 4291.1694\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4970.2324 - val_loss: 4247.6406\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4923.2886 - val_loss: 4204.6294\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4876.8960 - val_loss: 4161.3706\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4830.6616 - val_loss: 4117.8271\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4784.5239 - val_loss: 4074.1472\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4738.5391 - val_loss: 4030.4500\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4692.7041 - val_loss: 3986.6379\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4646.8755 - val_loss: 3942.4114\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4600.8022 - val_loss: 3897.6289\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 4554.2710 - val_loss: 3852.6707\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4507.3525 - val_loss: 3808.2996\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4460.5303 - val_loss: 3764.9910\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4414.3086 - val_loss: 3722.8699\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4368.9761 - val_loss: 3681.8906\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4324.7202 - val_loss: 3641.8691\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4281.4463 - val_loss: 3602.6692\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4239.2734 - val_loss: 3564.0840\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4197.4688 - val_loss: 3526.0559\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4156.3926 - val_loss: 3488.6885\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4115.9404 - val_loss: 3451.9285\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4076.1594 - val_loss: 3415.5291\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4036.8938 - val_loss: 3379.5364\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3997.9734 - val_loss: 3344.2766\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3959.4785 - val_loss: 3309.9036\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3921.7161 - val_loss: 3276.2659\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3884.9727 - val_loss: 3243.0527\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3848.8313 - val_loss: 3210.1565\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3813.2190 - val_loss: 3177.4348\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3777.9031 - val_loss: 3144.8821\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3742.8562 - val_loss: 3112.4385\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3707.8848 - val_loss: 3080.1316\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3673.0312 - val_loss: 3048.0022\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3638.2695 - val_loss: 3016.1750\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3603.6934 - val_loss: 2984.7747\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3569.4558 - val_loss: 2953.8718\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3535.6924 - val_loss: 2923.4597\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 3502.4580 - val_loss: 2893.4954\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3469.7351 - val_loss: 2863.9329\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3437.4846 - val_loss: 2834.7334\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3405.6653 - val_loss: 2805.8977\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3374.2698 - val_loss: 2777.4407\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3343.2859 - val_loss: 2749.2996\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3312.6150 - val_loss: 2721.4668\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3282.2598 - val_loss: 2693.9397\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3252.2375 - val_loss: 2666.6826\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3222.5168 - val_loss: 2639.6899\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3193.0840 - val_loss: 2612.9780\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3163.9504 - val_loss: 2586.5454\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3135.1104 - val_loss: 2560.3711\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3106.5320 - val_loss: 2534.4565\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3078.2166 - val_loss: 2508.8066\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3050.1750 - val_loss: 2483.4155\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3022.4045 - val_loss: 2458.2632\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2994.8867 - val_loss: 2433.3381\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2967.6116 - val_loss: 2408.6560\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2940.6003 - val_loss: 2384.1787\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2913.7942 - val_loss: 2359.9209\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2887.2058 - val_loss: 2335.8655\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2860.8230 - val_loss: 2311.9883\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2834.6213 - val_loss: 2288.2666\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2808.5771 - val_loss: 2264.6885\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2782.6787 - val_loss: 2241.2612\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2756.9343 - val_loss: 2218.0134\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2731.3523 - val_loss: 2194.9756\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2705.9873 - val_loss: 2172.1631\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2680.8801 - val_loss: 2149.5596\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2656.0298 - val_loss: 2127.1211\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2631.3987 - val_loss: 2104.7852\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2606.8982 - val_loss: 2082.5176\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2582.4331 - val_loss: 2060.3457\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2557.9875 - val_loss: 2038.3746\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2533.6411 - val_loss: 2016.7408\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2509.5642 - val_loss: 1995.5316\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2485.9128 - val_loss: 1974.7578\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2462.7400 - val_loss: 1954.3588\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2440.0127 - val_loss: 1934.2650\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2417.6602 - val_loss: 1914.4183\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2395.6016 - val_loss: 1894.8048\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2373.8054 - val_loss: 1875.4127\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2352.2432 - val_loss: 1856.2303\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2330.9036 - val_loss: 1837.2476\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2309.7783 - val_loss: 1818.4613\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2288.8638 - val_loss: 1799.8717\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2268.1565 - val_loss: 1781.4774\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2247.6536 - val_loss: 1763.2789\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2227.3540 - val_loss: 1745.2738\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2207.2544 - val_loss: 1727.4594\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2187.3535 - val_loss: 1709.8344\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2167.6509 - val_loss: 1692.3950\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2148.1431 - val_loss: 1675.1390\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2128.8291 - val_loss: 1658.0654\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2109.7058 - val_loss: 1641.1748\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2090.7744 - val_loss: 1624.4655\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2072.0310 - val_loss: 1607.9354\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2053.4746 - val_loss: 1591.5831\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2035.1041 - val_loss: 1575.4059\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2016.9170 - val_loss: 1559.4009\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1998.9115 - val_loss: 1543.5669\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1981.0861 - val_loss: 1527.9017\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1963.4388 - val_loss: 1512.4059\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1945.9689 - val_loss: 1497.0768\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1928.6742 - val_loss: 1481.9132\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1911.5522 - val_loss: 1466.9136\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1894.6024 - val_loss: 1452.0746\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1877.8228 - val_loss: 1437.3929\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1861.2098 - val_loss: 1422.8668\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1844.7614 - val_loss: 1408.4962\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1828.4762 - val_loss: 1394.2821\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1812.3502 - val_loss: 1380.2266\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1796.3848 - val_loss: 1366.3292\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1780.5831 - val_loss: 1352.5862\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1764.9503 - val_loss: 1338.9945\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1749.4790 - val_loss: 1325.5513\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 1734.1652 - val_loss: 1312.2557\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1719.0065 - val_loss: 1299.1056\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1704.0013 - val_loss: 1286.0999\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1689.1488 - val_loss: 1273.2374\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1674.4473 - val_loss: 1260.5173\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1659.8959 - val_loss: 1247.9381\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1645.4928 - val_loss: 1235.4983\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1631.2363 - val_loss: 1223.1964\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1617.1256 - val_loss: 1211.0312\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1603.1592 - val_loss: 1199.0011\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1589.3356 - val_loss: 1187.1051\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1575.6539 - val_loss: 1175.3417\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1562.1128 - val_loss: 1163.7102\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1548.7109 - val_loss: 1152.2090\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1535.4469 - val_loss: 1140.8368\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1522.3190 - val_loss: 1129.5923\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1509.3265 - val_loss: 1118.4746\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1496.4681 - val_loss: 1107.4827\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1483.7433 - val_loss: 1096.6150\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1471.1498 - val_loss: 1085.8706\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1458.6870 - val_loss: 1075.2478\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1446.3531 - val_loss: 1064.7462\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1434.1481 - val_loss: 1054.3639\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1422.0698 - val_loss: 1044.1001\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1410.1173 - val_loss: 1033.9542\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1398.2899 - val_loss: 1023.9246\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1386.5858 - val_loss: 1014.0106\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1375.0043 - val_loss: 1004.2107\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1363.5446 - val_loss: 994.5236\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1352.2047 - val_loss: 984.9490\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1340.9845 - val_loss: 975.4850\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1329.8822 - val_loss: 966.1312\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1318.8971 - val_loss: 956.8863\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1308.0281 - val_loss: 947.7492\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1297.2739 - val_loss: 938.7186\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1286.6337 - val_loss: 929.7939\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1276.1063 - val_loss: 920.9739\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1265.6907 - val_loss: 912.2579\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1255.3862 - val_loss: 903.6448\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1245.1914 - val_loss: 895.1335\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1235.1056 - val_loss: 886.7231\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1225.1279 - val_loss: 878.4128\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1215.2570 - val_loss: 870.2012\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1205.4918 - val_loss: 862.0876\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1195.8315 - val_loss: 854.0713\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1186.2754 - val_loss: 846.1512\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1176.8221 - val_loss: 838.3261\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1167.4712 - val_loss: 830.5955\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1158.2213 - val_loss: 822.9585\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1149.0717 - val_loss: 815.4135\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1140.0212 - val_loss: 807.9603\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1131.0692 - val_loss: 800.5980\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1122.2148 - val_loss: 793.3256\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1113.4572 - val_loss: 786.1418\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1104.7947 - val_loss: 779.0461\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1096.2275 - val_loss: 772.0378\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1087.7540 - val_loss: 765.1161\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1079.3739 - val_loss: 758.2796\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1071.0857 - val_loss: 751.5280\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1062.8888 - val_loss: 744.8604\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1054.7826 - val_loss: 738.2756\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1046.7657 - val_loss: 731.7734\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1038.8383 - val_loss: 725.3527\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1030.9984 - val_loss: 719.0125\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1023.2458 - val_loss: 712.7521\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1015.5795 - val_loss: 706.5706\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1007.9987 - val_loss: 700.4675\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1000.5027 - val_loss: 694.4419\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 993.0906 - val_loss: 688.4929\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 985.7617 - val_loss: 682.6200\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 978.5154 - val_loss: 676.8218\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 971.3503 - val_loss: 671.0986\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 964.2662 - val_loss: 665.4484\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 957.2618 - val_loss: 659.8715\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 950.3373 - val_loss: 654.3667\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 943.4910 - val_loss: 648.9332\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 936.7225 - val_loss: 643.5704\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 930.0310 - val_loss: 638.2775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 923.4157 - val_loss: 633.0540\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 916.8763 - val_loss: 627.8985\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 910.4113 - val_loss: 622.8112\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 904.0206 - val_loss: 617.7910\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 897.7032 - val_loss: 612.8371\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 891.4588 - val_loss: 607.9487\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 885.2858 - val_loss: 603.1255\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 879.1848 - val_loss: 598.3666\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 873.1540 - val_loss: 593.6717\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 867.1933 - val_loss: 589.0394\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 861.3015 - val_loss: 584.4695\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 855.4783 - val_loss: 579.9614\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 849.7231 - val_loss: 575.5142\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 844.0350 - val_loss: 571.1273\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 838.4133 - val_loss: 566.8002\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 832.8577 - val_loss: 562.5325\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 827.3672 - val_loss: 558.3229\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 821.9414 - val_loss: 554.1713\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 816.5793 - val_loss: 550.0770\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 811.2808 - val_loss: 546.0389\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 806.0444 - val_loss: 542.0572\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 800.8704 - val_loss: 538.1306\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 795.7579 - val_loss: 534.2590\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 790.7060 - val_loss: 530.4415\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 785.7143 - val_loss: 526.6777\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 780.7820 - val_loss: 522.9666\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 775.9090 - val_loss: 519.3082\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 771.0942 - val_loss: 515.7017\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 766.3376 - val_loss: 512.1462\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 761.6371 - val_loss: 508.6417\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 756.9941 - val_loss: 505.1870\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 752.4067 - val_loss: 501.7823\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 747.8751 - val_loss: 498.4262\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 743.3980 - val_loss: 495.1189\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 738.9755 - val_loss: 491.8595\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 734.6067 - val_loss: 488.6472\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 730.2908 - val_loss: 485.4819\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 726.0276 - val_loss: 482.3630\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 721.8167 - val_loss: 479.2897\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 717.6570 - val_loss: 476.2617\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 713.5486 - val_loss: 473.2787\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 709.4908 - val_loss: 470.3396\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 705.4827 - val_loss: 467.4442\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 701.5237 - val_loss: 464.5921\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 697.6140 - val_loss: 461.7827\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 693.7525 - val_loss: 459.0154\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 689.9389 - val_loss: 456.2898\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 686.1726 - val_loss: 453.6052\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 682.4530 - val_loss: 450.9616\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 678.7800 - val_loss: 448.3579\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 675.1526 - val_loss: 445.7941\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 671.5706 - val_loss: 443.2694\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 668.0334 - val_loss: 440.7832\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 664.5403 - val_loss: 438.3355\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 661.0913 - val_loss: 435.9253\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 657.6856 - val_loss: 433.5523\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 654.3225 - val_loss: 431.2162\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 651.0023 - val_loss: 428.9161\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 647.7235 - val_loss: 426.6521\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 644.4862 - val_loss: 424.4231\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 641.2900 - val_loss: 422.2287\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 638.1340 - val_loss: 420.0688\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 635.0184 - val_loss: 417.9423\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 631.9418 - val_loss: 415.8490\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 628.9045 - val_loss: 413.7886\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 625.9058 - val_loss: 411.7600\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 622.9451 - val_loss: 409.7628\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 620.0218 - val_loss: 407.7969\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 617.1359 - val_loss: 405.8614\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 614.2867 - val_loss: 403.9556\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 611.4736 - val_loss: 402.0799\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 608.6969 - val_loss: 400.2328\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 605.9556 - val_loss: 398.4147\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 603.2494 - val_loss: 396.6256\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 600.5787 - val_loss: 394.8652\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 597.9430 - val_loss: 393.1336\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 595.3420 - val_loss: 391.4309\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 592.7757 - val_loss: 389.7575\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 590.2438 - val_loss: 388.1137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 587.7461 - val_loss: 386.4992\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 585.2818 - val_loss: 384.9136\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 582.8499 - val_loss: 383.3571\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 580.4502 - val_loss: 381.8289\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 578.0815 - val_loss: 380.3287\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 575.7434 - val_loss: 378.8559\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 573.4355 - val_loss: 377.4102\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 571.1573 - val_loss: 375.9910\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 568.9089 - val_loss: 374.5973\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 566.6899 - val_loss: 373.2285\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 564.5002 - val_loss: 371.8834\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 562.3393 - val_loss: 370.5602\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 560.2064 - val_loss: 369.2575\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 558.1012 - val_loss: 367.9731\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 556.0222 - val_loss: 366.7047\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 553.9688 - val_loss: 365.4495\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 551.9392 - val_loss: 364.2040\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 549.9325 - val_loss: 362.9644\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 547.9465 - val_loss: 361.7253\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 545.9794 - val_loss: 360.4828\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 544.0309 - val_loss: 359.2359\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 542.1045 - val_loss: 357.9929\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 540.2115 - val_loss: 356.7827\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 538.3726 - val_loss: 355.6479\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 536.5905 - val_loss: 354.5743\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 534.8145 - val_loss: 353.5350\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 533.0353 - val_loss: 352.5321\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 531.2706 - val_loss: 351.5688\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 529.5357 - val_loss: 350.6382\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 527.8356 - val_loss: 349.7277\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 526.1666 - val_loss: 348.8259\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 524.5230 - val_loss: 347.9259\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 522.9005 - val_loss: 347.0253\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 521.2961 - val_loss: 346.1239\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 519.7094 - val_loss: 345.2230\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 518.1411 - val_loss: 344.3264\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 516.5928 - val_loss: 343.4395\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 515.0672 - val_loss: 342.5692\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 513.5660 - val_loss: 341.7220\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 512.0894 - val_loss: 340.9024\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 510.6351 - val_loss: 340.1115\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 509.2003 - val_loss: 339.3483\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 507.7820 - val_loss: 338.6113\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 506.3808 - val_loss: 337.8983\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 504.9984 - val_loss: 337.2063\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 503.6367 - val_loss: 336.5304\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 502.2958 - val_loss: 335.8655\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 500.9750 - val_loss: 335.2071\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 499.6730 - val_loss: 334.5522\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 498.3883 - val_loss: 333.8996\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 497.1198 - val_loss: 333.2500\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 495.8669 - val_loss: 332.6054\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 494.6293 - val_loss: 331.9691\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 493.4069 - val_loss: 331.3461\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 492.1984 - val_loss: 330.7463\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 491.0042 - val_loss: 330.1911\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 489.8285 - val_loss: 329.6699\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 488.6740 - val_loss: 329.0784\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 487.5184 - val_loss: 328.5227\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 486.3909 - val_loss: 328.0050\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 485.2773 - val_loss: 327.5239\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 484.1679 - val_loss: 327.1471\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 483.0839 - val_loss: 326.6056\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 481.9974 - val_loss: 326.0966\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 480.9381 - val_loss: 325.6587\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 479.8802 - val_loss: 325.3170\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 478.8453 - val_loss: 324.7853\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 477.8116 - val_loss: 324.3026\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 476.8041 - val_loss: 323.9292\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 475.7990 - val_loss: 323.5665\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 474.8188 - val_loss: 323.0314\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 473.8443 - val_loss: 322.6398\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 472.8818 - val_loss: 322.3670\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 471.9397 - val_loss: 321.8982\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 470.9981 - val_loss: 321.4990\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 470.0824 - val_loss: 321.2256\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 469.1725 - val_loss: 320.8706\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 468.2782 - val_loss: 320.4641\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 467.4015 - val_loss: 320.1831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 466.5299 - val_loss: 319.8954\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 465.6795 - val_loss: 319.4981\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 464.8388 - val_loss: 319.2220\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 464.0061 - val_loss: 318.9714\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 463.1957 - val_loss: 318.5959\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 462.3910 - val_loss: 318.3307\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 461.5975 - val_loss: 318.1115\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 460.8247 - val_loss: 317.7721\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 460.0552 - val_loss: 317.5199\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 459.3004 - val_loss: 317.3288\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 458.5619 - val_loss: 317.0360\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 457.8275 - val_loss: 316.7959\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 457.1102 - val_loss: 316.6235\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 456.4042 - val_loss: 316.3776\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 455.7056 - val_loss: 316.1477\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 455.0232 - val_loss: 315.9846\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 454.3488 - val_loss: 315.7774\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 453.6852 - val_loss: 315.5597\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 453.0348 - val_loss: 315.4027\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 452.3919 - val_loss: 315.2261\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 451.7610 - val_loss: 315.0262\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 451.1406 - val_loss: 314.8787\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 450.5283 - val_loss: 314.7288\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 449.9278 - val_loss: 314.5519\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 449.3361 - val_loss: 314.4181\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 448.7525 - val_loss: 314.2904\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 448.1792 - val_loss: 314.1364\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 447.6124 - val_loss: 314.0149\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 447.0517 - val_loss: 313.9023\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 446.4971 - val_loss: 313.7656\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 445.9442 - val_loss: 313.6474\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 445.3900 - val_loss: 313.5371\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 444.8280 - val_loss: 313.4077\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019A7E048EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MAE: 15.384953613281251\n",
      "SMAPE: 12.85798603594636\n",
      "RMSE: 19.567332258077585\n",
      "R2 Score: -18.052788045415546\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 3 data points for the rolling window\n",
    "window_size = 3\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ace93e",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd5e4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15281.1309 - val_loss: 11947.8613\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 15138.0000 - val_loss: 11839.3652\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14993.6143 - val_loss: 11743.8018\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14861.5049 - val_loss: 11639.2441\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14716.9736 - val_loss: 11548.7217\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14581.9082 - val_loss: 11469.2061\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 14450.5664 - val_loss: 11392.8965\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 14316.3818 - val_loss: 11317.9727\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 14181.4648 - val_loss: 11244.3867\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14050.2676 - val_loss: 11173.1543\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 13926.2148 - val_loss: 11099.0557\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 13803.8838 - val_loss: 11022.1338\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 13684.0781 - val_loss: 10943.3643\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 13564.3975 - val_loss: 10868.7500\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 13447.6416 - val_loss: 10797.6768\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13334.8574 - val_loss: 10726.3965\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 13223.3008 - val_loss: 10652.8320\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 13111.8916 - val_loss: 10575.9727\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12999.5811 - val_loss: 10498.7256\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 12887.5225 - val_loss: 10419.2100\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 12776.6035 - val_loss: 10335.6357\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 12665.0410 - val_loss: 10251.6035\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 12554.5205 - val_loss: 10168.1816\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 12446.2461 - val_loss: 10084.0879\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 12339.5117 - val_loss: 9998.3213\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 12233.4150 - val_loss: 9910.0811\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 12127.0000 - val_loss: 9818.0713\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12018.8428 - val_loss: 9720.9072\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11907.5039 - val_loss: 9618.7539\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 11792.9375 - val_loss: 9512.1807\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 11675.5264 - val_loss: 9401.7256\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 11555.6816 - val_loss: 9287.5625\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 11433.6748 - val_loss: 9168.6230\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 11309.0928 - val_loss: 9044.4619\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 11180.9648 - val_loss: 8915.3350\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 11050.2080 - val_loss: 8780.9150\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10916.1094 - val_loss: 8642.4043\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10779.2305 - val_loss: 8501.0938\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10640.9746 - val_loss: 8358.0166\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10502.9092 - val_loss: 8213.7842\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 10366.3271 - val_loss: 8068.8193\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10232.2471 - val_loss: 7923.9844\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10101.3086 - val_loss: 7786.6484\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9972.3232 - val_loss: 7658.1245\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9847.8340 - val_loss: 7540.6787\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9734.4902 - val_loss: 7428.9810\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9625.5684 - val_loss: 7323.2397\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9520.5068 - val_loss: 7222.9746\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9419.6191 - val_loss: 7125.9985\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9321.4873 - val_loss: 7030.3970\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9224.8271 - val_loss: 6935.2480\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9129.0635 - val_loss: 6840.8369\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9034.1836 - val_loss: 6746.3799\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8939.9482 - val_loss: 6649.9438\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8845.4365 - val_loss: 6549.9653\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8749.2471 - val_loss: 6445.9473\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8650.5625 - val_loss: 6339.8721\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8549.3662 - val_loss: 6236.6348\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8448.0879 - val_loss: 6140.0210\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8350.8848 - val_loss: 6049.8179\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8258.4971 - val_loss: 5964.9214\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8170.0811 - val_loss: 5884.6763\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8085.5205 - val_loss: 5807.5249\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8003.7671 - val_loss: 5731.5186\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7923.1875 - val_loss: 5655.6313\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7842.4297 - val_loss: 5580.1943\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7761.4717 - val_loss: 5505.6377\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7681.3838 - val_loss: 5431.9121\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7602.7290 - val_loss: 5358.9668\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7525.4980 - val_loss: 5286.7471\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7449.0845 - val_loss: 5215.7529\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7373.4238 - val_loss: 5146.2925\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7298.6646 - val_loss: 5078.3813\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7224.8735 - val_loss: 5011.9424\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7151.9019 - val_loss: 4947.0718\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7079.7593 - val_loss: 4883.5435\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7008.2476 - val_loss: 4821.2524\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 6937.4263 - val_loss: 4760.4062\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6867.7964 - val_loss: 4700.8540\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6799.4761 - val_loss: 4642.5298\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6732.7388 - val_loss: 4585.4863\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6667.8604 - val_loss: 4529.8188\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6604.5752 - val_loss: 4475.6396\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6542.5020 - val_loss: 4422.7090\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6481.1533 - val_loss: 4370.2759\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6419.8442 - val_loss: 4317.8755\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6358.2969 - val_loss: 4265.7710\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6297.0239 - val_loss: 4214.8794\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6237.2144 - val_loss: 4164.2358\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6177.7373 - val_loss: 4114.8784\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6119.8408 - val_loss: 4066.4124\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6062.9673 - val_loss: 4018.6921\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6006.8379 - val_loss: 3971.6941\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5951.2988 - val_loss: 3925.4268\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5896.2842 - val_loss: 3879.9873\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5841.9175 - val_loss: 3835.4290\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5788.3154 - val_loss: 3791.6873\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5735.4844 - val_loss: 3748.6208\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5683.3735 - val_loss: 3706.1169\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5631.9429 - val_loss: 3664.1082\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5581.1636 - val_loss: 3622.4988\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 5530.9551 - val_loss: 3581.0930\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5481.1943 - val_loss: 3539.5845\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5431.7178 - val_loss: 3497.5457\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5382.2021 - val_loss: 3454.6262\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5332.2866 - val_loss: 3410.7471\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5281.7876 - val_loss: 3366.1296\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5230.7549 - val_loss: 3321.1746\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5179.4282 - val_loss: 3276.2820\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5128.1191 - val_loss: 3231.7532\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5077.1382 - val_loss: 3187.6978\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5026.6543 - val_loss: 3144.1633\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4976.6958 - val_loss: 3101.3662\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4927.2817 - val_loss: 3059.6492\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4878.5015 - val_loss: 3019.2908\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4830.5869 - val_loss: 2980.4944\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4783.9624 - val_loss: 2943.1858\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4738.7725 - val_loss: 2906.9624\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4694.5615 - val_loss: 2871.6963\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4651.2202 - val_loss: 2837.2690\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4608.6616 - val_loss: 2803.5461\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4566.8145 - val_loss: 2770.3164\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4525.5103 - val_loss: 2737.3555\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4484.5259 - val_loss: 2704.6147\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4443.7871 - val_loss: 2672.0322\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4403.1113 - val_loss: 2639.8159\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4362.6450 - val_loss: 2608.0146\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4322.4751 - val_loss: 2576.6614\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4282.7300 - val_loss: 2545.6667\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4243.3589 - val_loss: 2514.9890\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4204.3447 - val_loss: 2484.6194\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4165.6909 - val_loss: 2454.5288\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 4127.3662 - val_loss: 2424.7004\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4089.3640 - val_loss: 2395.1333\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4051.7078 - val_loss: 2365.8279\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4014.3901 - val_loss: 2336.7102\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3977.3215 - val_loss: 2307.5781\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3940.3020 - val_loss: 2278.1907\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3903.0713 - val_loss: 2248.3716\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3865.4265 - val_loss: 2218.0735\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3827.3237 - val_loss: 2187.4026\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3788.8777 - val_loss: 2156.6023\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3750.3120 - val_loss: 2126.0242\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3711.9321 - val_loss: 2096.1006\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3674.1394 - val_loss: 2067.1550\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3637.2617 - val_loss: 2039.1766\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3601.3411 - val_loss: 2012.0253\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3566.3000 - val_loss: 1985.6146\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3532.0681 - val_loss: 1959.8422\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3498.5317 - val_loss: 1934.5964\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3465.5627 - val_loss: 1909.7916\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3433.0518 - val_loss: 1885.3732\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3400.9209 - val_loss: 1861.3052\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3369.1331 - val_loss: 1837.5535\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 3337.6733 - val_loss: 1814.0853\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3306.5266 - val_loss: 1790.8715\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3275.6655 - val_loss: 1767.8885\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3245.0637 - val_loss: 1745.1202\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3214.6968 - val_loss: 1722.5543\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3184.5457 - val_loss: 1700.1836\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3154.5981 - val_loss: 1678.0027\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3124.8506 - val_loss: 1656.0131\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3095.3054 - val_loss: 1634.3466\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3066.1052 - val_loss: 1612.7874\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3037.0374 - val_loss: 1591.4309\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3008.1860 - val_loss: 1570.2784\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2979.5354 - val_loss: 1549.2699\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2951.0181 - val_loss: 1528.4261\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2922.6731 - val_loss: 1507.8130\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2894.5972 - val_loss: 1487.4796\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2866.8577 - val_loss: 1467.4255\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2839.4448 - val_loss: 1447.6172\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2812.3035 - val_loss: 1428.0117\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2785.3728 - val_loss: 1408.5637\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2758.6033 - val_loss: 1389.2798\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2732.0061 - val_loss: 1370.2281\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2705.6807 - val_loss: 1351.4832\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2679.7593 - val_loss: 1333.1021\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2654.3000 - val_loss: 1315.0759\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2629.2573 - val_loss: 1297.3290\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2604.5388 - val_loss: 1279.8164\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2580.0913 - val_loss: 1262.5232\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2555.8933 - val_loss: 1245.5348\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2532.0281 - val_loss: 1228.6516\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2508.3213 - val_loss: 1211.9882\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2484.8677 - val_loss: 1195.5432\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2461.6577 - val_loss: 1179.2814\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2438.6509 - val_loss: 1163.1793\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2415.8167 - val_loss: 1147.2152\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2393.1262 - val_loss: 1131.3569\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2370.5347 - val_loss: 1115.5751\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2347.9998 - val_loss: 1099.8735\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2325.5220 - val_loss: 1084.3099\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2303.1780 - val_loss: 1068.9445\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2281.0681 - val_loss: 1053.8363\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2259.2817 - val_loss: 1039.0123\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2237.8491 - val_loss: 1024.4397\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2216.7251 - val_loss: 1010.0801\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2195.8562 - val_loss: 995.9133\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2175.2144 - val_loss: 981.9296\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2154.7861 - val_loss: 968.1258\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2134.5659 - val_loss: 954.5004\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2114.5527 - val_loss: 941.0719\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2094.7651 - val_loss: 927.7714\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2075.1372 - val_loss: 914.6553\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2055.7236 - val_loss: 901.7075\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2036.5074 - val_loss: 888.9280\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2017.4878 - val_loss: 876.3146\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1998.6614 - val_loss: 863.8642\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1980.0250 - val_loss: 851.5754\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1961.5774 - val_loss: 839.4464\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1943.3168 - val_loss: 827.4759\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1925.2419 - val_loss: 815.6635\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1907.3531 - val_loss: 804.0059\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1889.6471 - val_loss: 792.5016\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1872.1218 - val_loss: 781.1490\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1854.7758 - val_loss: 769.9454\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1837.6063 - val_loss: 758.8907\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1820.6133 - val_loss: 747.9839\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1803.7954 - val_loss: 737.2233\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1787.1495 - val_loss: 726.6074\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1770.6752 - val_loss: 716.1348\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1754.3702 - val_loss: 705.8033\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1738.2325 - val_loss: 695.6122\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1722.2617 - val_loss: 685.5593\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1706.4545 - val_loss: 675.6437\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1690.8109 - val_loss: 665.8636\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1675.3290 - val_loss: 656.2179\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1660.0072 - val_loss: 646.7042\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1644.8439 - val_loss: 637.3219\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1629.8375 - val_loss: 628.0692\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 1614.9858 - val_loss: 618.9450\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1600.2893 - val_loss: 609.9479\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1585.7443 - val_loss: 601.0771\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1571.3508 - val_loss: 592.3314\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1557.1078 - val_loss: 583.7090\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1543.0128 - val_loss: 575.2090\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1529.0653 - val_loss: 566.8295\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1515.2626 - val_loss: 558.5696\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1501.6042 - val_loss: 550.4274\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1488.0879 - val_loss: 542.4022\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1474.7135 - val_loss: 534.4927\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1461.4791 - val_loss: 526.6973\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1448.3834 - val_loss: 519.0153\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1435.4253 - val_loss: 511.4446\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1422.6021 - val_loss: 503.9867\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1409.9152 - val_loss: 496.6360\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1397.3608 - val_loss: 489.3952\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1384.9403 - val_loss: 482.2620\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1372.6510 - val_loss: 475.2349\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1360.4907 - val_loss: 468.3135\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1348.4598 - val_loss: 461.4966\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1336.5571 - val_loss: 454.7812\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1324.7800 - val_loss: 448.1683\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1313.1284 - val_loss: 441.6563\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1301.6010 - val_loss: 435.2440\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1290.1956 - val_loss: 428.9313\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1278.9138 - val_loss: 422.7150\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1267.7511 - val_loss: 416.5951\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1256.7086 - val_loss: 410.5716\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1245.7849 - val_loss: 404.6423\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1234.9783 - val_loss: 398.8068\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1224.2878 - val_loss: 393.0636\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1213.7128 - val_loss: 387.4118\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1203.2517 - val_loss: 381.8506\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1192.9041 - val_loss: 376.3789\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1182.6681 - val_loss: 370.9964\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1172.5435 - val_loss: 365.7012\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1162.5288 - val_loss: 360.4928\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1152.6227 - val_loss: 355.3698\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1142.8246 - val_loss: 350.3322\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1133.1335 - val_loss: 345.3781\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1123.5485 - val_loss: 340.5070\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1114.0681 - val_loss: 335.7181\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1104.6917 - val_loss: 331.0104\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1095.4185 - val_loss: 326.3829\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1086.2469 - val_loss: 321.8347\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1077.1769 - val_loss: 317.3649\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1068.2062 - val_loss: 312.9729\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1059.3356 - val_loss: 308.6575\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1050.5629 - val_loss: 304.4180\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1041.8875 - val_loss: 300.2533\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1033.3081 - val_loss: 296.1630\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1024.8245 - val_loss: 292.1460\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1016.4355 - val_loss: 288.2014\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1008.1400 - val_loss: 284.3288\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 999.9379 - val_loss: 280.5267\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 991.8271 - val_loss: 276.7948\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 983.8076 - val_loss: 273.1322\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 975.8787 - val_loss: 269.5379\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 968.0384 - val_loss: 266.0115\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 960.2870 - val_loss: 262.5518\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 952.6231 - val_loss: 259.1580\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 945.0459 - val_loss: 255.8299\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 937.5549 - val_loss: 252.5660\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 930.1488 - val_loss: 249.3661\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 922.8273 - val_loss: 246.2292\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 915.5891 - val_loss: 243.1546\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 908.4337 - val_loss: 240.1415\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 901.3602 - val_loss: 237.1894\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 894.3679 - val_loss: 234.2973\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 887.4559 - val_loss: 231.4646\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 880.6234 - val_loss: 228.6904\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 873.8696 - val_loss: 225.9743\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 867.1938 - val_loss: 223.3155\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 860.5953 - val_loss: 220.7131\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 854.0734 - val_loss: 218.1666\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 847.6267 - val_loss: 215.6755\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 841.2557 - val_loss: 213.2386\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 834.9582 - val_loss: 210.8553\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 828.7340 - val_loss: 208.5249\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 822.5811 - val_loss: 206.2463\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 816.4986 - val_loss: 204.0187\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 810.4841 - val_loss: 201.8410\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 804.5339 - val_loss: 199.7117\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 798.6449 - val_loss: 197.6296\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 792.8163 - val_loss: 195.5931\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 787.0504 - val_loss: 193.6008\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 781.3527 - val_loss: 191.6568\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 775.7276 - val_loss: 189.7666\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 770.1806 - val_loss: 187.9285\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 764.7076 - val_loss: 186.1383\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 759.3007 - val_loss: 184.3935\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 753.9594 - val_loss: 182.6944\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 748.6861 - val_loss: 181.0423\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 743.4818 - val_loss: 179.4352\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 738.3420 - val_loss: 177.8712\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 733.2636 - val_loss: 176.3499\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 728.2471 - val_loss: 174.8709\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 723.2913 - val_loss: 173.4331\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 718.3955 - val_loss: 172.0365\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 713.5590 - val_loss: 170.6802\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 708.7817 - val_loss: 169.3638\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 704.0623 - val_loss: 168.0866\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 699.4008 - val_loss: 166.8482\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 694.7961 - val_loss: 165.6479\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 690.2480 - val_loss: 164.4854\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 685.7556 - val_loss: 163.3599\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 681.3184 - val_loss: 162.2712\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 676.9363 - val_loss: 161.2184\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 672.6077 - val_loss: 160.2014\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 668.3328 - val_loss: 159.2195\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 664.1113 - val_loss: 158.2721\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 659.9418 - val_loss: 157.3588\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 655.8241 - val_loss: 156.4790\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 651.7579 - val_loss: 155.6324\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 647.7423 - val_loss: 154.8184\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 643.7770 - val_loss: 154.0365\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 639.8615 - val_loss: 153.2863\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 635.9949 - val_loss: 152.5673\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 632.1769 - val_loss: 151.8789\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 628.4069 - val_loss: 151.2209\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 624.6848 - val_loss: 150.5927\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 621.0096 - val_loss: 149.9937\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 617.3804 - val_loss: 149.4236\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 613.7979 - val_loss: 148.8821\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 610.2607 - val_loss: 148.3685\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 606.7686 - val_loss: 147.8824\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 603.3211 - val_loss: 147.4236\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 599.9172 - val_loss: 146.9913\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 596.5574 - val_loss: 146.5854\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 593.2404 - val_loss: 146.2053\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 589.9658 - val_loss: 145.8506\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 586.7333 - val_loss: 145.5209\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 583.5427 - val_loss: 145.2157\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 580.3931 - val_loss: 144.9338\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 577.2836 - val_loss: 144.6728\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 574.2139 - val_loss: 144.4444\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 571.1861 - val_loss: 144.2337\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 568.1956 - val_loss: 144.0417\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 565.2435 - val_loss: 143.8774\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 562.3301 - val_loss: 143.7344\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 559.4562 - val_loss: 143.6117\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 556.6187 - val_loss: 143.5101\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 553.8191 - val_loss: 143.4314\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 551.0554 - val_loss: 143.3716\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 548.3288 - val_loss: 143.3312\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 545.6387 - val_loss: 143.3118\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 542.9833 - val_loss: 143.3106\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 540.3630 - val_loss: 143.3280\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 537.7782 - val_loss: 143.3645\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 535.2269 - val_loss: 143.4187\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 532.7103 - val_loss: 143.4908\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 530.2263 - val_loss: 143.5803\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 527.7759 - val_loss: 143.6865\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 525.3578 - val_loss: 143.8091\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 522.9727 - val_loss: 143.9485\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 520.6189 - val_loss: 144.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 518.2970 - val_loss: 144.2735\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 516.0060 - val_loss: 144.4584\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 513.7460 - val_loss: 144.6586\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 511.5157 - val_loss: 144.8730\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 509.3160 - val_loss: 145.1005\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 507.1457 - val_loss: 145.3414\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 505.0045 - val_loss: 145.5957\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 502.8919 - val_loss: 145.8625\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 500.8079 - val_loss: 146.1409\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 498.7520 - val_loss: 146.4302\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 496.7235 - val_loss: 146.7306\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 494.7222 - val_loss: 147.0416\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 492.7477 - val_loss: 147.3618\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 490.7994 - val_loss: 147.6904\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 488.8772 - val_loss: 148.0271\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 486.9807 - val_loss: 148.3714\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 485.1093 - val_loss: 148.7221\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 483.2626 - val_loss: 149.0777\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 481.4404 - val_loss: 149.4374\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 479.6421 - val_loss: 149.8005\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 477.8670 - val_loss: 150.1658\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 476.1151 - val_loss: 150.5318\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 474.3858 - val_loss: 150.8966\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 472.6788 - val_loss: 151.2591\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 470.9934 - val_loss: 151.6178\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 469.3290 - val_loss: 151.9699\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 467.6848 - val_loss: 152.3117\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 466.0600 - val_loss: 152.6380\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 464.4530 - val_loss: 152.9411\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 462.8625 - val_loss: 153.2098\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 461.2869 - val_loss: 153.4293\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 459.7254 - val_loss: 153.5852\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 458.1792 - val_loss: 153.6742\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 456.6532 - val_loss: 153.7200\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 455.1587 - val_loss: 153.7841\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 453.7100 - val_loss: 153.9473\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 452.3133 - val_loss: 154.2554\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 450.9492 - val_loss: 154.6897\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 449.5869 - val_loss: 155.2157\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 448.2174 - val_loss: 155.8167\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 446.8499 - val_loss: 156.4852\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 445.4980 - val_loss: 157.2090\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 444.1726 - val_loss: 157.9657\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 442.8774 - val_loss: 158.7272\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 441.6093 - val_loss: 159.4677\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 440.3638 - val_loss: 160.1704\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 439.1359 - val_loss: 160.8272\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 437.9224 - val_loss: 161.4362\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 436.7221 - val_loss: 162.0002\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 435.5348 - val_loss: 162.5254\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 434.3616 - val_loss: 163.0216\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 433.2038 - val_loss: 163.5023\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 432.0640 - val_loss: 163.9828\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 430.9436 - val_loss: 164.4778\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 429.8429 - val_loss: 164.9984\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 428.7610 - val_loss: 165.5501\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 427.6953 - val_loss: 166.1340\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 426.6437 - val_loss: 166.7480\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 425.6045 - val_loss: 167.3884\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 424.5780 - val_loss: 168.0509\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 423.5649 - val_loss: 168.7298\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 422.5674 - val_loss: 169.4176\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 421.5856 - val_loss: 170.1061\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 420.6196 - val_loss: 170.7872\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 419.6690 - val_loss: 171.4544\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 418.7325 - val_loss: 172.1040\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 417.8094 - val_loss: 172.7352\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 416.8991 - val_loss: 173.3501\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 416.0013 - val_loss: 173.9533\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 415.1162 - val_loss: 174.5507\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 414.2443 - val_loss: 175.1489\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 413.3855 - val_loss: 175.7538\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 412.5401 - val_loss: 176.3702\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 411.7078 - val_loss: 177.0010\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 410.8882 - val_loss: 177.6475\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 410.0804 - val_loss: 178.3095\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 409.2843 - val_loss: 178.9856\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 408.4996 - val_loss: 179.6733\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 407.7267 - val_loss: 180.3696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 406.9650 - val_loss: 181.0709\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 406.2150 - val_loss: 181.7730\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 405.4766 - val_loss: 182.4727\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 404.7495 - val_loss: 183.1671\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 404.0334 - val_loss: 183.8541\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 403.3280 - val_loss: 184.5332\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 402.6331 - val_loss: 185.2048\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 401.9486 - val_loss: 185.8702\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 401.2744 - val_loss: 186.5319\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 400.6104 - val_loss: 187.1918\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 399.9566 - val_loss: 187.8524\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 399.3128 - val_loss: 188.5154\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 398.6788 - val_loss: 189.1821\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 398.0547 - val_loss: 189.8529\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 397.4398 - val_loss: 190.5281\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 396.8345 - val_loss: 191.2068\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 396.2384 - val_loss: 191.8886\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 395.6512 - val_loss: 192.5722\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 395.0732 - val_loss: 193.2562\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 394.5041 - val_loss: 193.9394\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 393.9438 - val_loss: 194.6208\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 393.3921 - val_loss: 195.2996\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 392.8490 - val_loss: 195.9753\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 392.3142 - val_loss: 196.6481\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 391.7878 - val_loss: 197.3182\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 391.2695 - val_loss: 197.9861\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 390.7592 - val_loss: 198.6528\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 390.2568 - val_loss: 199.3191\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 389.7622 - val_loss: 199.9853\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 389.2754 - val_loss: 200.6520\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 388.7963 - val_loss: 201.3194\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 388.3244 - val_loss: 201.9873\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 387.8603 - val_loss: 202.6557\n",
      "MAE: 17.37687169392904\n",
      "SMAPE: 13.584044482816898\n",
      "RMSE: 22.737815974329266\n",
      "R2 Score: -739.4628545130073\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 2 data points for the rolling window\n",
    "window_size = 2\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978e1ba",
   "metadata": {},
   "source": [
    "## Testing Proposed Model w/TF with Rolling window of  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f38030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15640.3926 - val_loss: 16102.9785\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 15497.3525 - val_loss: 16036.3965\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15351.5049 - val_loss: 15969.9775\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15200.1787 - val_loss: 15903.1338\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 15039.9434 - val_loss: 15837.0615\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14869.7900 - val_loss: 15769.1104\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14690.4307 - val_loss: 15701.0039\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 14507.1318 - val_loss: 15633.0498\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14326.1289 - val_loss: 15564.6631\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14151.3760 - val_loss: 15494.7959\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 13982.8291 - val_loss: 15419.5518\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 13817.4795 - val_loss: 15340.5781\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13650.4668 - val_loss: 15263.2920\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13479.3418 - val_loss: 15187.3809\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 13310.5283 - val_loss: 15112.4541\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 13147.0469 - val_loss: 15037.9561\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12985.6875 - val_loss: 14968.6504\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12825.9805 - val_loss: 14931.9658\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 12668.8643 - val_loss: 14863.4111\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 12513.9854 - val_loss: 14797.0723\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12363.2773 - val_loss: 14720.1475\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12217.5254 - val_loss: 14644.9961\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 12077.6055 - val_loss: 14564.4688\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 11943.1465 - val_loss: 14465.0615\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 11813.6064 - val_loss: 14380.5049\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11687.5762 - val_loss: 14311.3926\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 11560.6816 - val_loss: 14249.4902\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 11434.7441 - val_loss: 14195.7686\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 11318.9238 - val_loss: 14132.8076\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 11205.6436 - val_loss: 14064.6357\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 11093.0889 - val_loss: 13988.1816\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10980.5439 - val_loss: 13903.5820\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10867.7773 - val_loss: 13812.3975\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10753.7754 - val_loss: 13720.3438\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10637.9209 - val_loss: 13631.5850\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10520.6191 - val_loss: 13547.5928\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10403.0928 - val_loss: 13466.5918\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10287.0059 - val_loss: 13385.9629\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10173.8291 - val_loss: 13303.6309\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10064.1748 - val_loss: 13220.0654\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9957.4697 - val_loss: 13136.5537\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9852.6611 - val_loss: 13054.8975\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9750.1436 - val_loss: 12976.1465\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9649.6680 - val_loss: 12902.7998\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9552.4346 - val_loss: 12834.8232\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9459.0811 - val_loss: 12770.7773\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9369.5156 - val_loss: 12708.6055\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9283.3564 - val_loss: 12646.3525\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9199.9570 - val_loss: 12583.4043\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 9118.5273 - val_loss: 12520.5449\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9038.2979 - val_loss: 12459.6650\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 8959.1074 - val_loss: 12401.3105\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8881.2188 - val_loss: 12344.6934\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8804.5840 - val_loss: 12288.9824\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8728.6719 - val_loss: 12233.9248\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8652.9551 - val_loss: 12179.6748\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8577.1807 - val_loss: 12126.6055\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8501.2891 - val_loss: 12075.0342\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8425.3311 - val_loss: 12022.3564\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8349.2939 - val_loss: 11968.1084\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8273.3652 - val_loss: 11912.5830\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8197.9199 - val_loss: 11856.5410\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8123.5176 - val_loss: 11800.6768\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8050.7812 - val_loss: 11745.6367\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7979.9331 - val_loss: 11692.1064\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7910.3750 - val_loss: 11640.5156\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7841.1577 - val_loss: 11589.6084\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7772.3872 - val_loss: 11537.1846\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7703.8667 - val_loss: 11483.1416\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7635.5254 - val_loss: 11427.9893\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7567.1353 - val_loss: 11373.2334\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7499.1968 - val_loss: 11320.5273\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7432.9360 - val_loss: 11270.4248\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7367.8926 - val_loss: 11222.3135\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7303.7778 - val_loss: 11175.4170\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7240.7661 - val_loss: 11128.6377\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7178.7998 - val_loss: 11080.4414\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 7117.0137 - val_loss: 11029.6133\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7055.7197 - val_loss: 10975.2100\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6994.5781 - val_loss: 10917.0645\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6933.9937 - val_loss: 10854.2676\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6875.0171 - val_loss: 10789.2979\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6817.1040 - val_loss: 10724.8877\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6760.1821 - val_loss: 10662.0830\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6703.4541 - val_loss: 10601.9863\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6646.7876 - val_loss: 10545.0479\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6590.4243 - val_loss: 10491.4043\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6534.6084 - val_loss: 10440.5205\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6479.4302 - val_loss: 10391.6191\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6424.8750 - val_loss: 10343.8545\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6370.9614 - val_loss: 10296.4150\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6317.4854 - val_loss: 10248.7246\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6264.1987 - val_loss: 10200.6162\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6210.9409 - val_loss: 10152.3018\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6157.6416 - val_loss: 10104.0537\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6104.3906 - val_loss: 10056.0371\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6051.6929 - val_loss: 10008.4541\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6000.3721 - val_loss: 9961.2900\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5949.4751 - val_loss: 9914.4268\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5898.0312 - val_loss: 9867.7666\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5845.8286 - val_loss: 9821.9033\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5793.1582 - val_loss: 9777.5615\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5740.5317 - val_loss: 9735.0742\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5688.6719 - val_loss: 9694.1084\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5637.8999 - val_loss: 9653.8027\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5588.5220 - val_loss: 9613.5732\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5540.1250 - val_loss: 9572.8184\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5491.9365 - val_loss: 9530.8965\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5443.5635 - val_loss: 9487.4795\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5394.8472 - val_loss: 9443.1406\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5345.7061 - val_loss: 9399.2373\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5296.3936 - val_loss: 9356.7959\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5247.9160 - val_loss: 9316.0898\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5201.7959 - val_loss: 9276.9932\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5158.1216 - val_loss: 9239.3174\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5114.3169 - val_loss: 9203.3623\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5070.2656 - val_loss: 9169.9209\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5026.3037 - val_loss: 9140.7305\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4981.6699 - val_loss: 9118.6162\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4937.7861 - val_loss: 9087.9775\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4894.4717 - val_loss: 9046.2129\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4851.6719 - val_loss: 9001.5889\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4809.5830 - val_loss: 8958.1113\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4768.0337 - val_loss: 8917.2812\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4726.6777 - val_loss: 8886.5938\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4685.3052 - val_loss: 8870.5889\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4643.9282 - val_loss: 8834.9736\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4602.6543 - val_loss: 8790.0654\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 4561.5581 - val_loss: 8740.6582\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4520.6616 - val_loss: 8695.9824\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4479.9341 - val_loss: 8658.2129\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4439.2300 - val_loss: 8622.3711\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4398.7114 - val_loss: 8584.8154\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4358.1948 - val_loss: 8545.5791\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4317.9478 - val_loss: 8506.1475\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4278.1973 - val_loss: 8467.5068\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4239.1016 - val_loss: 8429.7979\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4200.5396 - val_loss: 8392.9375\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4162.4756 - val_loss: 8356.8682\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4125.2393 - val_loss: 8321.5869\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4089.3723 - val_loss: 8287.0449\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4053.5198 - val_loss: 8252.7764\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4017.4531 - val_loss: 8217.8506\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3981.5308 - val_loss: 8181.9370\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3945.7913 - val_loss: 8146.2568\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 3910.0000 - val_loss: 8111.8779\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3874.0344 - val_loss: 8078.6021\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3839.1829 - val_loss: 8045.7236\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3806.2466 - val_loss: 8012.6748\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3771.8955 - val_loss: 7978.8604\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3737.7576 - val_loss: 7943.8232\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3704.7036 - val_loss: 7907.3706\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3672.1963 - val_loss: 7869.6665\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3639.7485 - val_loss: 7831.2129\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step - loss: 3607.2551 - val_loss: 7792.6714\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3574.7451 - val_loss: 7754.5957\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3542.3491 - val_loss: 7717.2822\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3510.2498 - val_loss: 7680.7749\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3478.4438 - val_loss: 7644.9897\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3446.6956 - val_loss: 7609.8247\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3414.9429 - val_loss: 7575.1206\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3383.3901 - val_loss: 7540.5889\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3352.2693 - val_loss: 7505.8862\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3321.6484 - val_loss: 7470.9302\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3291.4583 - val_loss: 7436.2915\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3261.6218 - val_loss: 7402.6074\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3232.1169 - val_loss: 7370.1113\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3202.9517 - val_loss: 7338.7456\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3174.0852 - val_loss: 7308.1006\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3145.4504 - val_loss: 7277.7095\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3116.9988 - val_loss: 7247.2974\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3088.7341 - val_loss: 7216.8374\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3060.7070 - val_loss: 7186.4150\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3032.9780 - val_loss: 7156.0103\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3005.5708 - val_loss: 7125.5625\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2978.4722 - val_loss: 7095.0845\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2951.6526 - val_loss: 7064.7593\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2925.0933 - val_loss: 7034.8291\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2898.7817 - val_loss: 7005.4302\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2872.7114 - val_loss: 6976.5728\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2846.8799 - val_loss: 6948.1802\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2821.2844 - val_loss: 6920.1499\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2795.9204 - val_loss: 6892.3813\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2770.7866 - val_loss: 6864.7944\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2745.8794 - val_loss: 6837.3345\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2721.1980 - val_loss: 6809.9712\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2696.7427 - val_loss: 6782.6919\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2672.5168 - val_loss: 6755.4917\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2648.5225 - val_loss: 6728.3779\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2624.7563 - val_loss: 6701.3594\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2601.2178 - val_loss: 6674.4497\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2577.9014 - val_loss: 6647.6665\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2554.8037 - val_loss: 6621.0249\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2531.9209 - val_loss: 6594.5391\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2509.2522 - val_loss: 6568.2207\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2486.7942 - val_loss: 6542.0718\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2464.5454 - val_loss: 6516.0903\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2442.5037 - val_loss: 6490.2671\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2420.6692 - val_loss: 6464.5928\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2399.0466 - val_loss: 6439.0566\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2377.6265 - val_loss: 6413.6489\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2356.3958 - val_loss: 6388.3501\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2335.3704 - val_loss: 6363.1177\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2314.5359 - val_loss: 6337.9990\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2293.9019 - val_loss: 6313.0068\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2273.4604 - val_loss: 6288.1528\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2253.2100 - val_loss: 6263.4473\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2233.1475 - val_loss: 6238.9062\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2213.2712 - val_loss: 6214.5415\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2193.5786 - val_loss: 6190.3604\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2174.0715 - val_loss: 6166.3486\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2154.7512 - val_loss: 6142.4873\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2135.6052 - val_loss: 6118.8066\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2116.6414 - val_loss: 6095.3154\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2097.8567 - val_loss: 6072.0000\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2079.2478 - val_loss: 6048.8291\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2060.8132 - val_loss: 6025.8364\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2042.5503 - val_loss: 6003.0073\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2024.4620 - val_loss: 5980.3262\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2006.5437 - val_loss: 5957.7886\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1988.7924 - val_loss: 5935.4053\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1971.2095 - val_loss: 5913.1729\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1953.7936 - val_loss: 5891.0918\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1936.5404 - val_loss: 5869.1528\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1919.4493 - val_loss: 5847.3481\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1902.5217 - val_loss: 5825.7158\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1885.7539 - val_loss: 5804.2354\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1869.1450 - val_loss: 5782.8911\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1852.6936 - val_loss: 5761.7290\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1836.3989 - val_loss: 5740.7051\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1820.2599 - val_loss: 5719.8105\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 1804.2751 - val_loss: 5699.1094\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1788.4421 - val_loss: 5678.4790\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1772.7612 - val_loss: 5658.0020\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1757.2318 - val_loss: 5637.7651\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1741.8511 - val_loss: 5617.5396\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1726.6167 - val_loss: 5597.4380\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1711.5302 - val_loss: 5577.6270\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1696.5876 - val_loss: 5557.7559\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1681.7870 - val_loss: 5537.8750\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1667.1300 - val_loss: 5518.3149\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1652.6074 - val_loss: 5498.7915\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1638.2222 - val_loss: 5479.1694\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1623.9723 - val_loss: 5459.7939\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1609.8667 - val_loss: 5440.7173\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1595.9069 - val_loss: 5421.6045\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1582.0839 - val_loss: 5402.5244\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1568.3959 - val_loss: 5383.7993\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1554.8403 - val_loss: 5365.2422\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1541.4182 - val_loss: 5346.5908\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1528.1263 - val_loss: 5328.0884\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1514.9652 - val_loss: 5309.9346\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1501.9316 - val_loss: 5291.8257\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1489.0267 - val_loss: 5273.6592\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1476.2478 - val_loss: 5255.7495\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1463.5938 - val_loss: 5238.1196\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1451.0641 - val_loss: 5220.4331\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1438.6570 - val_loss: 5202.7095\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1426.3705 - val_loss: 5185.2407\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1414.2026 - val_loss: 5167.9019\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1402.1510 - val_loss: 5150.4058\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1390.2108 - val_loss: 5132.8716\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1378.3749 - val_loss: 5115.4531\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1366.6273 - val_loss: 5097.8052\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1354.9366 - val_loss: 5079.5571\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1343.2343 - val_loss: 5060.8125\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1331.4154 - val_loss: 5041.8081\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1319.3713 - val_loss: 5022.7808\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1307.0812 - val_loss: 5004.1689\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1294.6958 - val_loss: 4986.4106\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1282.4899 - val_loss: 4970.3350\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1270.6398 - val_loss: 4956.3984\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1259.1428 - val_loss: 4944.0000\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1247.9907 - val_loss: 4930.2178\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1237.0521 - val_loss: 4914.4341\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1226.2480 - val_loss: 4898.4004\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1215.6360 - val_loss: 4883.8130\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1205.1501 - val_loss: 4868.9990\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1194.7927 - val_loss: 4852.0532\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1184.5621 - val_loss: 4831.3750\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1174.4458 - val_loss: 4807.8345\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1164.4366 - val_loss: 4784.1284\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1154.5333 - val_loss: 4762.1387\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1144.7358 - val_loss: 4742.1938\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1135.0466 - val_loss: 4723.8994\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1125.4656 - val_loss: 4706.7822\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1115.9934 - val_loss: 4690.4707\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1106.6271 - val_loss: 4674.7080\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1097.3656 - val_loss: 4659.3560\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1088.2047 - val_loss: 4644.3833\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1079.1464 - val_loss: 4629.8223\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1070.1888 - val_loss: 4615.7280\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1061.3334 - val_loss: 4602.1553\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1052.5780 - val_loss: 4589.1396\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1043.9211 - val_loss: 4576.6357\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1035.3619 - val_loss: 4564.4575\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1026.8999 - val_loss: 4552.2290\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1018.5339 - val_loss: 4539.4482\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1010.2643 - val_loss: 4525.6987\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1002.0895 - val_loss: 4510.8833\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 994.0078 - val_loss: 4495.2793\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 986.0181 - val_loss: 4479.3613\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 978.1194 - val_loss: 4463.5605\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 970.3112 - val_loss: 4448.1260\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 962.5926 - val_loss: 4433.1304\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 954.9620 - val_loss: 4418.5459\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 947.4205 - val_loss: 4404.3066\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 939.9656 - val_loss: 4390.3491\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step - loss: 932.5964 - val_loss: 4376.6240\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 925.3125 - val_loss: 4363.1050\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 918.1123 - val_loss: 4349.7793\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 910.9949 - val_loss: 4336.6494\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 903.9606 - val_loss: 4323.7212\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 897.0070 - val_loss: 4311.0034\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 890.1344 - val_loss: 4298.4990\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 883.3406 - val_loss: 4286.2046\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 876.6243 - val_loss: 4274.1079\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 869.9838 - val_loss: 4262.1699\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 863.4156 - val_loss: 4250.2417\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 856.9138 - val_loss: 4238.3042\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 850.4742 - val_loss: 4226.3262\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 844.0934 - val_loss: 4214.2734\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 837.7815 - val_loss: 4202.1377\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 831.5587 - val_loss: 4189.9385\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 825.4348 - val_loss: 4177.7114\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 819.3948 - val_loss: 4165.5010\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 813.4284 - val_loss: 4153.3569\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 807.5322 - val_loss: 4141.3257\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 801.7060 - val_loss: 4129.4058\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 795.9484 - val_loss: 4117.5645\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 790.2587 - val_loss: 4105.8662\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 784.6368 - val_loss: 4094.3728\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 779.0807 - val_loss: 4083.1116\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 773.5914 - val_loss: 4072.0938\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 768.1673 - val_loss: 4061.3391\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 762.8076 - val_loss: 4050.8594\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 757.5117 - val_loss: 4040.5266\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 752.2792 - val_loss: 4030.2043\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 747.1090 - val_loss: 4020.0210\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 742.0010 - val_loss: 4010.0503\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 736.9537 - val_loss: 4000.3230\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 731.9675 - val_loss: 3990.8245\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 727.0408 - val_loss: 3980.9729\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 722.1736 - val_loss: 3970.9141\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 717.3652 - val_loss: 3961.2161\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 712.6149 - val_loss: 3952.0833\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 707.9217 - val_loss: 3942.7380\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 703.2853 - val_loss: 3932.5117\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 698.7053 - val_loss: 3923.3655\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 694.1805 - val_loss: 3915.5781\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 689.7111 - val_loss: 3904.9951\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 685.2958 - val_loss: 3896.7058\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 680.9345 - val_loss: 3890.4968\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 676.6265 - val_loss: 3877.6343\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 672.3705 - val_loss: 3871.7581\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 668.1671 - val_loss: 3867.9724\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 664.0150 - val_loss: 3849.1140\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 659.9140 - val_loss: 3844.0808\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 655.8624 - val_loss: 3846.2568\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 651.8621 - val_loss: 3819.5884\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 647.9105 - val_loss: 3810.7087\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 644.0078 - val_loss: 3812.3623\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 640.1528 - val_loss: 3794.7468\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 636.3447 - val_loss: 3783.2390\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 632.5859 - val_loss: 3775.7698\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 628.8727 - val_loss: 3766.5071\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 625.2067 - val_loss: 3755.1697\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 621.5866 - val_loss: 3746.3396\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 618.0111 - val_loss: 3737.9048\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 614.4818 - val_loss: 3727.8506\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 610.9957 - val_loss: 3718.7666\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 607.5543 - val_loss: 3710.2146\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 604.1565 - val_loss: 3701.1421\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 600.8010 - val_loss: 3692.1150\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 597.4889 - val_loss: 3683.5562\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 594.2180 - val_loss: 3675.1033\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 590.9896 - val_loss: 3666.4949\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 587.8018 - val_loss: 3658.0837\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 584.6550 - val_loss: 3649.9265\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 581.5478 - val_loss: 3641.7827\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 578.4810 - val_loss: 3633.6277\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 575.4532 - val_loss: 3625.6313\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 572.4642 - val_loss: 3617.7542\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 569.5135 - val_loss: 3609.8706\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 566.6010 - val_loss: 3602.0391\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 563.7260 - val_loss: 3594.3198\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 560.8880 - val_loss: 3586.6641\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 558.0870 - val_loss: 3579.0376\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 555.3221 - val_loss: 3571.4917\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 552.5933 - val_loss: 3564.0234\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 549.8996 - val_loss: 3556.6101\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 547.2411 - val_loss: 3549.2522\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 544.6174 - val_loss: 3541.9548\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 542.0278 - val_loss: 3534.7078\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 539.4721 - val_loss: 3527.5107\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 536.9501 - val_loss: 3520.3635\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 534.4611 - val_loss: 3513.2544\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 532.0046 - val_loss: 3506.1917\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 529.5808 - val_loss: 3499.1890\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 527.1884 - val_loss: 3492.2505\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 524.8286 - val_loss: 3485.3718\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 522.4990 - val_loss: 3478.5808\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 520.2010 - val_loss: 3471.9119\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 517.9332 - val_loss: 3465.3911\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 515.6957 - val_loss: 3459.0649\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 513.4882 - val_loss: 3453.0359\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 511.3098 - val_loss: 3447.2009\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 509.1607 - val_loss: 3440.0295\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 507.0403 - val_loss: 3432.9673\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 504.9487 - val_loss: 3426.2922\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 502.8848 - val_loss: 3420.0088\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 500.8488 - val_loss: 3414.1536\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 498.8402 - val_loss: 3408.6187\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 496.8589 - val_loss: 3401.6340\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 494.9045 - val_loss: 3394.8438\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 492.9763 - val_loss: 3388.5972\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 491.0744 - val_loss: 3382.8350\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 489.1985 - val_loss: 3377.2061\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 487.3480 - val_loss: 3370.5850\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 485.5227 - val_loss: 3364.0837\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 483.7225 - val_loss: 3358.0781\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 481.9467 - val_loss: 3352.4734\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 480.1957 - val_loss: 3346.7766\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 478.4682 - val_loss: 3340.4819\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 476.7649 - val_loss: 3334.3010\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 475.0850 - val_loss: 3328.5186\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 473.4282 - val_loss: 3323.0044\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 471.7946 - val_loss: 3317.2905\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 470.1833 - val_loss: 3311.2642\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 468.5947 - val_loss: 3305.3867\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 467.0278 - val_loss: 3299.8113\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 465.4829 - val_loss: 3294.3677\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 463.9596 - val_loss: 3288.7378\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 462.4573 - val_loss: 3282.9973\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 460.9763 - val_loss: 3277.4219\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 459.5161 - val_loss: 3272.0562\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 458.0765 - val_loss: 3266.7354\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 456.6568 - val_loss: 3261.2961\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 455.2574 - val_loss: 3255.8455\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 453.8776 - val_loss: 3250.5366\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 452.5172 - val_loss: 3245.3618\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 451.1764 - val_loss: 3240.1975\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 449.8544 - val_loss: 3234.9744\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 448.5512 - val_loss: 3229.7729\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 447.2665 - val_loss: 3224.6733\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 446.0002 - val_loss: 3219.6633\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 444.7519 - val_loss: 3214.6707\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 443.5216 - val_loss: 3209.6580\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 442.3088 - val_loss: 3204.6677\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 441.1134 - val_loss: 3199.7473\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 439.9353 - val_loss: 3194.9009\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 438.7741 - val_loss: 3190.0901\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 437.6295 - val_loss: 3185.2834\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 436.5016 - val_loss: 3180.4885\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 435.3901 - val_loss: 3175.7380\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 434.2946 - val_loss: 3171.0496\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 433.2150 - val_loss: 3166.4124\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 432.1512 - val_loss: 3161.7959\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 431.1028 - val_loss: 3157.1865\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 430.0695 - val_loss: 3152.5999\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 429.0516 - val_loss: 3148.0632\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 428.0483 - val_loss: 3143.5823\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 427.0598 - val_loss: 3139.1404\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 426.0861 - val_loss: 3134.7136\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 425.1264 - val_loss: 3130.2996\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 424.1810 - val_loss: 3125.9172\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 423.2495 - val_loss: 3121.5867\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 422.3319 - val_loss: 3117.3044\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 421.4277 - val_loss: 3113.0557\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 420.5371 - val_loss: 3108.8232\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 419.6595 - val_loss: 3104.6096\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 418.7949 - val_loss: 3100.4319\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 417.9434 - val_loss: 3096.2998\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 417.1045 - val_loss: 3092.2102\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 416.2780 - val_loss: 3088.1523\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 415.4642 - val_loss: 3084.1135\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 414.6625 - val_loss: 3080.0972\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 413.8728 - val_loss: 3076.1125\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 413.0949 - val_loss: 3072.1677\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 412.3287 - val_loss: 3068.2622\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 411.5742 - val_loss: 3064.3872\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 410.8312 - val_loss: 3060.5361\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 410.0992 - val_loss: 3056.7073\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 409.3783 - val_loss: 3052.9070\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 408.6685 - val_loss: 3049.1409\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 407.9693 - val_loss: 3045.4094\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 407.2810 - val_loss: 3041.7114\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 406.6031 - val_loss: 3038.0391\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 405.9357 - val_loss: 3034.3906\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 405.2783 - val_loss: 3030.7678\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 404.6308 - val_loss: 3027.1741\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 403.9938 - val_loss: 3023.6116\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 403.3663 - val_loss: 3020.0808\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 402.7484 - val_loss: 3016.5786\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 402.1400 - val_loss: 3013.1025\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 401.5412 - val_loss: 3009.6511\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 400.9514 - val_loss: 3006.2241\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 400.3711 - val_loss: 3002.8218\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 399.7994 - val_loss: 2999.4497\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 399.2368 - val_loss: 2996.1060\n",
      "MAE: 50.28315551757813\n",
      "SMAPE: 47.96673996024673\n",
      "RMSE: 55.038685051126926\n",
      "R2 Score: -5.534864051408866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Spliting the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "# Define the encoder and decoder inputs\n",
    "encoder_inputs = Input(shape=(None, 1))\n",
    "decoder_inputs = Input(shape=(None, 1))\n",
    "\n",
    "# Define the encoder LSTM layer\n",
    "encoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder LSTM layer\n",
    "decoder_lstm = LSTM(180, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Adding the Attention mechanism \n",
    "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "# Output layer\n",
    "output = TimeDistributed(Dense(1, activation='linear'))(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Prepare data using the last 2 data points for the rolling window\n",
    "window_size = 1\n",
    "\n",
    "encoder_input_train = train_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_output_train = train_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_input_train = np.zeros_like(decoder_output_train)  # Initializing decoder inputs\n",
    "\n",
    "# Teacher forcing: Setting up decoder inputs with true outputs from previous timestep\n",
    "decoder_input_train[:-1] = decoder_output_train[:-1]\n",
    "\n",
    "encoder_input_val = val_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_val = val_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "encoder_input_test = test_data.values[-window_size-1:-1, :, np.newaxis]\n",
    "decoder_input_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "decoder_output_test = test_data.values[-window_size:, :, np.newaxis]\n",
    "\n",
    "# Train the model using teacher forcing\n",
    "model.fit(\n",
    "    [encoder_input_train, decoder_input_train],\n",
    "    decoder_output_train,\n",
    "    validation_data=([encoder_input_val, decoder_input_val], decoder_output_val),\n",
    "    epochs=500,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "preds = model.predict([encoder_input_test, decoder_input_test])\n",
    "predictions = preds.squeeze()\n",
    "test_values = decoder_output_test.squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_values, predictions)\n",
    "smape = 100 * np.mean(2 * np.abs(predictions - test_values) / (np.abs(predictions) + np.abs(test_values)))\n",
    "rmse = np.sqrt(mean_squared_error(test_values, predictions))\n",
    "r2 = r2_score(test_values, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"SMAPE:\", smape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebc5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
